{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCKVmb32RehK"
      },
      "source": [
        "# **Grounding DINO - Abel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-onp0zmeW2R"
      },
      "source": [
        "### Imports and config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "vQQI2JK-qooE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fClyB0MARsWl",
        "outputId": "53224289-b88a-4a07-e2b5-3237a32ca110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.17.1-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.23.5)\n",
            "Collecting opencv-python-headless<=4.8.1.78,>=4.5.5.64 (from supervision)\n",
            "  Downloading opencv_python_headless-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.11.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Collecting starlette<0.36.0,>=0.35.0 (from fastapi)\n",
            "  Downloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->supervision) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->supervision) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->supervision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->supervision) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->supervision) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.36.0,>=0.35.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->supervision) (1.16.0)\n",
            "Installing collected packages: kaleido, typing-extensions, python-multipart, opencv-python-headless, h11, uvicorn, starlette, supervision, fastapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.109.0 h11-0.14.0 kaleido-0.2.1 opencv-python-headless-4.8.1.78 python-multipart-0.0.6 starlette-0.35.1 supervision-0.17.1 typing-extensions-4.9.0 uvicorn-0.26.0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install supervision fastapi kaleido python-multipart uvicorn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os, cv2, bisect\n",
        "import supervision as sv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT1ZWFrXRuWt"
      },
      "source": [
        "## **Grounding DINO Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puvr4k4LSKGa"
      },
      "source": [
        "**Download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xdjawtLRzlB",
        "outputId": "26459179-b789-43fe-9a4b-9cecdfafe98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'GroundingDINO'...\n",
            "remote: Enumerating objects: 421, done.\u001b[K\n",
            "remote: Counting objects: 100% (182/182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 421 (delta 136), reused 131 (delta 124), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (421/421), 12.85 MiB | 24.06 MiB/s, done.\n",
            "Resolving deltas: 100% (214/214), done.\n",
            "/content/GroundingDINO\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py ; exist: True\n",
            "/content\n",
            "/content/weights\n",
            "/content/weights/groundingdino_swint_ogc.pth ; exist: True\n",
            "/content/GroundingDINO\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "%cd {HOME}/GroundingDINO\n",
        "!pip install -q -e .\n",
        "!pip install -q roboflow\n",
        "\n",
        "CONFIG_PATH = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
        "print(CONFIG_PATH, \"; exist:\", os.path.isfile(CONFIG_PATH))\n",
        "\n",
        "%cd {HOME}\n",
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
        "\n",
        "WEIGHTS_NAME = \"groundingdino_swint_ogc.pth\"\n",
        "WEIGHTS_PATH = os.path.join(HOME, \"weights\", WEIGHTS_NAME)\n",
        "print(WEIGHTS_PATH, \"; exist:\", os.path.isfile(WEIGHTS_PATH))\n",
        "\n",
        "%cd {HOME}/GroundingDINO\n",
        "from groundingdino.util.inference import load_model, load_image, predict, annotate, Model\n",
        "from groundingdino.util.utils import get_phrases_from_posmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbMcRvNbSLgv"
      },
      "source": [
        "**Load**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq-vlgrlSMvz",
        "outputId": "69754f8d-11f3-4e14-c417-4766a9a2ecc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GroundingDINO\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}/GroundingDINO\n",
        "from groundingdino.util.inference import load_model, load_image, predict, annotate, Model\n",
        "from groundingdino.util.utils import get_phrases_from_posmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kJt4Uk1SEVU"
      },
      "source": [
        "## **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfgr36hCU2Sc"
      },
      "outputs": [],
      "source": [
        "classes = ['acorn', 'axe', 'backpack', 'badger', 'bag', 'barrel', 'basket', 'bear', 'bed', 'bee', 'bell', 'bench', 'bird', 'birdcage', 'boar', 'boat', 'book', 'bottle', 'bow', 'bowl', 'box', 'bridge', 'broom', 'brush', 'bucket', 'building', 'butterfly', 'camel', 'campfire', 'candle', 'cane', 'cannon', 'car', 'cat', 'cello', 'chair', 'clock', 'couch', 'cow', 'cradle', 'crown', 'cup', 'curtain', 'deer', 'diningTable', 'dog', 'doghouse', 'donkey', 'door', 'dragon', 'drum', 'egg', 'elephant', 'ermine', 'feather', 'female', 'fence', 'fireplace', 'fish', 'fishingRod', 'flag', 'flower', 'flute', 'fox', 'frog', 'glasses', 'globe', 'goat', 'gun', 'hammer', 'hat', 'hedgehog', 'helmet', 'horse', 'hotAirBalloon', 'inkpot', 'insect', 'jackal', 'jar', 'jug', 'kettle', 'kite', 'knife', 'ladder', 'lamp', 'lifebuoy', 'lion', 'lizard', 'lobster', 'male', 'map', 'marmot', 'melon', 'monkey', 'moon', 'musicSheet', 'nest', 'net', 'painting', 'paintingStand', 'pan', 'pear', 'pen', 'penguin', 'piano', 'pickaxe', 'pig', 'pineapple', 'pipe', 'plant', 'plate', 'pot', 'pottedPlant', 'rabbit', 'rake', 'rat', 'rhino', 'sausage', 'saw', 'scale', 'scissors', 'scorpion', 'seal', 'shark', 'sheep', 'shield', 'shovel', 'sieve', 'skate', 'snail', 'snake', 'spear', 'spoon', 'sportsBall', 'squirrel', 'star', 'stool', 'stroller', 'suitcase', 'sun', 'sunflower', 'sword', 'teachingBoard', 'teapot', 'tent', 'tie', 'tiger', 'train', 'tree', 'trumpet', 'tub', 'turtle', 'umbrella', 'vase', 'violin', 'wagon', 'walnut', 'weight', 'whip', 'windmill', 'window', 'wineGlass', 'wolf', 'zebra']\n",
        "# datasets = ['train', 'valid', 'test']\n",
        "datasets = ['train']\n",
        "data = {}\n",
        "\n",
        "transform_img_to_tensor = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "for dataset in datasets:\n",
        "    directory_images = '/content/drive/MyDrive/Delft/capstone data/1.0_Children_Books/'+dataset+'/images'\n",
        "    directory_labels = '/content/drive/MyDrive/Delft/capstone data/1.0_Children_Books/'+dataset+'/labels'\n",
        "\n",
        "    files_images = os.listdir(directory_images)\n",
        "    files_labels = os.listdir(directory_labels)\n",
        "\n",
        "    data[dataset] = []\n",
        "\n",
        "    # Load image name, label and bbox coordinates in format (name, [[label, bbox coordinates], ...])\n",
        "    for idx, label in enumerate(files_labels[:100]):\n",
        "        img_label = label[:-4]\n",
        "        img = directory_images+'/'+img_label+'.jpg'\n",
        "        # img = Image.open(img)\n",
        "        # numpy_image = transform_img_to_tensor(img).numpy()\n",
        "        _, img = load_image(img)\n",
        "\n",
        "        f = open(directory_labels+'/'+label)\n",
        "        f = [i.split(' ') for i in  f.read().split('\\n')]\n",
        "        f = [[float(j) for j in i] for i in f]\n",
        "\n",
        "        y_labels_int = torch.LongTensor([i[0] for i in f])\n",
        "        # y_labels_str = [classes[int(i[0])] for i in f]\n",
        "        # y_labels_str = [classes[i] for i in y_labels_int]\n",
        "        y_bboxes = torch.tensor([i[1:] for i in f])\n",
        "\n",
        "        # print('f: {}'.format(f))\n",
        "        # print(y_labels_int, y_labels_str, y_bboxes)\n",
        "\n",
        "        data[dataset].append((img, y_labels_int, y_bboxes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbSXmYIxaUsR"
      },
      "source": [
        "**Create data loaders**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate(batch):\n",
        "    img = [item[0] for item in batch]\n",
        "    target_int = [item[1] for item in batch]\n",
        "    target_bbox = [item[2] for item in batch]\n",
        "\n",
        "    return [img, target_int, target_bbox]\n",
        "\n",
        "    # data = [item[0] for item in batch]\n",
        "    # target = [item[1] for item in batch]\n",
        "    # target = torch.LongTensor(target)\n",
        "    # return [data, target]\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "train_loader = DataLoader(data['train'], batch_size, shuffle = False, pin_memory = True, collate_fn=custom_collate)\n",
        "# val_loader = DataLoader(data['valid'], batch_size*2, pin_memory = True)\n",
        "# test_loader = DataLoader(data['test'], batch_size*2, pin_memory = True)"
      ],
      "metadata": {
        "id": "JUrRn3WNRe8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozB_9_8sSS-j"
      },
      "source": [
        "## **Train, validation, test helper funcions**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train function"
      ],
      "metadata": {
        "id": "nfc4m4smez8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GD uses L1 and GIO loss**"
      ],
      "metadata": {
        "id": "-WJ5TmpluoBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crossentropy_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(train_loader, net, optimizer, IoU_threshold=0.6, beta=1e3):\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    loss_list = []\n",
        "\n",
        "    for i, d in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        print('ITEM {} IN LOADER     '.format(i)+'-'*70)\n",
        "\n",
        "        # -------------------------\n",
        "        # |   DATA FROM LOADER    |\n",
        "        # -------------------------\n",
        "\n",
        "        image_tensor, y_labels_int, y_bboxes = d\n",
        "        image_tensor, y_labels_int, y_bboxes = image_tensor[0], y_labels_int[0], y_bboxes[0]\n",
        "        y_labels_str = [classes[i] for i in y_labels_int]\n",
        "\n",
        "        print('y_labels_str = {}'.format(y_labels_str))\n",
        "\n",
        "        image_tensor = image_tensor.to(device)\n",
        "\n",
        "        # -------------------------\n",
        "        # |   RUN FORWARD PASS    |\n",
        "        # -------------------------\n",
        "\n",
        "        caption = \". \".join(list(set(y_labels_str)))+'.'\n",
        "        # print('PROVIDED CAPTION: {}'.format(caption))\n",
        "\n",
        "        y_hat_bboxes, y_hat_logits, y_hat_labels_str, y_hat_logits_raw = net(image_tensor, caption)\n",
        "\n",
        "        print('y_hat_labels_str = {}'.format(y_hat_labels_str))\n",
        "\n",
        "        if y_hat_labels_str != []:\n",
        "            # print('y_hat_bboxes = {}'.format(y_hat_bboxes))\n",
        "            # print('y_hat_logits_raw = {}'.format(y_hat_logits_raw))\n",
        "\n",
        "            # -------------------------\n",
        "            # |   PROCESS OUTPUTS     |\n",
        "            # -------------------------\n",
        "\n",
        "            # Remove classes from y_labels_str that GD did not find\n",
        "            for i in y_labels_str:\n",
        "                if not i in y_hat_labels_str:\n",
        "                    index = y_labels_str.index(i)\n",
        "                    y_labels_str = y_labels_str[0:index] + y_labels_str[index+1:]\n",
        "                    y_labels_int = torch.cat([y_labels_int.clone()[0:index], y_labels_int.clone()[index+1:]])\n",
        "                    y_bboxes = torch.cat([y_bboxes.clone()[0:index], y_bboxes.clone()[index+1:]])\n",
        "\n",
        "\n",
        "            # Check GD prediction belongs to which true label by checking the highest IoU with an IoU threshold\n",
        "            final_y_order_list = []\n",
        "            final_y_hat_order_list = []\n",
        "\n",
        "            for idx, true in enumerate(y_labels_str):\n",
        "                IoU_list = []\n",
        "                new_y_order_list = []\n",
        "                new_y_hat_order_list = []\n",
        "\n",
        "                for idx2, pred in enumerate(y_hat_labels_str):\n",
        "                    IoU = calc_IoU(y_bboxes[idx], y_hat_bboxes[idx2])\n",
        "                    # print('{} - {} - {}'.format(true, pred, IoU))\n",
        "                    if IoU > IoU_threshold:\n",
        "                        IoU_list.append(IoU)\n",
        "                        new_y_order_list.append(idx)\n",
        "                        new_y_hat_order_list.append(idx2)\n",
        "\n",
        "\n",
        "                if IoU_list != []:\n",
        "                    IoU_list = np.array([i.item() for i in IoU_list])\n",
        "\n",
        "                    argmax = np.argmax(IoU_list)\n",
        "\n",
        "                    new_y_order = new_y_order_list[argmax]\n",
        "                    final_y_order_list.append(new_y_order)\n",
        "\n",
        "                    new_y_hat_order = new_y_hat_order_list[argmax]\n",
        "                    final_y_hat_order_list.append(new_y_hat_order)\n",
        "\n",
        "            # print('final_y_order_list = {}'.format(final_y_order_list))\n",
        "            # print('final_y_hat_order_list = {}'.format(final_y_hat_order_list))\n",
        "\n",
        "            if final_y_order_list != []:\n",
        "                y_labels_int_v2 = torch.tensor([y_labels_int[i] for i in final_y_order_list]).to(device)\n",
        "                y_labels_str_v2 = [y_labels_str[i] for i in final_y_order_list]\n",
        "                y_bboxes_v2 = y_bboxes.clone().index_select(0, torch.tensor(final_y_order_list)).to(device)\n",
        "\n",
        "            if final_y_hat_order_list != []:\n",
        "                y_hat_labels_str_v2 = [y_hat_labels_str[i] for i in final_y_hat_order_list]\n",
        "                y_hat_bboxes_v2 = y_hat_bboxes.clone().index_select(0, torch.tensor(final_y_hat_order_list).to(device)).to(device)\n",
        "                y_hat_logits_raw_v2 = y_hat_logits_raw.clone().index_select(0, torch.tensor(final_y_hat_order_list).to(device)).to(device)\n",
        "            print('[Values V2]')\n",
        "            print('y_labels_str_v2 = {}'.format(y_labels_str_v2))\n",
        "            print('y_labels_int_v2 = {}'.format(y_labels_int_v2))\n",
        "            print('y_bboxes_v2 = {}'.format(y_bboxes_v2))\n",
        "\n",
        "            print('y_hat_labels_str_v2 = {}'.format(y_hat_labels_str_v2))\n",
        "            print('y_hat_bboxes_v2 = {}'.format(y_hat_bboxes_v2))\n",
        "            print('y_hat_logits_raw_v2 = {}'.format(y_hat_logits_raw_v2))\n",
        "\n",
        "            # -------------------------\n",
        "            # |    CALCULATE LOSS     |\n",
        "            # -------------------------\n",
        "\n",
        "            loss_box = torch.mean((y_bboxes_v2-y_hat_bboxes_v2)**2)*beta\n",
        "            loss_cls = crossentropy_loss(y_hat_logits_raw_v2, y_labels_int_v2)\n",
        "            loss = loss_box + loss_cls\n",
        "\n",
        "            print('loss = loss_box*{} + loss_cls = {} = {} + {}'.format(beta, loss, loss_box, loss_cls))\n",
        "\n",
        "            if not torch.isnan(loss):\n",
        "                loss.backward()\n",
        "\n",
        "                print('MODEL PARAMETER GRADIENT CHECK: {}'.format(list(model.parameters())[-1].grad))\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                loss_list.append(loss.item())\n",
        "\n",
        "    if len(loss_list) != 0:\n",
        "        return sum(loss_list)/len(loss_list)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "CCtx90PUeyZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train function 22:32 17/01/2024"
      ],
      "metadata": {
        "id": "VcpdWG-CVzXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crossentropy_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# def train(train_loader, net, optimizer, IoU_threshold=0.6):\n",
        "#     loss_list = []\n",
        "\n",
        "#     for i, d in enumerate(train_loader):\n",
        "#         print('\\nITERATION IN LOADER: {}'.format(i)+'-'*40)\n",
        "\n",
        "#         # -------------------------\n",
        "#         # |   DATA FROM LOADER    |\n",
        "#         # -------------------------\n",
        "\n",
        "#         image_tensor, y_labels_int, y_bboxes = d\n",
        "#         image_tensor, y_labels_int, y_bboxes = image_tensor[0], y_labels_int[0], y_bboxes[0]\n",
        "#         y_labels_str = [classes[i] for i in y_labels_int]\n",
        "\n",
        "#         image_tensor = image_tensor.to(device)\n",
        "\n",
        "#         # print('\\n[Y VALUES]')\n",
        "#         # print('y_labels_str = {}'.format(y_labels_str))\n",
        "#         # print('y_labels_int = {}'.format(y_labels_int))\n",
        "#         # print('y_bboxes = {}'.format(y_bboxes))\n",
        "\n",
        "#         # image_tensor, y_labels_int, y_bboxes = image_tensor.to(device), y_labels_int.to(device), y_bboxes.to(device)\n",
        "\n",
        "#         # -------------------------\n",
        "#         # |   RUN FORWARD PASS    |\n",
        "#         # -------------------------\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         caption = \". \".join(list(set(y_labels_str)))+'.'\n",
        "#         print('PROVIDED CAPTION: {}'.format(caption))\n",
        "\n",
        "#         y_hat_bboxes, y_hat_logits, y_hat_labels_str, y_hat_logits_raw = net(image_tensor, caption)\n",
        "\n",
        "#         # -------------------------\n",
        "#         # |   PROCESS OUTPUTS     |\n",
        "#         # -------------------------\n",
        "\n",
        "#         # Check if GD found all classes, remove not found classes by GD from true labels list y_labels_str\n",
        "#         for i in y_labels_str:\n",
        "#             # print('{} in {} is {}'.format(i, y_hat_labels_str, i in y_hat_labels_str))\n",
        "#             if not i in y_hat_labels_str:\n",
        "#                 index = y_labels_str.index(i)\n",
        "#                 # y_labels_str.remove(i)\n",
        "#                 y_labels_str = y_labels_str[0:index] + y_labels_str[index+1:]\n",
        "#                 y_labels_int = torch.cat([y_labels_int[0:index], y_labels_int[index+1:]])\n",
        "#                 y_bboxes = torch.cat([y_bboxes[0:index], y_bboxes[index+1:]])\n",
        "\n",
        "\n",
        "#         # print('\\n[Y VALUES AFTER DELETION]\\ny_labels_str = {}\\ny_labels_int = {}\\ny_bboxes = {}'.format(y_labels_str, y_labels_int, y_bboxes))\n",
        "#         # print('\\n[BEFORE IOU FILTER]')\n",
        "#         # print('y_hat_labels_str: {}'.format(y_hat_labels_str))\n",
        "#         # print('y_hat_bboxes: {}'.format(y_hat_bboxes))\n",
        "\n",
        "#         # Convert list[tensor, ...] to tensor[list, ...]\n",
        "#         y_hat_bboxes = torch.tensor([i.tolist() for i in y_hat_bboxes])\n",
        "#         y_hat_logits_raw = torch.tensor([i.tolist() for i in y_hat_logits_raw])\n",
        "\n",
        "#         # Check GD prediction belongs to which true label\n",
        "#         # Loop over true labels and link the prediction with the highest IoU\n",
        "\n",
        "#         y_hat_labels_str_v2 = []\n",
        "#         y_hat_IoU_v2 = []\n",
        "#         y_hat_bboxes_v2 = []\n",
        "#         y_hat_logits_v2 = []\n",
        "#         y_hat_logits_raw_v2 = []\n",
        "\n",
        "#         y_labels_str_v2 = []\n",
        "#         y_labels_int_v2 = []\n",
        "#         y_bboxes_v2 = []\n",
        "\n",
        "#         for idx, true in enumerate(y_labels_str):\n",
        "#             # print('\\nTrue label: {} - {}'.format(true, idx))\n",
        "\n",
        "#             best_IoU = 0\n",
        "#             y_hat_best_label_str = ''\n",
        "#             y_hat_best_corresponding_bbox = []\n",
        "#             y_hat_best_corresponding_logits = []\n",
        "#             y_hat_best_corresponding_logits_raw = []\n",
        "\n",
        "#             y_best_corresponding_bbox = []\n",
        "\n",
        "#             for idx2, pred in enumerate(y_hat_labels_str):\n",
        "#                 IoU = calc_IoU(y_hat_bboxes[idx2], y_bboxes[idx])\n",
        "#                 # print('Checking with prediction: {} - {}, IoU: {}'.format(pred, idx2, IoU))\n",
        "#                 if IoU > best_IoU and IoU > IoU_threshold:\n",
        "#                     best_IoU = IoU\n",
        "#                     y_hat_best_label_str = pred\n",
        "#                     y_hat_best_corresponding_bbox = y_hat_bboxes[idx2].tolist()\n",
        "#                     y_hat_best_corresponding_logits = y_hat_logits[idx2].tolist()\n",
        "#                     y_hat_best_corresponding_logits_raw = y_hat_logits_raw[idx2].tolist()\n",
        "\n",
        "#                     y_best_corresponding_bbox = y_bboxes[idx].tolist()\n",
        "#                     # print('[NEW BEST ]')\n",
        "\n",
        "#             if best_IoU != 0:\n",
        "#                 y_hat_IoU_v2.append(best_IoU)\n",
        "#                 y_hat_labels_str_v2.append(y_hat_best_label_str)\n",
        "#                 y_hat_bboxes_v2.append(y_hat_best_corresponding_bbox)\n",
        "#                 y_hat_logits_v2.append(y_hat_best_corresponding_logits)\n",
        "#                 y_hat_logits_raw_v2.append(y_hat_best_corresponding_logits_raw)\n",
        "\n",
        "#                 y_labels_str_v2.append(true)\n",
        "#                 y_labels_int_v2.append(y_labels_int[idx])\n",
        "#                 y_bboxes_v2.append(y_best_corresponding_bbox)\n",
        "#             else:\n",
        "#                 pass\n",
        "#                 # print('NO IOU ABOVE THRESHOLD {}'.format(IoU_threshold))\n",
        "\n",
        "#         y_hat_bboxes_v2 = torch.tensor(y_hat_bboxes_v2).to(device)\n",
        "#         y_hat_logits_v2 = torch.tensor(y_hat_logits_v2).to(device)\n",
        "#         y_hat_logits_raw_v2 = torch.tensor(y_hat_logits_raw_v2).to(device)\n",
        "\n",
        "#         y_labels_int_v2 = torch.tensor([i.item() for i in y_labels_int_v2]).to(device)\n",
        "#         y_bboxes_v2 = torch.tensor(y_bboxes_v2).to(device)\n",
        "\n",
        "#         IoUs = [i.item() for i in y_hat_IoU_v2]\n",
        "\n",
        "#         # print('\\n[AFTER IOU FILTER]')\n",
        "#         # print('\\n[Y VALUES V2]')\n",
        "#         # print('y_labels_str_v2 = {}'.format(y_labels_str_v2))\n",
        "#         # print('y_labels_int_v2 = {}'.format(y_labels_int_v2))\n",
        "#         # print('IoUs = {}'.format(IoUs))\n",
        "#         # print('y_bboxes_v2 = {}'.format(y_bboxes_v2))\n",
        "\n",
        "#         # print('\\n[Y-HAT VALUES V2]')\n",
        "#         # print('y_hat_labels_str_v2 = {}'.format(y_hat_labels_str_v2))\n",
        "#         # print('y_hat_bboxes_v2 = {}'.format(y_hat_bboxes_v2))\n",
        "#         # print('y_hat_logits_raw_v2 shape = {}'.format(y_hat_logits_raw_v2.shape))\n",
        "#         # # print('\\nlen(y_hat_logits_raw_v2): {}'.format(len(y_hat_logits_raw_v2)))\n",
        "#         # print('len(y_labels_int) = {}'.format(len(y_labels_int)))\n",
        "\n",
        "\n",
        "#         # -------------------------\n",
        "#         # |    CALCULATE LOSS     |\n",
        "#         # -------------------------\n",
        "\n",
        "#         loss_box = torch.mean((y_bboxes_v2-y_hat_bboxes_v2)**2)\n",
        "#         loss_cls = crossentropy_loss(y_hat_logits_raw_v2, y_labels_int_v2)\n",
        "#         loss = loss_box + loss_cls\n",
        "\n",
        "#         print('loss = loss_box + loss_cs = {}'.format(loss))\n",
        "\n",
        "#         if not torch.isnan(loss):\n",
        "#             loss.requires_grad = True\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             loss_list.append(loss.item())\n",
        "\n",
        "#         # _, predicted = torch.max(y_cls.data, 1)\n",
        "#         # total += labels.size(0)\n",
        "#         # correct += (predicted == labels).sum().item()\n",
        "\n",
        "#         # error_boxes  += torch.mean(torch.abs(y_bboxes-bboxes))\n",
        "\n",
        "#     return sum(loss_list)/len(loss_list)#, correct / total, error_boxes / len(train_loader)"
      ],
      "metadata": {
        "id": "7JIlywHFV48V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation function"
      ],
      "metadata": {
        "id": "cu7vtqgMe5KB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJKg7Dqac0zk"
      },
      "outputs": [],
      "source": [
        "# def val(val_loader, net, beta):\n",
        "#   avg_loss = 0\n",
        "#   correct = 0\n",
        "#   total = 0\n",
        "#   error_boxes = 0\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     for data in val_loader:\n",
        "#         inputs, labels, bboxes = data\n",
        "\n",
        "#         inputs, labels, bboxes = inputs.to(device), labels.to(device), bboxes.to(device)\n",
        "\n",
        "#         boxes, logits, phrases = net(inputs)\n",
        "\n",
        "#         loss_box = torch.mean((y_box-bboxes)**2)*beta\n",
        "#         loss_cls = crossentropy_loss(y_cls, labels)\n",
        "\n",
        "#         loss = loss_box + loss_cls\n",
        "\n",
        "#         avg_loss += loss\n",
        "\n",
        "#         _, predicted = torch.max(y_cls.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#         error_boxes  += torch.mean(torch.abs(y_box-bboxes))\n",
        "\n",
        "\n",
        "#   return avg_loss/len(val_loader), correct / total, error_boxes / len(val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83jpa6CPc7t_"
      },
      "source": [
        "## **Grounding DINO Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom model - Grounding DINO V2"
      ],
      "metadata": {
        "id": "714TAmIhDgVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GroundingDINOV2(nn.Module):\n",
        "    def __init__(self, box_threshold=0.35, text_threshold=0.25):\n",
        "        super(GroundingDINOV2, self).__init__()\n",
        "\n",
        "        self.box_threshold = box_threshold\n",
        "        self.text_threshold = text_threshold\n",
        "\n",
        "        self.basemodel = load_model(CONFIG_PATH, WEIGHTS_PATH)\n",
        "\n",
        "    def basemodel_forward(self, image, caption, remove_combined=False):\n",
        "        outputs = self.basemodel(image[None], captions=[caption])\n",
        "\n",
        "        prediction_logits = outputs[\"pred_logits\"].sigmoid()[0]  # prediction_logits.shape = (nq, 256)\n",
        "        prediction_logits_no_sigmoid = outputs[\"pred_logits\"][0]  # prediction_logits.shape = (nq, 256)\n",
        "        prediction_boxes = outputs[\"pred_boxes\"][0]  # prediction_boxes.shape = (nq, 4)\n",
        "\n",
        "        mask = prediction_logits.max(dim=1)[0] > self.box_threshold\n",
        "        logits = prediction_logits[mask]  # logits.shape = (n, 256)\n",
        "        boxes = prediction_boxes[mask]  # boxes.shape = (n, 4)\n",
        "\n",
        "        logits_raw = prediction_logits[mask]\n",
        "\n",
        "        tokenizer = self.basemodel.tokenizer\n",
        "        tokenized = tokenizer(caption)\n",
        "\n",
        "        if remove_combined:\n",
        "            sep_idx = [i for i in range(len(tokenized['input_ids'])) if tokenized['input_ids'][i] in [101, 102, 1012]]\n",
        "\n",
        "            phrases = []\n",
        "            for logit in logits:\n",
        "                max_idx = logit.argmax()\n",
        "                insert_idx = bisect.bisect_left(sep_idx, max_idx)\n",
        "                right_idx = sep_idx[insert_idx]\n",
        "                left_idx = sep_idx[insert_idx - 1]\n",
        "                phrases.append(get_phrases_from_posmap(logit > self.text_threshold, tokenized, tokenizer, left_idx, right_idx).replace('.', ''))\n",
        "        else:\n",
        "            phrases = [\n",
        "                get_phrases_from_posmap(logit > self.text_threshold, tokenized, tokenizer).replace('.', '')\n",
        "                for logit\n",
        "                in logits\n",
        "            ]\n",
        "\n",
        "        return boxes, logits.max(dim=1)[0], phrases, logits_raw\n",
        "\n",
        "    def forward(self, image, caption='chair.'):\n",
        "        return self.basemodel_forward(image, caption)"
      ],
      "metadata": {
        "id": "33bX9zGCU4EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Grounding DINO V2"
      ],
      "metadata": {
        "id": "SXSbtRGjEOH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run function"
      ],
      "metadata": {
        "id": "Ur0gjcGb7JWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(model, epochs, lr):\n",
        "    print('Starting run function')\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "\n",
        "    epoch_count = 0\n",
        "\n",
        "    for epoch in range(epochs+1):\n",
        "        model = model.train()\n",
        "        train_loss = train(train_loader, model, optimizer)\n",
        "        # train_loss = train(data['train'][1:], model, optimizer)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        epoch_count += 1\n",
        "        print(\"Epoch: {} | Train loss: {}\".format(epoch, train_loss))\n",
        "\n",
        "    return train_losses"
      ],
      "metadata": {
        "id": "a7vBxQ-ZGTpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IoU Function"
      ],
      "metadata": {
        "id": "rx-Z2DZZ7Lr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_IoU(boxA, boxB):\n",
        "\txA = max(boxA[0], boxB[0])\n",
        "\tyA = max(boxA[1], boxB[1])\n",
        "\txB = min(boxA[2], boxB[2])\n",
        "\tyB = min(boxA[3], boxB[3])\n",
        "\n",
        "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "\n",
        "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "\n",
        "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "\treturn iou"
      ],
      "metadata": {
        "id": "JBAvtDW5hPEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IoU_threshold = 0.5\n",
        "\n",
        "y_labels_str = ['bottle', 'painting', 'dog', 'window']\n",
        "\n",
        "y_bboxes = torch.tensor([[0.4808, 0.4615, 0.0745, 0.1466],\n",
        "    [0.5072, 0.2332, 0.1731, 0.1899],\n",
        "    [0.3245, 0.7188, 0.4736, 0.3149],\n",
        "    [0.8582, 0.2812, 0.2572, 0.2933]])\n",
        "\n",
        "\n",
        "y_hat_labels_str = ['window', 'bottle', 'dog', 'dog', 'painting', 'painting']\n",
        "y_hat_bboxes= torch.tensor([[0.8576, 0.2888, 0.2683, 0.3153],\n",
        "    [0.4809, 0.4581, 0.0633, 0.1276],\n",
        "    [0.3189, 0.7199, 0.4825, 0.3303],\n",
        "    [0.2569, 0.5575, 0.3608, 0.2712],\n",
        "    [0.5081, 0.2378, 0.1699, 0.1899],\n",
        "    [0.5000, 0.5017, 0.9996, 0.8149]])\n",
        "\n",
        "\n",
        "for idx, true in enumerate(y_labels_str):\n",
        "    print('\\nTrue label: {} - {}'.format(true, idx))\n",
        "\n",
        "    best_IoU = 0\n",
        "    best_cor_bbox = 0\n",
        "    best_cor_logits = 0\n",
        "\n",
        "    for idx2, pred in enumerate(y_hat_labels_str):\n",
        "        IoU = calc_IoU(y_hat_bboxes[idx2], y_bboxes[idx])\n",
        "        if IoU > best_IoU:\n",
        "            best_IoU = IoU\n",
        "            best_cor_bbox = y_hat_bboxes[idx2]\n",
        "            print('Checking with prediction: {} - {}, IoU: {}'.format(pred, idx2, IoU))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkHYd5B3gn0h",
        "outputId": "07d5db8d-0d34-44cd-fddc-fe51c34b1886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "True label: bottle - 0\n",
            "Checking with prediction: window - 0, IoU: 0.21861384809017181\n",
            "Checking with prediction: bottle - 1, IoU: 0.9491409659385681\n",
            "\n",
            "True label: painting - 1\n",
            "Checking with prediction: window - 0, IoU: 0.3671414256095886\n",
            "Checking with prediction: bottle - 1, IoU: 0.5686933994293213\n",
            "Checking with prediction: painting - 4, IoU: 0.9890643954277039\n",
            "\n",
            "True label: dog - 2\n",
            "Checking with prediction: window - 0, IoU: 0.2840963304042816\n",
            "Checking with prediction: bottle - 1, IoU: 0.2845150828361511\n",
            "Checking with prediction: dog - 2, IoU: 0.9609138369560242\n",
            "\n",
            "True label: window - 3\n",
            "Checking with prediction: window - 0, IoU: 0.9439011812210083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run model"
      ],
      "metadata": {
        "id": "IRnVODXp7P1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GroundingDINOV2()\n",
        "model = model.to(device)\n",
        "initial_parameters = model.state_dict()\n",
        "\n",
        "all_parameters = model.parameters()\n",
        "\n",
        "\n",
        "# for idx, param in enumerate(list(all_parameters)):\n",
        "#     if idx < len(list(all_parameters)) - 1:\n",
        "#         param.requires_grad = False\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for idx, (name, param) in enumerate(model.named_parameters()):\n",
        "    if idx > 827:\n",
        "        param.requires_grad = True\n",
        "\n",
        "    print('{} - {}: {}'.format(idx, name, param.requires_grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "737a48fa72d846d1816c3c7426c2eae6",
            "8d87446db91e4f6dafc2901719893140",
            "5e9ea20a5f294d5bb19f0faaab2bc268",
            "f2cfc1b0d5fe43d89273f26a375de8f4",
            "1f88739868b240d2b3bab0611412a881",
            "de24fa72109541179c57f6b5c66cc795",
            "3150d3a576f147f5b0546f5e76579fed",
            "dbf5fed0371b49c78973e89a90da447b",
            "b436b86abddd467cab22f6eae204c183",
            "26cea3edf5eb4f078a2b9f1676a1e46b",
            "cd45ac1e1f27460498d614b4e2b36f6b",
            "fba7ed9965154a949665b47de71873c0",
            "f2ff0eba58b542d29cbe3bec34dc9b21",
            "73c6d7b70cbd41ffbd8e8c143895ae96",
            "98733a4aab1e46f5a246f6d329e03008",
            "16f4a3e0e8764568999848536e08c792",
            "6b89ac451a854cfcadc120c727f33df3",
            "49a819311bf04dc6b76c5b033ca5b6b5",
            "c7b45196818f47c88fb3839c58746867",
            "695558a2f8d24fb2948b0a2b25f2e79b",
            "55b364725392466582f371ac3c0d89a2",
            "c26057d9f6da4297adba2bca594a93d6",
            "2576b37624fa46e6a70d439311e83000",
            "c7209b18fa864498a00681939cd44578",
            "6f4a8698671f4c5dbd3c3d707c533c4a",
            "c3a969a596a54d9d8acef303173d22b5",
            "9f5d041ced52415687d499ffb320c097",
            "ad1afc2ac48b4a939abff56af701013a",
            "bc8ff3ee72544e6783b66082646f5248",
            "57cdcaa1473c408aa0427ffae4012741",
            "68bd8129a3f540b2aca477df3003fdf7",
            "8c5ddbae1cac478ebc4dc74b227a7d65",
            "831eda6ff3294b05a76ebbad70f4bcee",
            "6cb828d23df24d9492d4d14dadfc3ce3",
            "9f1cbbdccf7c434aa8548fe70705fba7",
            "fc6574bbb55b4bc0afa750bbd4048803",
            "d6aa17eadd0a4cc3bf47733637234a3f",
            "3da49739e8b642898c096015b05c981d",
            "935548d7e4c840b6bea8503dfa1af264",
            "bfa1154152b84377b5db9ab36a87a3db",
            "1812528bae9749c5b059f2de1404aeba",
            "4f8db92ee3554d0e96433d7287525248",
            "4ee475aec82148fa81a3791f5292d9a7",
            "37454c105a9f43d88d243df166c29c99",
            "5006c00fa4b2479b9e6bdad160bae7f2",
            "b5b82a8aff184716b4ba663d589f7919",
            "055a5b178c2d4c8b86910f374b2650d1",
            "158823c117154b5ab9c89302fb9da5ba",
            "8492ddd14606452e9950bc5ecf416d82",
            "de5f354b5a9a43fdb83ebd755d7cadab",
            "964712212eb9469696344f879863ff34",
            "c58caf6e3c644986a3b5f0747070da4c",
            "03533bc094364676bd1dbfeadd6a88ae",
            "bf8f241504a345cd994b96f0629360a1",
            "24ff6ab18784458b862382773c605da3"
          ]
        },
        "id": "ykgby4QRWv5w",
        "outputId": "f856bf3f-ece1-4ded-eea2-4f4cefb44349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final text_encoder_type: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "737a48fa72d846d1816c3c7426c2eae6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fba7ed9965154a949665b47de71873c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2576b37624fa46e6a70d439311e83000"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb828d23df24d9492d4d14dadfc3ce3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5006c00fa4b2479b9e6bdad160bae7f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - basemodel.transformer.level_embed: False\n",
            "1 - basemodel.transformer.encoder.layers.0.self_attn.sampling_offsets.weight: False\n",
            "2 - basemodel.transformer.encoder.layers.0.self_attn.sampling_offsets.bias: False\n",
            "3 - basemodel.transformer.encoder.layers.0.self_attn.attention_weights.weight: False\n",
            "4 - basemodel.transformer.encoder.layers.0.self_attn.attention_weights.bias: False\n",
            "5 - basemodel.transformer.encoder.layers.0.self_attn.value_proj.weight: False\n",
            "6 - basemodel.transformer.encoder.layers.0.self_attn.value_proj.bias: False\n",
            "7 - basemodel.transformer.encoder.layers.0.self_attn.output_proj.weight: False\n",
            "8 - basemodel.transformer.encoder.layers.0.self_attn.output_proj.bias: False\n",
            "9 - basemodel.transformer.encoder.layers.0.norm1.weight: False\n",
            "10 - basemodel.transformer.encoder.layers.0.norm1.bias: False\n",
            "11 - basemodel.transformer.encoder.layers.0.linear1.weight: False\n",
            "12 - basemodel.transformer.encoder.layers.0.linear1.bias: False\n",
            "13 - basemodel.transformer.encoder.layers.0.linear2.weight: False\n",
            "14 - basemodel.transformer.encoder.layers.0.linear2.bias: False\n",
            "15 - basemodel.transformer.encoder.layers.0.norm2.weight: False\n",
            "16 - basemodel.transformer.encoder.layers.0.norm2.bias: False\n",
            "17 - basemodel.transformer.encoder.layers.1.self_attn.sampling_offsets.weight: False\n",
            "18 - basemodel.transformer.encoder.layers.1.self_attn.sampling_offsets.bias: False\n",
            "19 - basemodel.transformer.encoder.layers.1.self_attn.attention_weights.weight: False\n",
            "20 - basemodel.transformer.encoder.layers.1.self_attn.attention_weights.bias: False\n",
            "21 - basemodel.transformer.encoder.layers.1.self_attn.value_proj.weight: False\n",
            "22 - basemodel.transformer.encoder.layers.1.self_attn.value_proj.bias: False\n",
            "23 - basemodel.transformer.encoder.layers.1.self_attn.output_proj.weight: False\n",
            "24 - basemodel.transformer.encoder.layers.1.self_attn.output_proj.bias: False\n",
            "25 - basemodel.transformer.encoder.layers.1.norm1.weight: False\n",
            "26 - basemodel.transformer.encoder.layers.1.norm1.bias: False\n",
            "27 - basemodel.transformer.encoder.layers.1.linear1.weight: False\n",
            "28 - basemodel.transformer.encoder.layers.1.linear1.bias: False\n",
            "29 - basemodel.transformer.encoder.layers.1.linear2.weight: False\n",
            "30 - basemodel.transformer.encoder.layers.1.linear2.bias: False\n",
            "31 - basemodel.transformer.encoder.layers.1.norm2.weight: False\n",
            "32 - basemodel.transformer.encoder.layers.1.norm2.bias: False\n",
            "33 - basemodel.transformer.encoder.layers.2.self_attn.sampling_offsets.weight: False\n",
            "34 - basemodel.transformer.encoder.layers.2.self_attn.sampling_offsets.bias: False\n",
            "35 - basemodel.transformer.encoder.layers.2.self_attn.attention_weights.weight: False\n",
            "36 - basemodel.transformer.encoder.layers.2.self_attn.attention_weights.bias: False\n",
            "37 - basemodel.transformer.encoder.layers.2.self_attn.value_proj.weight: False\n",
            "38 - basemodel.transformer.encoder.layers.2.self_attn.value_proj.bias: False\n",
            "39 - basemodel.transformer.encoder.layers.2.self_attn.output_proj.weight: False\n",
            "40 - basemodel.transformer.encoder.layers.2.self_attn.output_proj.bias: False\n",
            "41 - basemodel.transformer.encoder.layers.2.norm1.weight: False\n",
            "42 - basemodel.transformer.encoder.layers.2.norm1.bias: False\n",
            "43 - basemodel.transformer.encoder.layers.2.linear1.weight: False\n",
            "44 - basemodel.transformer.encoder.layers.2.linear1.bias: False\n",
            "45 - basemodel.transformer.encoder.layers.2.linear2.weight: False\n",
            "46 - basemodel.transformer.encoder.layers.2.linear2.bias: False\n",
            "47 - basemodel.transformer.encoder.layers.2.norm2.weight: False\n",
            "48 - basemodel.transformer.encoder.layers.2.norm2.bias: False\n",
            "49 - basemodel.transformer.encoder.layers.3.self_attn.sampling_offsets.weight: False\n",
            "50 - basemodel.transformer.encoder.layers.3.self_attn.sampling_offsets.bias: False\n",
            "51 - basemodel.transformer.encoder.layers.3.self_attn.attention_weights.weight: False\n",
            "52 - basemodel.transformer.encoder.layers.3.self_attn.attention_weights.bias: False\n",
            "53 - basemodel.transformer.encoder.layers.3.self_attn.value_proj.weight: False\n",
            "54 - basemodel.transformer.encoder.layers.3.self_attn.value_proj.bias: False\n",
            "55 - basemodel.transformer.encoder.layers.3.self_attn.output_proj.weight: False\n",
            "56 - basemodel.transformer.encoder.layers.3.self_attn.output_proj.bias: False\n",
            "57 - basemodel.transformer.encoder.layers.3.norm1.weight: False\n",
            "58 - basemodel.transformer.encoder.layers.3.norm1.bias: False\n",
            "59 - basemodel.transformer.encoder.layers.3.linear1.weight: False\n",
            "60 - basemodel.transformer.encoder.layers.3.linear1.bias: False\n",
            "61 - basemodel.transformer.encoder.layers.3.linear2.weight: False\n",
            "62 - basemodel.transformer.encoder.layers.3.linear2.bias: False\n",
            "63 - basemodel.transformer.encoder.layers.3.norm2.weight: False\n",
            "64 - basemodel.transformer.encoder.layers.3.norm2.bias: False\n",
            "65 - basemodel.transformer.encoder.layers.4.self_attn.sampling_offsets.weight: False\n",
            "66 - basemodel.transformer.encoder.layers.4.self_attn.sampling_offsets.bias: False\n",
            "67 - basemodel.transformer.encoder.layers.4.self_attn.attention_weights.weight: False\n",
            "68 - basemodel.transformer.encoder.layers.4.self_attn.attention_weights.bias: False\n",
            "69 - basemodel.transformer.encoder.layers.4.self_attn.value_proj.weight: False\n",
            "70 - basemodel.transformer.encoder.layers.4.self_attn.value_proj.bias: False\n",
            "71 - basemodel.transformer.encoder.layers.4.self_attn.output_proj.weight: False\n",
            "72 - basemodel.transformer.encoder.layers.4.self_attn.output_proj.bias: False\n",
            "73 - basemodel.transformer.encoder.layers.4.norm1.weight: False\n",
            "74 - basemodel.transformer.encoder.layers.4.norm1.bias: False\n",
            "75 - basemodel.transformer.encoder.layers.4.linear1.weight: False\n",
            "76 - basemodel.transformer.encoder.layers.4.linear1.bias: False\n",
            "77 - basemodel.transformer.encoder.layers.4.linear2.weight: False\n",
            "78 - basemodel.transformer.encoder.layers.4.linear2.bias: False\n",
            "79 - basemodel.transformer.encoder.layers.4.norm2.weight: False\n",
            "80 - basemodel.transformer.encoder.layers.4.norm2.bias: False\n",
            "81 - basemodel.transformer.encoder.layers.5.self_attn.sampling_offsets.weight: False\n",
            "82 - basemodel.transformer.encoder.layers.5.self_attn.sampling_offsets.bias: False\n",
            "83 - basemodel.transformer.encoder.layers.5.self_attn.attention_weights.weight: False\n",
            "84 - basemodel.transformer.encoder.layers.5.self_attn.attention_weights.bias: False\n",
            "85 - basemodel.transformer.encoder.layers.5.self_attn.value_proj.weight: False\n",
            "86 - basemodel.transformer.encoder.layers.5.self_attn.value_proj.bias: False\n",
            "87 - basemodel.transformer.encoder.layers.5.self_attn.output_proj.weight: False\n",
            "88 - basemodel.transformer.encoder.layers.5.self_attn.output_proj.bias: False\n",
            "89 - basemodel.transformer.encoder.layers.5.norm1.weight: False\n",
            "90 - basemodel.transformer.encoder.layers.5.norm1.bias: False\n",
            "91 - basemodel.transformer.encoder.layers.5.linear1.weight: False\n",
            "92 - basemodel.transformer.encoder.layers.5.linear1.bias: False\n",
            "93 - basemodel.transformer.encoder.layers.5.linear2.weight: False\n",
            "94 - basemodel.transformer.encoder.layers.5.linear2.bias: False\n",
            "95 - basemodel.transformer.encoder.layers.5.norm2.weight: False\n",
            "96 - basemodel.transformer.encoder.layers.5.norm2.bias: False\n",
            "97 - basemodel.transformer.encoder.text_layers.0.self_attn.in_proj_weight: False\n",
            "98 - basemodel.transformer.encoder.text_layers.0.self_attn.in_proj_bias: False\n",
            "99 - basemodel.transformer.encoder.text_layers.0.self_attn.out_proj.weight: False\n",
            "100 - basemodel.transformer.encoder.text_layers.0.self_attn.out_proj.bias: False\n",
            "101 - basemodel.transformer.encoder.text_layers.0.linear1.weight: False\n",
            "102 - basemodel.transformer.encoder.text_layers.0.linear1.bias: False\n",
            "103 - basemodel.transformer.encoder.text_layers.0.linear2.weight: False\n",
            "104 - basemodel.transformer.encoder.text_layers.0.linear2.bias: False\n",
            "105 - basemodel.transformer.encoder.text_layers.0.norm1.weight: False\n",
            "106 - basemodel.transformer.encoder.text_layers.0.norm1.bias: False\n",
            "107 - basemodel.transformer.encoder.text_layers.0.norm2.weight: False\n",
            "108 - basemodel.transformer.encoder.text_layers.0.norm2.bias: False\n",
            "109 - basemodel.transformer.encoder.text_layers.1.self_attn.in_proj_weight: False\n",
            "110 - basemodel.transformer.encoder.text_layers.1.self_attn.in_proj_bias: False\n",
            "111 - basemodel.transformer.encoder.text_layers.1.self_attn.out_proj.weight: False\n",
            "112 - basemodel.transformer.encoder.text_layers.1.self_attn.out_proj.bias: False\n",
            "113 - basemodel.transformer.encoder.text_layers.1.linear1.weight: False\n",
            "114 - basemodel.transformer.encoder.text_layers.1.linear1.bias: False\n",
            "115 - basemodel.transformer.encoder.text_layers.1.linear2.weight: False\n",
            "116 - basemodel.transformer.encoder.text_layers.1.linear2.bias: False\n",
            "117 - basemodel.transformer.encoder.text_layers.1.norm1.weight: False\n",
            "118 - basemodel.transformer.encoder.text_layers.1.norm1.bias: False\n",
            "119 - basemodel.transformer.encoder.text_layers.1.norm2.weight: False\n",
            "120 - basemodel.transformer.encoder.text_layers.1.norm2.bias: False\n",
            "121 - basemodel.transformer.encoder.text_layers.2.self_attn.in_proj_weight: False\n",
            "122 - basemodel.transformer.encoder.text_layers.2.self_attn.in_proj_bias: False\n",
            "123 - basemodel.transformer.encoder.text_layers.2.self_attn.out_proj.weight: False\n",
            "124 - basemodel.transformer.encoder.text_layers.2.self_attn.out_proj.bias: False\n",
            "125 - basemodel.transformer.encoder.text_layers.2.linear1.weight: False\n",
            "126 - basemodel.transformer.encoder.text_layers.2.linear1.bias: False\n",
            "127 - basemodel.transformer.encoder.text_layers.2.linear2.weight: False\n",
            "128 - basemodel.transformer.encoder.text_layers.2.linear2.bias: False\n",
            "129 - basemodel.transformer.encoder.text_layers.2.norm1.weight: False\n",
            "130 - basemodel.transformer.encoder.text_layers.2.norm1.bias: False\n",
            "131 - basemodel.transformer.encoder.text_layers.2.norm2.weight: False\n",
            "132 - basemodel.transformer.encoder.text_layers.2.norm2.bias: False\n",
            "133 - basemodel.transformer.encoder.text_layers.3.self_attn.in_proj_weight: False\n",
            "134 - basemodel.transformer.encoder.text_layers.3.self_attn.in_proj_bias: False\n",
            "135 - basemodel.transformer.encoder.text_layers.3.self_attn.out_proj.weight: False\n",
            "136 - basemodel.transformer.encoder.text_layers.3.self_attn.out_proj.bias: False\n",
            "137 - basemodel.transformer.encoder.text_layers.3.linear1.weight: False\n",
            "138 - basemodel.transformer.encoder.text_layers.3.linear1.bias: False\n",
            "139 - basemodel.transformer.encoder.text_layers.3.linear2.weight: False\n",
            "140 - basemodel.transformer.encoder.text_layers.3.linear2.bias: False\n",
            "141 - basemodel.transformer.encoder.text_layers.3.norm1.weight: False\n",
            "142 - basemodel.transformer.encoder.text_layers.3.norm1.bias: False\n",
            "143 - basemodel.transformer.encoder.text_layers.3.norm2.weight: False\n",
            "144 - basemodel.transformer.encoder.text_layers.3.norm2.bias: False\n",
            "145 - basemodel.transformer.encoder.text_layers.4.self_attn.in_proj_weight: False\n",
            "146 - basemodel.transformer.encoder.text_layers.4.self_attn.in_proj_bias: False\n",
            "147 - basemodel.transformer.encoder.text_layers.4.self_attn.out_proj.weight: False\n",
            "148 - basemodel.transformer.encoder.text_layers.4.self_attn.out_proj.bias: False\n",
            "149 - basemodel.transformer.encoder.text_layers.4.linear1.weight: False\n",
            "150 - basemodel.transformer.encoder.text_layers.4.linear1.bias: False\n",
            "151 - basemodel.transformer.encoder.text_layers.4.linear2.weight: False\n",
            "152 - basemodel.transformer.encoder.text_layers.4.linear2.bias: False\n",
            "153 - basemodel.transformer.encoder.text_layers.4.norm1.weight: False\n",
            "154 - basemodel.transformer.encoder.text_layers.4.norm1.bias: False\n",
            "155 - basemodel.transformer.encoder.text_layers.4.norm2.weight: False\n",
            "156 - basemodel.transformer.encoder.text_layers.4.norm2.bias: False\n",
            "157 - basemodel.transformer.encoder.text_layers.5.self_attn.in_proj_weight: False\n",
            "158 - basemodel.transformer.encoder.text_layers.5.self_attn.in_proj_bias: False\n",
            "159 - basemodel.transformer.encoder.text_layers.5.self_attn.out_proj.weight: False\n",
            "160 - basemodel.transformer.encoder.text_layers.5.self_attn.out_proj.bias: False\n",
            "161 - basemodel.transformer.encoder.text_layers.5.linear1.weight: False\n",
            "162 - basemodel.transformer.encoder.text_layers.5.linear1.bias: False\n",
            "163 - basemodel.transformer.encoder.text_layers.5.linear2.weight: False\n",
            "164 - basemodel.transformer.encoder.text_layers.5.linear2.bias: False\n",
            "165 - basemodel.transformer.encoder.text_layers.5.norm1.weight: False\n",
            "166 - basemodel.transformer.encoder.text_layers.5.norm1.bias: False\n",
            "167 - basemodel.transformer.encoder.text_layers.5.norm2.weight: False\n",
            "168 - basemodel.transformer.encoder.text_layers.5.norm2.bias: False\n",
            "169 - basemodel.transformer.encoder.fusion_layers.0.gamma_v: False\n",
            "170 - basemodel.transformer.encoder.fusion_layers.0.gamma_l: False\n",
            "171 - basemodel.transformer.encoder.fusion_layers.0.layer_norm_v.weight: False\n",
            "172 - basemodel.transformer.encoder.fusion_layers.0.layer_norm_v.bias: False\n",
            "173 - basemodel.transformer.encoder.fusion_layers.0.layer_norm_l.weight: False\n",
            "174 - basemodel.transformer.encoder.fusion_layers.0.layer_norm_l.bias: False\n",
            "175 - basemodel.transformer.encoder.fusion_layers.0.attn.v_proj.weight: False\n",
            "176 - basemodel.transformer.encoder.fusion_layers.0.attn.v_proj.bias: False\n",
            "177 - basemodel.transformer.encoder.fusion_layers.0.attn.l_proj.weight: False\n",
            "178 - basemodel.transformer.encoder.fusion_layers.0.attn.l_proj.bias: False\n",
            "179 - basemodel.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight: False\n",
            "180 - basemodel.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias: False\n",
            "181 - basemodel.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight: False\n",
            "182 - basemodel.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias: False\n",
            "183 - basemodel.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight: False\n",
            "184 - basemodel.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias: False\n",
            "185 - basemodel.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight: False\n",
            "186 - basemodel.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias: False\n",
            "187 - basemodel.transformer.encoder.fusion_layers.1.gamma_v: False\n",
            "188 - basemodel.transformer.encoder.fusion_layers.1.gamma_l: False\n",
            "189 - basemodel.transformer.encoder.fusion_layers.1.layer_norm_v.weight: False\n",
            "190 - basemodel.transformer.encoder.fusion_layers.1.layer_norm_v.bias: False\n",
            "191 - basemodel.transformer.encoder.fusion_layers.1.layer_norm_l.weight: False\n",
            "192 - basemodel.transformer.encoder.fusion_layers.1.layer_norm_l.bias: False\n",
            "193 - basemodel.transformer.encoder.fusion_layers.1.attn.v_proj.weight: False\n",
            "194 - basemodel.transformer.encoder.fusion_layers.1.attn.v_proj.bias: False\n",
            "195 - basemodel.transformer.encoder.fusion_layers.1.attn.l_proj.weight: False\n",
            "196 - basemodel.transformer.encoder.fusion_layers.1.attn.l_proj.bias: False\n",
            "197 - basemodel.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight: False\n",
            "198 - basemodel.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias: False\n",
            "199 - basemodel.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight: False\n",
            "200 - basemodel.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias: False\n",
            "201 - basemodel.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight: False\n",
            "202 - basemodel.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias: False\n",
            "203 - basemodel.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight: False\n",
            "204 - basemodel.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias: False\n",
            "205 - basemodel.transformer.encoder.fusion_layers.2.gamma_v: False\n",
            "206 - basemodel.transformer.encoder.fusion_layers.2.gamma_l: False\n",
            "207 - basemodel.transformer.encoder.fusion_layers.2.layer_norm_v.weight: False\n",
            "208 - basemodel.transformer.encoder.fusion_layers.2.layer_norm_v.bias: False\n",
            "209 - basemodel.transformer.encoder.fusion_layers.2.layer_norm_l.weight: False\n",
            "210 - basemodel.transformer.encoder.fusion_layers.2.layer_norm_l.bias: False\n",
            "211 - basemodel.transformer.encoder.fusion_layers.2.attn.v_proj.weight: False\n",
            "212 - basemodel.transformer.encoder.fusion_layers.2.attn.v_proj.bias: False\n",
            "213 - basemodel.transformer.encoder.fusion_layers.2.attn.l_proj.weight: False\n",
            "214 - basemodel.transformer.encoder.fusion_layers.2.attn.l_proj.bias: False\n",
            "215 - basemodel.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight: False\n",
            "216 - basemodel.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias: False\n",
            "217 - basemodel.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight: False\n",
            "218 - basemodel.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias: False\n",
            "219 - basemodel.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight: False\n",
            "220 - basemodel.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias: False\n",
            "221 - basemodel.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight: False\n",
            "222 - basemodel.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias: False\n",
            "223 - basemodel.transformer.encoder.fusion_layers.3.gamma_v: False\n",
            "224 - basemodel.transformer.encoder.fusion_layers.3.gamma_l: False\n",
            "225 - basemodel.transformer.encoder.fusion_layers.3.layer_norm_v.weight: False\n",
            "226 - basemodel.transformer.encoder.fusion_layers.3.layer_norm_v.bias: False\n",
            "227 - basemodel.transformer.encoder.fusion_layers.3.layer_norm_l.weight: False\n",
            "228 - basemodel.transformer.encoder.fusion_layers.3.layer_norm_l.bias: False\n",
            "229 - basemodel.transformer.encoder.fusion_layers.3.attn.v_proj.weight: False\n",
            "230 - basemodel.transformer.encoder.fusion_layers.3.attn.v_proj.bias: False\n",
            "231 - basemodel.transformer.encoder.fusion_layers.3.attn.l_proj.weight: False\n",
            "232 - basemodel.transformer.encoder.fusion_layers.3.attn.l_proj.bias: False\n",
            "233 - basemodel.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight: False\n",
            "234 - basemodel.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias: False\n",
            "235 - basemodel.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight: False\n",
            "236 - basemodel.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias: False\n",
            "237 - basemodel.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight: False\n",
            "238 - basemodel.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias: False\n",
            "239 - basemodel.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight: False\n",
            "240 - basemodel.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias: False\n",
            "241 - basemodel.transformer.encoder.fusion_layers.4.gamma_v: False\n",
            "242 - basemodel.transformer.encoder.fusion_layers.4.gamma_l: False\n",
            "243 - basemodel.transformer.encoder.fusion_layers.4.layer_norm_v.weight: False\n",
            "244 - basemodel.transformer.encoder.fusion_layers.4.layer_norm_v.bias: False\n",
            "245 - basemodel.transformer.encoder.fusion_layers.4.layer_norm_l.weight: False\n",
            "246 - basemodel.transformer.encoder.fusion_layers.4.layer_norm_l.bias: False\n",
            "247 - basemodel.transformer.encoder.fusion_layers.4.attn.v_proj.weight: False\n",
            "248 - basemodel.transformer.encoder.fusion_layers.4.attn.v_proj.bias: False\n",
            "249 - basemodel.transformer.encoder.fusion_layers.4.attn.l_proj.weight: False\n",
            "250 - basemodel.transformer.encoder.fusion_layers.4.attn.l_proj.bias: False\n",
            "251 - basemodel.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight: False\n",
            "252 - basemodel.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias: False\n",
            "253 - basemodel.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight: False\n",
            "254 - basemodel.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias: False\n",
            "255 - basemodel.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight: False\n",
            "256 - basemodel.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias: False\n",
            "257 - basemodel.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight: False\n",
            "258 - basemodel.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias: False\n",
            "259 - basemodel.transformer.encoder.fusion_layers.5.gamma_v: False\n",
            "260 - basemodel.transformer.encoder.fusion_layers.5.gamma_l: False\n",
            "261 - basemodel.transformer.encoder.fusion_layers.5.layer_norm_v.weight: False\n",
            "262 - basemodel.transformer.encoder.fusion_layers.5.layer_norm_v.bias: False\n",
            "263 - basemodel.transformer.encoder.fusion_layers.5.layer_norm_l.weight: False\n",
            "264 - basemodel.transformer.encoder.fusion_layers.5.layer_norm_l.bias: False\n",
            "265 - basemodel.transformer.encoder.fusion_layers.5.attn.v_proj.weight: False\n",
            "266 - basemodel.transformer.encoder.fusion_layers.5.attn.v_proj.bias: False\n",
            "267 - basemodel.transformer.encoder.fusion_layers.5.attn.l_proj.weight: False\n",
            "268 - basemodel.transformer.encoder.fusion_layers.5.attn.l_proj.bias: False\n",
            "269 - basemodel.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight: False\n",
            "270 - basemodel.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias: False\n",
            "271 - basemodel.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight: False\n",
            "272 - basemodel.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias: False\n",
            "273 - basemodel.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight: False\n",
            "274 - basemodel.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias: False\n",
            "275 - basemodel.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight: False\n",
            "276 - basemodel.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias: False\n",
            "277 - basemodel.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight: False\n",
            "278 - basemodel.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias: False\n",
            "279 - basemodel.transformer.decoder.layers.0.cross_attn.attention_weights.weight: False\n",
            "280 - basemodel.transformer.decoder.layers.0.cross_attn.attention_weights.bias: False\n",
            "281 - basemodel.transformer.decoder.layers.0.cross_attn.value_proj.weight: False\n",
            "282 - basemodel.transformer.decoder.layers.0.cross_attn.value_proj.bias: False\n",
            "283 - basemodel.transformer.decoder.layers.0.cross_attn.output_proj.weight: False\n",
            "284 - basemodel.transformer.decoder.layers.0.cross_attn.output_proj.bias: False\n",
            "285 - basemodel.transformer.decoder.layers.0.norm1.weight: False\n",
            "286 - basemodel.transformer.decoder.layers.0.norm1.bias: False\n",
            "287 - basemodel.transformer.decoder.layers.0.ca_text.in_proj_weight: False\n",
            "288 - basemodel.transformer.decoder.layers.0.ca_text.in_proj_bias: False\n",
            "289 - basemodel.transformer.decoder.layers.0.ca_text.out_proj.weight: False\n",
            "290 - basemodel.transformer.decoder.layers.0.ca_text.out_proj.bias: False\n",
            "291 - basemodel.transformer.decoder.layers.0.catext_norm.weight: False\n",
            "292 - basemodel.transformer.decoder.layers.0.catext_norm.bias: False\n",
            "293 - basemodel.transformer.decoder.layers.0.self_attn.in_proj_weight: False\n",
            "294 - basemodel.transformer.decoder.layers.0.self_attn.in_proj_bias: False\n",
            "295 - basemodel.transformer.decoder.layers.0.self_attn.out_proj.weight: False\n",
            "296 - basemodel.transformer.decoder.layers.0.self_attn.out_proj.bias: False\n",
            "297 - basemodel.transformer.decoder.layers.0.norm2.weight: False\n",
            "298 - basemodel.transformer.decoder.layers.0.norm2.bias: False\n",
            "299 - basemodel.transformer.decoder.layers.0.linear1.weight: False\n",
            "300 - basemodel.transformer.decoder.layers.0.linear1.bias: False\n",
            "301 - basemodel.transformer.decoder.layers.0.linear2.weight: False\n",
            "302 - basemodel.transformer.decoder.layers.0.linear2.bias: False\n",
            "303 - basemodel.transformer.decoder.layers.0.norm3.weight: False\n",
            "304 - basemodel.transformer.decoder.layers.0.norm3.bias: False\n",
            "305 - basemodel.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight: False\n",
            "306 - basemodel.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias: False\n",
            "307 - basemodel.transformer.decoder.layers.1.cross_attn.attention_weights.weight: False\n",
            "308 - basemodel.transformer.decoder.layers.1.cross_attn.attention_weights.bias: False\n",
            "309 - basemodel.transformer.decoder.layers.1.cross_attn.value_proj.weight: False\n",
            "310 - basemodel.transformer.decoder.layers.1.cross_attn.value_proj.bias: False\n",
            "311 - basemodel.transformer.decoder.layers.1.cross_attn.output_proj.weight: False\n",
            "312 - basemodel.transformer.decoder.layers.1.cross_attn.output_proj.bias: False\n",
            "313 - basemodel.transformer.decoder.layers.1.norm1.weight: False\n",
            "314 - basemodel.transformer.decoder.layers.1.norm1.bias: False\n",
            "315 - basemodel.transformer.decoder.layers.1.ca_text.in_proj_weight: False\n",
            "316 - basemodel.transformer.decoder.layers.1.ca_text.in_proj_bias: False\n",
            "317 - basemodel.transformer.decoder.layers.1.ca_text.out_proj.weight: False\n",
            "318 - basemodel.transformer.decoder.layers.1.ca_text.out_proj.bias: False\n",
            "319 - basemodel.transformer.decoder.layers.1.catext_norm.weight: False\n",
            "320 - basemodel.transformer.decoder.layers.1.catext_norm.bias: False\n",
            "321 - basemodel.transformer.decoder.layers.1.self_attn.in_proj_weight: False\n",
            "322 - basemodel.transformer.decoder.layers.1.self_attn.in_proj_bias: False\n",
            "323 - basemodel.transformer.decoder.layers.1.self_attn.out_proj.weight: False\n",
            "324 - basemodel.transformer.decoder.layers.1.self_attn.out_proj.bias: False\n",
            "325 - basemodel.transformer.decoder.layers.1.norm2.weight: False\n",
            "326 - basemodel.transformer.decoder.layers.1.norm2.bias: False\n",
            "327 - basemodel.transformer.decoder.layers.1.linear1.weight: False\n",
            "328 - basemodel.transformer.decoder.layers.1.linear1.bias: False\n",
            "329 - basemodel.transformer.decoder.layers.1.linear2.weight: False\n",
            "330 - basemodel.transformer.decoder.layers.1.linear2.bias: False\n",
            "331 - basemodel.transformer.decoder.layers.1.norm3.weight: False\n",
            "332 - basemodel.transformer.decoder.layers.1.norm3.bias: False\n",
            "333 - basemodel.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight: False\n",
            "334 - basemodel.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias: False\n",
            "335 - basemodel.transformer.decoder.layers.2.cross_attn.attention_weights.weight: False\n",
            "336 - basemodel.transformer.decoder.layers.2.cross_attn.attention_weights.bias: False\n",
            "337 - basemodel.transformer.decoder.layers.2.cross_attn.value_proj.weight: False\n",
            "338 - basemodel.transformer.decoder.layers.2.cross_attn.value_proj.bias: False\n",
            "339 - basemodel.transformer.decoder.layers.2.cross_attn.output_proj.weight: False\n",
            "340 - basemodel.transformer.decoder.layers.2.cross_attn.output_proj.bias: False\n",
            "341 - basemodel.transformer.decoder.layers.2.norm1.weight: False\n",
            "342 - basemodel.transformer.decoder.layers.2.norm1.bias: False\n",
            "343 - basemodel.transformer.decoder.layers.2.ca_text.in_proj_weight: False\n",
            "344 - basemodel.transformer.decoder.layers.2.ca_text.in_proj_bias: False\n",
            "345 - basemodel.transformer.decoder.layers.2.ca_text.out_proj.weight: False\n",
            "346 - basemodel.transformer.decoder.layers.2.ca_text.out_proj.bias: False\n",
            "347 - basemodel.transformer.decoder.layers.2.catext_norm.weight: False\n",
            "348 - basemodel.transformer.decoder.layers.2.catext_norm.bias: False\n",
            "349 - basemodel.transformer.decoder.layers.2.self_attn.in_proj_weight: False\n",
            "350 - basemodel.transformer.decoder.layers.2.self_attn.in_proj_bias: False\n",
            "351 - basemodel.transformer.decoder.layers.2.self_attn.out_proj.weight: False\n",
            "352 - basemodel.transformer.decoder.layers.2.self_attn.out_proj.bias: False\n",
            "353 - basemodel.transformer.decoder.layers.2.norm2.weight: False\n",
            "354 - basemodel.transformer.decoder.layers.2.norm2.bias: False\n",
            "355 - basemodel.transformer.decoder.layers.2.linear1.weight: False\n",
            "356 - basemodel.transformer.decoder.layers.2.linear1.bias: False\n",
            "357 - basemodel.transformer.decoder.layers.2.linear2.weight: False\n",
            "358 - basemodel.transformer.decoder.layers.2.linear2.bias: False\n",
            "359 - basemodel.transformer.decoder.layers.2.norm3.weight: False\n",
            "360 - basemodel.transformer.decoder.layers.2.norm3.bias: False\n",
            "361 - basemodel.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight: False\n",
            "362 - basemodel.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias: False\n",
            "363 - basemodel.transformer.decoder.layers.3.cross_attn.attention_weights.weight: False\n",
            "364 - basemodel.transformer.decoder.layers.3.cross_attn.attention_weights.bias: False\n",
            "365 - basemodel.transformer.decoder.layers.3.cross_attn.value_proj.weight: False\n",
            "366 - basemodel.transformer.decoder.layers.3.cross_attn.value_proj.bias: False\n",
            "367 - basemodel.transformer.decoder.layers.3.cross_attn.output_proj.weight: False\n",
            "368 - basemodel.transformer.decoder.layers.3.cross_attn.output_proj.bias: False\n",
            "369 - basemodel.transformer.decoder.layers.3.norm1.weight: False\n",
            "370 - basemodel.transformer.decoder.layers.3.norm1.bias: False\n",
            "371 - basemodel.transformer.decoder.layers.3.ca_text.in_proj_weight: False\n",
            "372 - basemodel.transformer.decoder.layers.3.ca_text.in_proj_bias: False\n",
            "373 - basemodel.transformer.decoder.layers.3.ca_text.out_proj.weight: False\n",
            "374 - basemodel.transformer.decoder.layers.3.ca_text.out_proj.bias: False\n",
            "375 - basemodel.transformer.decoder.layers.3.catext_norm.weight: False\n",
            "376 - basemodel.transformer.decoder.layers.3.catext_norm.bias: False\n",
            "377 - basemodel.transformer.decoder.layers.3.self_attn.in_proj_weight: False\n",
            "378 - basemodel.transformer.decoder.layers.3.self_attn.in_proj_bias: False\n",
            "379 - basemodel.transformer.decoder.layers.3.self_attn.out_proj.weight: False\n",
            "380 - basemodel.transformer.decoder.layers.3.self_attn.out_proj.bias: False\n",
            "381 - basemodel.transformer.decoder.layers.3.norm2.weight: False\n",
            "382 - basemodel.transformer.decoder.layers.3.norm2.bias: False\n",
            "383 - basemodel.transformer.decoder.layers.3.linear1.weight: False\n",
            "384 - basemodel.transformer.decoder.layers.3.linear1.bias: False\n",
            "385 - basemodel.transformer.decoder.layers.3.linear2.weight: False\n",
            "386 - basemodel.transformer.decoder.layers.3.linear2.bias: False\n",
            "387 - basemodel.transformer.decoder.layers.3.norm3.weight: False\n",
            "388 - basemodel.transformer.decoder.layers.3.norm3.bias: False\n",
            "389 - basemodel.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight: False\n",
            "390 - basemodel.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias: False\n",
            "391 - basemodel.transformer.decoder.layers.4.cross_attn.attention_weights.weight: False\n",
            "392 - basemodel.transformer.decoder.layers.4.cross_attn.attention_weights.bias: False\n",
            "393 - basemodel.transformer.decoder.layers.4.cross_attn.value_proj.weight: False\n",
            "394 - basemodel.transformer.decoder.layers.4.cross_attn.value_proj.bias: False\n",
            "395 - basemodel.transformer.decoder.layers.4.cross_attn.output_proj.weight: False\n",
            "396 - basemodel.transformer.decoder.layers.4.cross_attn.output_proj.bias: False\n",
            "397 - basemodel.transformer.decoder.layers.4.norm1.weight: False\n",
            "398 - basemodel.transformer.decoder.layers.4.norm1.bias: False\n",
            "399 - basemodel.transformer.decoder.layers.4.ca_text.in_proj_weight: False\n",
            "400 - basemodel.transformer.decoder.layers.4.ca_text.in_proj_bias: False\n",
            "401 - basemodel.transformer.decoder.layers.4.ca_text.out_proj.weight: False\n",
            "402 - basemodel.transformer.decoder.layers.4.ca_text.out_proj.bias: False\n",
            "403 - basemodel.transformer.decoder.layers.4.catext_norm.weight: False\n",
            "404 - basemodel.transformer.decoder.layers.4.catext_norm.bias: False\n",
            "405 - basemodel.transformer.decoder.layers.4.self_attn.in_proj_weight: False\n",
            "406 - basemodel.transformer.decoder.layers.4.self_attn.in_proj_bias: False\n",
            "407 - basemodel.transformer.decoder.layers.4.self_attn.out_proj.weight: False\n",
            "408 - basemodel.transformer.decoder.layers.4.self_attn.out_proj.bias: False\n",
            "409 - basemodel.transformer.decoder.layers.4.norm2.weight: False\n",
            "410 - basemodel.transformer.decoder.layers.4.norm2.bias: False\n",
            "411 - basemodel.transformer.decoder.layers.4.linear1.weight: False\n",
            "412 - basemodel.transformer.decoder.layers.4.linear1.bias: False\n",
            "413 - basemodel.transformer.decoder.layers.4.linear2.weight: False\n",
            "414 - basemodel.transformer.decoder.layers.4.linear2.bias: False\n",
            "415 - basemodel.transformer.decoder.layers.4.norm3.weight: False\n",
            "416 - basemodel.transformer.decoder.layers.4.norm3.bias: False\n",
            "417 - basemodel.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight: False\n",
            "418 - basemodel.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias: False\n",
            "419 - basemodel.transformer.decoder.layers.5.cross_attn.attention_weights.weight: False\n",
            "420 - basemodel.transformer.decoder.layers.5.cross_attn.attention_weights.bias: False\n",
            "421 - basemodel.transformer.decoder.layers.5.cross_attn.value_proj.weight: False\n",
            "422 - basemodel.transformer.decoder.layers.5.cross_attn.value_proj.bias: False\n",
            "423 - basemodel.transformer.decoder.layers.5.cross_attn.output_proj.weight: False\n",
            "424 - basemodel.transformer.decoder.layers.5.cross_attn.output_proj.bias: False\n",
            "425 - basemodel.transformer.decoder.layers.5.norm1.weight: False\n",
            "426 - basemodel.transformer.decoder.layers.5.norm1.bias: False\n",
            "427 - basemodel.transformer.decoder.layers.5.ca_text.in_proj_weight: False\n",
            "428 - basemodel.transformer.decoder.layers.5.ca_text.in_proj_bias: False\n",
            "429 - basemodel.transformer.decoder.layers.5.ca_text.out_proj.weight: False\n",
            "430 - basemodel.transformer.decoder.layers.5.ca_text.out_proj.bias: False\n",
            "431 - basemodel.transformer.decoder.layers.5.catext_norm.weight: False\n",
            "432 - basemodel.transformer.decoder.layers.5.catext_norm.bias: False\n",
            "433 - basemodel.transformer.decoder.layers.5.self_attn.in_proj_weight: False\n",
            "434 - basemodel.transformer.decoder.layers.5.self_attn.in_proj_bias: False\n",
            "435 - basemodel.transformer.decoder.layers.5.self_attn.out_proj.weight: False\n",
            "436 - basemodel.transformer.decoder.layers.5.self_attn.out_proj.bias: False\n",
            "437 - basemodel.transformer.decoder.layers.5.norm2.weight: False\n",
            "438 - basemodel.transformer.decoder.layers.5.norm2.bias: False\n",
            "439 - basemodel.transformer.decoder.layers.5.linear1.weight: False\n",
            "440 - basemodel.transformer.decoder.layers.5.linear1.bias: False\n",
            "441 - basemodel.transformer.decoder.layers.5.linear2.weight: False\n",
            "442 - basemodel.transformer.decoder.layers.5.linear2.bias: False\n",
            "443 - basemodel.transformer.decoder.layers.5.norm3.weight: False\n",
            "444 - basemodel.transformer.decoder.layers.5.norm3.bias: False\n",
            "445 - basemodel.transformer.decoder.norm.weight: False\n",
            "446 - basemodel.transformer.decoder.norm.bias: False\n",
            "447 - basemodel.transformer.decoder.ref_point_head.layers.0.weight: False\n",
            "448 - basemodel.transformer.decoder.ref_point_head.layers.0.bias: False\n",
            "449 - basemodel.transformer.decoder.ref_point_head.layers.1.weight: False\n",
            "450 - basemodel.transformer.decoder.ref_point_head.layers.1.bias: False\n",
            "451 - basemodel.transformer.decoder.bbox_embed.0.layers.0.weight: False\n",
            "452 - basemodel.transformer.decoder.bbox_embed.0.layers.0.bias: False\n",
            "453 - basemodel.transformer.decoder.bbox_embed.0.layers.1.weight: False\n",
            "454 - basemodel.transformer.decoder.bbox_embed.0.layers.1.bias: False\n",
            "455 - basemodel.transformer.decoder.bbox_embed.0.layers.2.weight: False\n",
            "456 - basemodel.transformer.decoder.bbox_embed.0.layers.2.bias: False\n",
            "457 - basemodel.transformer.tgt_embed.weight: False\n",
            "458 - basemodel.transformer.enc_output.weight: False\n",
            "459 - basemodel.transformer.enc_output.bias: False\n",
            "460 - basemodel.transformer.enc_output_norm.weight: False\n",
            "461 - basemodel.transformer.enc_output_norm.bias: False\n",
            "462 - basemodel.transformer.enc_out_bbox_embed.layers.0.weight: False\n",
            "463 - basemodel.transformer.enc_out_bbox_embed.layers.0.bias: False\n",
            "464 - basemodel.transformer.enc_out_bbox_embed.layers.1.weight: False\n",
            "465 - basemodel.transformer.enc_out_bbox_embed.layers.1.bias: False\n",
            "466 - basemodel.transformer.enc_out_bbox_embed.layers.2.weight: False\n",
            "467 - basemodel.transformer.enc_out_bbox_embed.layers.2.bias: False\n",
            "468 - basemodel.bert.embeddings.word_embeddings.weight: False\n",
            "469 - basemodel.bert.embeddings.position_embeddings.weight: False\n",
            "470 - basemodel.bert.embeddings.token_type_embeddings.weight: False\n",
            "471 - basemodel.bert.embeddings.LayerNorm.weight: False\n",
            "472 - basemodel.bert.embeddings.LayerNorm.bias: False\n",
            "473 - basemodel.bert.encoder.layer.0.attention.self.query.weight: False\n",
            "474 - basemodel.bert.encoder.layer.0.attention.self.query.bias: False\n",
            "475 - basemodel.bert.encoder.layer.0.attention.self.key.weight: False\n",
            "476 - basemodel.bert.encoder.layer.0.attention.self.key.bias: False\n",
            "477 - basemodel.bert.encoder.layer.0.attention.self.value.weight: False\n",
            "478 - basemodel.bert.encoder.layer.0.attention.self.value.bias: False\n",
            "479 - basemodel.bert.encoder.layer.0.attention.output.dense.weight: False\n",
            "480 - basemodel.bert.encoder.layer.0.attention.output.dense.bias: False\n",
            "481 - basemodel.bert.encoder.layer.0.attention.output.LayerNorm.weight: False\n",
            "482 - basemodel.bert.encoder.layer.0.attention.output.LayerNorm.bias: False\n",
            "483 - basemodel.bert.encoder.layer.0.intermediate.dense.weight: False\n",
            "484 - basemodel.bert.encoder.layer.0.intermediate.dense.bias: False\n",
            "485 - basemodel.bert.encoder.layer.0.output.dense.weight: False\n",
            "486 - basemodel.bert.encoder.layer.0.output.dense.bias: False\n",
            "487 - basemodel.bert.encoder.layer.0.output.LayerNorm.weight: False\n",
            "488 - basemodel.bert.encoder.layer.0.output.LayerNorm.bias: False\n",
            "489 - basemodel.bert.encoder.layer.1.attention.self.query.weight: False\n",
            "490 - basemodel.bert.encoder.layer.1.attention.self.query.bias: False\n",
            "491 - basemodel.bert.encoder.layer.1.attention.self.key.weight: False\n",
            "492 - basemodel.bert.encoder.layer.1.attention.self.key.bias: False\n",
            "493 - basemodel.bert.encoder.layer.1.attention.self.value.weight: False\n",
            "494 - basemodel.bert.encoder.layer.1.attention.self.value.bias: False\n",
            "495 - basemodel.bert.encoder.layer.1.attention.output.dense.weight: False\n",
            "496 - basemodel.bert.encoder.layer.1.attention.output.dense.bias: False\n",
            "497 - basemodel.bert.encoder.layer.1.attention.output.LayerNorm.weight: False\n",
            "498 - basemodel.bert.encoder.layer.1.attention.output.LayerNorm.bias: False\n",
            "499 - basemodel.bert.encoder.layer.1.intermediate.dense.weight: False\n",
            "500 - basemodel.bert.encoder.layer.1.intermediate.dense.bias: False\n",
            "501 - basemodel.bert.encoder.layer.1.output.dense.weight: False\n",
            "502 - basemodel.bert.encoder.layer.1.output.dense.bias: False\n",
            "503 - basemodel.bert.encoder.layer.1.output.LayerNorm.weight: False\n",
            "504 - basemodel.bert.encoder.layer.1.output.LayerNorm.bias: False\n",
            "505 - basemodel.bert.encoder.layer.2.attention.self.query.weight: False\n",
            "506 - basemodel.bert.encoder.layer.2.attention.self.query.bias: False\n",
            "507 - basemodel.bert.encoder.layer.2.attention.self.key.weight: False\n",
            "508 - basemodel.bert.encoder.layer.2.attention.self.key.bias: False\n",
            "509 - basemodel.bert.encoder.layer.2.attention.self.value.weight: False\n",
            "510 - basemodel.bert.encoder.layer.2.attention.self.value.bias: False\n",
            "511 - basemodel.bert.encoder.layer.2.attention.output.dense.weight: False\n",
            "512 - basemodel.bert.encoder.layer.2.attention.output.dense.bias: False\n",
            "513 - basemodel.bert.encoder.layer.2.attention.output.LayerNorm.weight: False\n",
            "514 - basemodel.bert.encoder.layer.2.attention.output.LayerNorm.bias: False\n",
            "515 - basemodel.bert.encoder.layer.2.intermediate.dense.weight: False\n",
            "516 - basemodel.bert.encoder.layer.2.intermediate.dense.bias: False\n",
            "517 - basemodel.bert.encoder.layer.2.output.dense.weight: False\n",
            "518 - basemodel.bert.encoder.layer.2.output.dense.bias: False\n",
            "519 - basemodel.bert.encoder.layer.2.output.LayerNorm.weight: False\n",
            "520 - basemodel.bert.encoder.layer.2.output.LayerNorm.bias: False\n",
            "521 - basemodel.bert.encoder.layer.3.attention.self.query.weight: False\n",
            "522 - basemodel.bert.encoder.layer.3.attention.self.query.bias: False\n",
            "523 - basemodel.bert.encoder.layer.3.attention.self.key.weight: False\n",
            "524 - basemodel.bert.encoder.layer.3.attention.self.key.bias: False\n",
            "525 - basemodel.bert.encoder.layer.3.attention.self.value.weight: False\n",
            "526 - basemodel.bert.encoder.layer.3.attention.self.value.bias: False\n",
            "527 - basemodel.bert.encoder.layer.3.attention.output.dense.weight: False\n",
            "528 - basemodel.bert.encoder.layer.3.attention.output.dense.bias: False\n",
            "529 - basemodel.bert.encoder.layer.3.attention.output.LayerNorm.weight: False\n",
            "530 - basemodel.bert.encoder.layer.3.attention.output.LayerNorm.bias: False\n",
            "531 - basemodel.bert.encoder.layer.3.intermediate.dense.weight: False\n",
            "532 - basemodel.bert.encoder.layer.3.intermediate.dense.bias: False\n",
            "533 - basemodel.bert.encoder.layer.3.output.dense.weight: False\n",
            "534 - basemodel.bert.encoder.layer.3.output.dense.bias: False\n",
            "535 - basemodel.bert.encoder.layer.3.output.LayerNorm.weight: False\n",
            "536 - basemodel.bert.encoder.layer.3.output.LayerNorm.bias: False\n",
            "537 - basemodel.bert.encoder.layer.4.attention.self.query.weight: False\n",
            "538 - basemodel.bert.encoder.layer.4.attention.self.query.bias: False\n",
            "539 - basemodel.bert.encoder.layer.4.attention.self.key.weight: False\n",
            "540 - basemodel.bert.encoder.layer.4.attention.self.key.bias: False\n",
            "541 - basemodel.bert.encoder.layer.4.attention.self.value.weight: False\n",
            "542 - basemodel.bert.encoder.layer.4.attention.self.value.bias: False\n",
            "543 - basemodel.bert.encoder.layer.4.attention.output.dense.weight: False\n",
            "544 - basemodel.bert.encoder.layer.4.attention.output.dense.bias: False\n",
            "545 - basemodel.bert.encoder.layer.4.attention.output.LayerNorm.weight: False\n",
            "546 - basemodel.bert.encoder.layer.4.attention.output.LayerNorm.bias: False\n",
            "547 - basemodel.bert.encoder.layer.4.intermediate.dense.weight: False\n",
            "548 - basemodel.bert.encoder.layer.4.intermediate.dense.bias: False\n",
            "549 - basemodel.bert.encoder.layer.4.output.dense.weight: False\n",
            "550 - basemodel.bert.encoder.layer.4.output.dense.bias: False\n",
            "551 - basemodel.bert.encoder.layer.4.output.LayerNorm.weight: False\n",
            "552 - basemodel.bert.encoder.layer.4.output.LayerNorm.bias: False\n",
            "553 - basemodel.bert.encoder.layer.5.attention.self.query.weight: False\n",
            "554 - basemodel.bert.encoder.layer.5.attention.self.query.bias: False\n",
            "555 - basemodel.bert.encoder.layer.5.attention.self.key.weight: False\n",
            "556 - basemodel.bert.encoder.layer.5.attention.self.key.bias: False\n",
            "557 - basemodel.bert.encoder.layer.5.attention.self.value.weight: False\n",
            "558 - basemodel.bert.encoder.layer.5.attention.self.value.bias: False\n",
            "559 - basemodel.bert.encoder.layer.5.attention.output.dense.weight: False\n",
            "560 - basemodel.bert.encoder.layer.5.attention.output.dense.bias: False\n",
            "561 - basemodel.bert.encoder.layer.5.attention.output.LayerNorm.weight: False\n",
            "562 - basemodel.bert.encoder.layer.5.attention.output.LayerNorm.bias: False\n",
            "563 - basemodel.bert.encoder.layer.5.intermediate.dense.weight: False\n",
            "564 - basemodel.bert.encoder.layer.5.intermediate.dense.bias: False\n",
            "565 - basemodel.bert.encoder.layer.5.output.dense.weight: False\n",
            "566 - basemodel.bert.encoder.layer.5.output.dense.bias: False\n",
            "567 - basemodel.bert.encoder.layer.5.output.LayerNorm.weight: False\n",
            "568 - basemodel.bert.encoder.layer.5.output.LayerNorm.bias: False\n",
            "569 - basemodel.bert.encoder.layer.6.attention.self.query.weight: False\n",
            "570 - basemodel.bert.encoder.layer.6.attention.self.query.bias: False\n",
            "571 - basemodel.bert.encoder.layer.6.attention.self.key.weight: False\n",
            "572 - basemodel.bert.encoder.layer.6.attention.self.key.bias: False\n",
            "573 - basemodel.bert.encoder.layer.6.attention.self.value.weight: False\n",
            "574 - basemodel.bert.encoder.layer.6.attention.self.value.bias: False\n",
            "575 - basemodel.bert.encoder.layer.6.attention.output.dense.weight: False\n",
            "576 - basemodel.bert.encoder.layer.6.attention.output.dense.bias: False\n",
            "577 - basemodel.bert.encoder.layer.6.attention.output.LayerNorm.weight: False\n",
            "578 - basemodel.bert.encoder.layer.6.attention.output.LayerNorm.bias: False\n",
            "579 - basemodel.bert.encoder.layer.6.intermediate.dense.weight: False\n",
            "580 - basemodel.bert.encoder.layer.6.intermediate.dense.bias: False\n",
            "581 - basemodel.bert.encoder.layer.6.output.dense.weight: False\n",
            "582 - basemodel.bert.encoder.layer.6.output.dense.bias: False\n",
            "583 - basemodel.bert.encoder.layer.6.output.LayerNorm.weight: False\n",
            "584 - basemodel.bert.encoder.layer.6.output.LayerNorm.bias: False\n",
            "585 - basemodel.bert.encoder.layer.7.attention.self.query.weight: False\n",
            "586 - basemodel.bert.encoder.layer.7.attention.self.query.bias: False\n",
            "587 - basemodel.bert.encoder.layer.7.attention.self.key.weight: False\n",
            "588 - basemodel.bert.encoder.layer.7.attention.self.key.bias: False\n",
            "589 - basemodel.bert.encoder.layer.7.attention.self.value.weight: False\n",
            "590 - basemodel.bert.encoder.layer.7.attention.self.value.bias: False\n",
            "591 - basemodel.bert.encoder.layer.7.attention.output.dense.weight: False\n",
            "592 - basemodel.bert.encoder.layer.7.attention.output.dense.bias: False\n",
            "593 - basemodel.bert.encoder.layer.7.attention.output.LayerNorm.weight: False\n",
            "594 - basemodel.bert.encoder.layer.7.attention.output.LayerNorm.bias: False\n",
            "595 - basemodel.bert.encoder.layer.7.intermediate.dense.weight: False\n",
            "596 - basemodel.bert.encoder.layer.7.intermediate.dense.bias: False\n",
            "597 - basemodel.bert.encoder.layer.7.output.dense.weight: False\n",
            "598 - basemodel.bert.encoder.layer.7.output.dense.bias: False\n",
            "599 - basemodel.bert.encoder.layer.7.output.LayerNorm.weight: False\n",
            "600 - basemodel.bert.encoder.layer.7.output.LayerNorm.bias: False\n",
            "601 - basemodel.bert.encoder.layer.8.attention.self.query.weight: False\n",
            "602 - basemodel.bert.encoder.layer.8.attention.self.query.bias: False\n",
            "603 - basemodel.bert.encoder.layer.8.attention.self.key.weight: False\n",
            "604 - basemodel.bert.encoder.layer.8.attention.self.key.bias: False\n",
            "605 - basemodel.bert.encoder.layer.8.attention.self.value.weight: False\n",
            "606 - basemodel.bert.encoder.layer.8.attention.self.value.bias: False\n",
            "607 - basemodel.bert.encoder.layer.8.attention.output.dense.weight: False\n",
            "608 - basemodel.bert.encoder.layer.8.attention.output.dense.bias: False\n",
            "609 - basemodel.bert.encoder.layer.8.attention.output.LayerNorm.weight: False\n",
            "610 - basemodel.bert.encoder.layer.8.attention.output.LayerNorm.bias: False\n",
            "611 - basemodel.bert.encoder.layer.8.intermediate.dense.weight: False\n",
            "612 - basemodel.bert.encoder.layer.8.intermediate.dense.bias: False\n",
            "613 - basemodel.bert.encoder.layer.8.output.dense.weight: False\n",
            "614 - basemodel.bert.encoder.layer.8.output.dense.bias: False\n",
            "615 - basemodel.bert.encoder.layer.8.output.LayerNorm.weight: False\n",
            "616 - basemodel.bert.encoder.layer.8.output.LayerNorm.bias: False\n",
            "617 - basemodel.bert.encoder.layer.9.attention.self.query.weight: False\n",
            "618 - basemodel.bert.encoder.layer.9.attention.self.query.bias: False\n",
            "619 - basemodel.bert.encoder.layer.9.attention.self.key.weight: False\n",
            "620 - basemodel.bert.encoder.layer.9.attention.self.key.bias: False\n",
            "621 - basemodel.bert.encoder.layer.9.attention.self.value.weight: False\n",
            "622 - basemodel.bert.encoder.layer.9.attention.self.value.bias: False\n",
            "623 - basemodel.bert.encoder.layer.9.attention.output.dense.weight: False\n",
            "624 - basemodel.bert.encoder.layer.9.attention.output.dense.bias: False\n",
            "625 - basemodel.bert.encoder.layer.9.attention.output.LayerNorm.weight: False\n",
            "626 - basemodel.bert.encoder.layer.9.attention.output.LayerNorm.bias: False\n",
            "627 - basemodel.bert.encoder.layer.9.intermediate.dense.weight: False\n",
            "628 - basemodel.bert.encoder.layer.9.intermediate.dense.bias: False\n",
            "629 - basemodel.bert.encoder.layer.9.output.dense.weight: False\n",
            "630 - basemodel.bert.encoder.layer.9.output.dense.bias: False\n",
            "631 - basemodel.bert.encoder.layer.9.output.LayerNorm.weight: False\n",
            "632 - basemodel.bert.encoder.layer.9.output.LayerNorm.bias: False\n",
            "633 - basemodel.bert.encoder.layer.10.attention.self.query.weight: False\n",
            "634 - basemodel.bert.encoder.layer.10.attention.self.query.bias: False\n",
            "635 - basemodel.bert.encoder.layer.10.attention.self.key.weight: False\n",
            "636 - basemodel.bert.encoder.layer.10.attention.self.key.bias: False\n",
            "637 - basemodel.bert.encoder.layer.10.attention.self.value.weight: False\n",
            "638 - basemodel.bert.encoder.layer.10.attention.self.value.bias: False\n",
            "639 - basemodel.bert.encoder.layer.10.attention.output.dense.weight: False\n",
            "640 - basemodel.bert.encoder.layer.10.attention.output.dense.bias: False\n",
            "641 - basemodel.bert.encoder.layer.10.attention.output.LayerNorm.weight: False\n",
            "642 - basemodel.bert.encoder.layer.10.attention.output.LayerNorm.bias: False\n",
            "643 - basemodel.bert.encoder.layer.10.intermediate.dense.weight: False\n",
            "644 - basemodel.bert.encoder.layer.10.intermediate.dense.bias: False\n",
            "645 - basemodel.bert.encoder.layer.10.output.dense.weight: False\n",
            "646 - basemodel.bert.encoder.layer.10.output.dense.bias: False\n",
            "647 - basemodel.bert.encoder.layer.10.output.LayerNorm.weight: False\n",
            "648 - basemodel.bert.encoder.layer.10.output.LayerNorm.bias: False\n",
            "649 - basemodel.bert.encoder.layer.11.attention.self.query.weight: False\n",
            "650 - basemodel.bert.encoder.layer.11.attention.self.query.bias: False\n",
            "651 - basemodel.bert.encoder.layer.11.attention.self.key.weight: False\n",
            "652 - basemodel.bert.encoder.layer.11.attention.self.key.bias: False\n",
            "653 - basemodel.bert.encoder.layer.11.attention.self.value.weight: False\n",
            "654 - basemodel.bert.encoder.layer.11.attention.self.value.bias: False\n",
            "655 - basemodel.bert.encoder.layer.11.attention.output.dense.weight: False\n",
            "656 - basemodel.bert.encoder.layer.11.attention.output.dense.bias: False\n",
            "657 - basemodel.bert.encoder.layer.11.attention.output.LayerNorm.weight: False\n",
            "658 - basemodel.bert.encoder.layer.11.attention.output.LayerNorm.bias: False\n",
            "659 - basemodel.bert.encoder.layer.11.intermediate.dense.weight: False\n",
            "660 - basemodel.bert.encoder.layer.11.intermediate.dense.bias: False\n",
            "661 - basemodel.bert.encoder.layer.11.output.dense.weight: False\n",
            "662 - basemodel.bert.encoder.layer.11.output.dense.bias: False\n",
            "663 - basemodel.bert.encoder.layer.11.output.LayerNorm.weight: False\n",
            "664 - basemodel.bert.encoder.layer.11.output.LayerNorm.bias: False\n",
            "665 - basemodel.bert.pooler.dense.weight: False\n",
            "666 - basemodel.bert.pooler.dense.bias: False\n",
            "667 - basemodel.feat_map.weight: False\n",
            "668 - basemodel.feat_map.bias: False\n",
            "669 - basemodel.input_proj.0.0.weight: False\n",
            "670 - basemodel.input_proj.0.0.bias: False\n",
            "671 - basemodel.input_proj.0.1.weight: False\n",
            "672 - basemodel.input_proj.0.1.bias: False\n",
            "673 - basemodel.input_proj.1.0.weight: False\n",
            "674 - basemodel.input_proj.1.0.bias: False\n",
            "675 - basemodel.input_proj.1.1.weight: False\n",
            "676 - basemodel.input_proj.1.1.bias: False\n",
            "677 - basemodel.input_proj.2.0.weight: False\n",
            "678 - basemodel.input_proj.2.0.bias: False\n",
            "679 - basemodel.input_proj.2.1.weight: False\n",
            "680 - basemodel.input_proj.2.1.bias: False\n",
            "681 - basemodel.input_proj.3.0.weight: False\n",
            "682 - basemodel.input_proj.3.0.bias: False\n",
            "683 - basemodel.input_proj.3.1.weight: False\n",
            "684 - basemodel.input_proj.3.1.bias: False\n",
            "685 - basemodel.backbone.0.patch_embed.proj.weight: False\n",
            "686 - basemodel.backbone.0.patch_embed.proj.bias: False\n",
            "687 - basemodel.backbone.0.patch_embed.norm.weight: False\n",
            "688 - basemodel.backbone.0.patch_embed.norm.bias: False\n",
            "689 - basemodel.backbone.0.layers.0.blocks.0.norm1.weight: False\n",
            "690 - basemodel.backbone.0.layers.0.blocks.0.norm1.bias: False\n",
            "691 - basemodel.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table: False\n",
            "692 - basemodel.backbone.0.layers.0.blocks.0.attn.qkv.weight: False\n",
            "693 - basemodel.backbone.0.layers.0.blocks.0.attn.qkv.bias: False\n",
            "694 - basemodel.backbone.0.layers.0.blocks.0.attn.proj.weight: False\n",
            "695 - basemodel.backbone.0.layers.0.blocks.0.attn.proj.bias: False\n",
            "696 - basemodel.backbone.0.layers.0.blocks.0.norm2.weight: False\n",
            "697 - basemodel.backbone.0.layers.0.blocks.0.norm2.bias: False\n",
            "698 - basemodel.backbone.0.layers.0.blocks.0.mlp.fc1.weight: False\n",
            "699 - basemodel.backbone.0.layers.0.blocks.0.mlp.fc1.bias: False\n",
            "700 - basemodel.backbone.0.layers.0.blocks.0.mlp.fc2.weight: False\n",
            "701 - basemodel.backbone.0.layers.0.blocks.0.mlp.fc2.bias: False\n",
            "702 - basemodel.backbone.0.layers.0.blocks.1.norm1.weight: False\n",
            "703 - basemodel.backbone.0.layers.0.blocks.1.norm1.bias: False\n",
            "704 - basemodel.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table: False\n",
            "705 - basemodel.backbone.0.layers.0.blocks.1.attn.qkv.weight: False\n",
            "706 - basemodel.backbone.0.layers.0.blocks.1.attn.qkv.bias: False\n",
            "707 - basemodel.backbone.0.layers.0.blocks.1.attn.proj.weight: False\n",
            "708 - basemodel.backbone.0.layers.0.blocks.1.attn.proj.bias: False\n",
            "709 - basemodel.backbone.0.layers.0.blocks.1.norm2.weight: False\n",
            "710 - basemodel.backbone.0.layers.0.blocks.1.norm2.bias: False\n",
            "711 - basemodel.backbone.0.layers.0.blocks.1.mlp.fc1.weight: False\n",
            "712 - basemodel.backbone.0.layers.0.blocks.1.mlp.fc1.bias: False\n",
            "713 - basemodel.backbone.0.layers.0.blocks.1.mlp.fc2.weight: False\n",
            "714 - basemodel.backbone.0.layers.0.blocks.1.mlp.fc2.bias: False\n",
            "715 - basemodel.backbone.0.layers.0.downsample.reduction.weight: False\n",
            "716 - basemodel.backbone.0.layers.0.downsample.norm.weight: False\n",
            "717 - basemodel.backbone.0.layers.0.downsample.norm.bias: False\n",
            "718 - basemodel.backbone.0.layers.1.blocks.0.norm1.weight: False\n",
            "719 - basemodel.backbone.0.layers.1.blocks.0.norm1.bias: False\n",
            "720 - basemodel.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table: False\n",
            "721 - basemodel.backbone.0.layers.1.blocks.0.attn.qkv.weight: False\n",
            "722 - basemodel.backbone.0.layers.1.blocks.0.attn.qkv.bias: False\n",
            "723 - basemodel.backbone.0.layers.1.blocks.0.attn.proj.weight: False\n",
            "724 - basemodel.backbone.0.layers.1.blocks.0.attn.proj.bias: False\n",
            "725 - basemodel.backbone.0.layers.1.blocks.0.norm2.weight: False\n",
            "726 - basemodel.backbone.0.layers.1.blocks.0.norm2.bias: False\n",
            "727 - basemodel.backbone.0.layers.1.blocks.0.mlp.fc1.weight: False\n",
            "728 - basemodel.backbone.0.layers.1.blocks.0.mlp.fc1.bias: False\n",
            "729 - basemodel.backbone.0.layers.1.blocks.0.mlp.fc2.weight: False\n",
            "730 - basemodel.backbone.0.layers.1.blocks.0.mlp.fc2.bias: False\n",
            "731 - basemodel.backbone.0.layers.1.blocks.1.norm1.weight: False\n",
            "732 - basemodel.backbone.0.layers.1.blocks.1.norm1.bias: False\n",
            "733 - basemodel.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table: False\n",
            "734 - basemodel.backbone.0.layers.1.blocks.1.attn.qkv.weight: False\n",
            "735 - basemodel.backbone.0.layers.1.blocks.1.attn.qkv.bias: False\n",
            "736 - basemodel.backbone.0.layers.1.blocks.1.attn.proj.weight: False\n",
            "737 - basemodel.backbone.0.layers.1.blocks.1.attn.proj.bias: False\n",
            "738 - basemodel.backbone.0.layers.1.blocks.1.norm2.weight: False\n",
            "739 - basemodel.backbone.0.layers.1.blocks.1.norm2.bias: False\n",
            "740 - basemodel.backbone.0.layers.1.blocks.1.mlp.fc1.weight: False\n",
            "741 - basemodel.backbone.0.layers.1.blocks.1.mlp.fc1.bias: False\n",
            "742 - basemodel.backbone.0.layers.1.blocks.1.mlp.fc2.weight: False\n",
            "743 - basemodel.backbone.0.layers.1.blocks.1.mlp.fc2.bias: False\n",
            "744 - basemodel.backbone.0.layers.1.downsample.reduction.weight: False\n",
            "745 - basemodel.backbone.0.layers.1.downsample.norm.weight: False\n",
            "746 - basemodel.backbone.0.layers.1.downsample.norm.bias: False\n",
            "747 - basemodel.backbone.0.layers.2.blocks.0.norm1.weight: False\n",
            "748 - basemodel.backbone.0.layers.2.blocks.0.norm1.bias: False\n",
            "749 - basemodel.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table: False\n",
            "750 - basemodel.backbone.0.layers.2.blocks.0.attn.qkv.weight: False\n",
            "751 - basemodel.backbone.0.layers.2.blocks.0.attn.qkv.bias: False\n",
            "752 - basemodel.backbone.0.layers.2.blocks.0.attn.proj.weight: False\n",
            "753 - basemodel.backbone.0.layers.2.blocks.0.attn.proj.bias: False\n",
            "754 - basemodel.backbone.0.layers.2.blocks.0.norm2.weight: False\n",
            "755 - basemodel.backbone.0.layers.2.blocks.0.norm2.bias: False\n",
            "756 - basemodel.backbone.0.layers.2.blocks.0.mlp.fc1.weight: False\n",
            "757 - basemodel.backbone.0.layers.2.blocks.0.mlp.fc1.bias: False\n",
            "758 - basemodel.backbone.0.layers.2.blocks.0.mlp.fc2.weight: False\n",
            "759 - basemodel.backbone.0.layers.2.blocks.0.mlp.fc2.bias: False\n",
            "760 - basemodel.backbone.0.layers.2.blocks.1.norm1.weight: False\n",
            "761 - basemodel.backbone.0.layers.2.blocks.1.norm1.bias: False\n",
            "762 - basemodel.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table: False\n",
            "763 - basemodel.backbone.0.layers.2.blocks.1.attn.qkv.weight: False\n",
            "764 - basemodel.backbone.0.layers.2.blocks.1.attn.qkv.bias: False\n",
            "765 - basemodel.backbone.0.layers.2.blocks.1.attn.proj.weight: False\n",
            "766 - basemodel.backbone.0.layers.2.blocks.1.attn.proj.bias: False\n",
            "767 - basemodel.backbone.0.layers.2.blocks.1.norm2.weight: False\n",
            "768 - basemodel.backbone.0.layers.2.blocks.1.norm2.bias: False\n",
            "769 - basemodel.backbone.0.layers.2.blocks.1.mlp.fc1.weight: False\n",
            "770 - basemodel.backbone.0.layers.2.blocks.1.mlp.fc1.bias: False\n",
            "771 - basemodel.backbone.0.layers.2.blocks.1.mlp.fc2.weight: False\n",
            "772 - basemodel.backbone.0.layers.2.blocks.1.mlp.fc2.bias: False\n",
            "773 - basemodel.backbone.0.layers.2.blocks.2.norm1.weight: False\n",
            "774 - basemodel.backbone.0.layers.2.blocks.2.norm1.bias: False\n",
            "775 - basemodel.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table: False\n",
            "776 - basemodel.backbone.0.layers.2.blocks.2.attn.qkv.weight: False\n",
            "777 - basemodel.backbone.0.layers.2.blocks.2.attn.qkv.bias: False\n",
            "778 - basemodel.backbone.0.layers.2.blocks.2.attn.proj.weight: False\n",
            "779 - basemodel.backbone.0.layers.2.blocks.2.attn.proj.bias: False\n",
            "780 - basemodel.backbone.0.layers.2.blocks.2.norm2.weight: False\n",
            "781 - basemodel.backbone.0.layers.2.blocks.2.norm2.bias: False\n",
            "782 - basemodel.backbone.0.layers.2.blocks.2.mlp.fc1.weight: False\n",
            "783 - basemodel.backbone.0.layers.2.blocks.2.mlp.fc1.bias: False\n",
            "784 - basemodel.backbone.0.layers.2.blocks.2.mlp.fc2.weight: False\n",
            "785 - basemodel.backbone.0.layers.2.blocks.2.mlp.fc2.bias: False\n",
            "786 - basemodel.backbone.0.layers.2.blocks.3.norm1.weight: False\n",
            "787 - basemodel.backbone.0.layers.2.blocks.3.norm1.bias: False\n",
            "788 - basemodel.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table: False\n",
            "789 - basemodel.backbone.0.layers.2.blocks.3.attn.qkv.weight: False\n",
            "790 - basemodel.backbone.0.layers.2.blocks.3.attn.qkv.bias: False\n",
            "791 - basemodel.backbone.0.layers.2.blocks.3.attn.proj.weight: False\n",
            "792 - basemodel.backbone.0.layers.2.blocks.3.attn.proj.bias: False\n",
            "793 - basemodel.backbone.0.layers.2.blocks.3.norm2.weight: False\n",
            "794 - basemodel.backbone.0.layers.2.blocks.3.norm2.bias: False\n",
            "795 - basemodel.backbone.0.layers.2.blocks.3.mlp.fc1.weight: False\n",
            "796 - basemodel.backbone.0.layers.2.blocks.3.mlp.fc1.bias: False\n",
            "797 - basemodel.backbone.0.layers.2.blocks.3.mlp.fc2.weight: False\n",
            "798 - basemodel.backbone.0.layers.2.blocks.3.mlp.fc2.bias: False\n",
            "799 - basemodel.backbone.0.layers.2.blocks.4.norm1.weight: False\n",
            "800 - basemodel.backbone.0.layers.2.blocks.4.norm1.bias: False\n",
            "801 - basemodel.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table: False\n",
            "802 - basemodel.backbone.0.layers.2.blocks.4.attn.qkv.weight: False\n",
            "803 - basemodel.backbone.0.layers.2.blocks.4.attn.qkv.bias: False\n",
            "804 - basemodel.backbone.0.layers.2.blocks.4.attn.proj.weight: False\n",
            "805 - basemodel.backbone.0.layers.2.blocks.4.attn.proj.bias: False\n",
            "806 - basemodel.backbone.0.layers.2.blocks.4.norm2.weight: False\n",
            "807 - basemodel.backbone.0.layers.2.blocks.4.norm2.bias: False\n",
            "808 - basemodel.backbone.0.layers.2.blocks.4.mlp.fc1.weight: False\n",
            "809 - basemodel.backbone.0.layers.2.blocks.4.mlp.fc1.bias: False\n",
            "810 - basemodel.backbone.0.layers.2.blocks.4.mlp.fc2.weight: False\n",
            "811 - basemodel.backbone.0.layers.2.blocks.4.mlp.fc2.bias: False\n",
            "812 - basemodel.backbone.0.layers.2.blocks.5.norm1.weight: False\n",
            "813 - basemodel.backbone.0.layers.2.blocks.5.norm1.bias: False\n",
            "814 - basemodel.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table: False\n",
            "815 - basemodel.backbone.0.layers.2.blocks.5.attn.qkv.weight: False\n",
            "816 - basemodel.backbone.0.layers.2.blocks.5.attn.qkv.bias: False\n",
            "817 - basemodel.backbone.0.layers.2.blocks.5.attn.proj.weight: False\n",
            "818 - basemodel.backbone.0.layers.2.blocks.5.attn.proj.bias: False\n",
            "819 - basemodel.backbone.0.layers.2.blocks.5.norm2.weight: False\n",
            "820 - basemodel.backbone.0.layers.2.blocks.5.norm2.bias: False\n",
            "821 - basemodel.backbone.0.layers.2.blocks.5.mlp.fc1.weight: False\n",
            "822 - basemodel.backbone.0.layers.2.blocks.5.mlp.fc1.bias: False\n",
            "823 - basemodel.backbone.0.layers.2.blocks.5.mlp.fc2.weight: False\n",
            "824 - basemodel.backbone.0.layers.2.blocks.5.mlp.fc2.bias: False\n",
            "825 - basemodel.backbone.0.layers.2.downsample.reduction.weight: False\n",
            "826 - basemodel.backbone.0.layers.2.downsample.norm.weight: False\n",
            "827 - basemodel.backbone.0.layers.2.downsample.norm.bias: False\n",
            "828 - basemodel.backbone.0.layers.3.blocks.0.norm1.weight: True\n",
            "829 - basemodel.backbone.0.layers.3.blocks.0.norm1.bias: True\n",
            "830 - basemodel.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table: True\n",
            "831 - basemodel.backbone.0.layers.3.blocks.0.attn.qkv.weight: True\n",
            "832 - basemodel.backbone.0.layers.3.blocks.0.attn.qkv.bias: True\n",
            "833 - basemodel.backbone.0.layers.3.blocks.0.attn.proj.weight: True\n",
            "834 - basemodel.backbone.0.layers.3.blocks.0.attn.proj.bias: True\n",
            "835 - basemodel.backbone.0.layers.3.blocks.0.norm2.weight: True\n",
            "836 - basemodel.backbone.0.layers.3.blocks.0.norm2.bias: True\n",
            "837 - basemodel.backbone.0.layers.3.blocks.0.mlp.fc1.weight: True\n",
            "838 - basemodel.backbone.0.layers.3.blocks.0.mlp.fc1.bias: True\n",
            "839 - basemodel.backbone.0.layers.3.blocks.0.mlp.fc2.weight: True\n",
            "840 - basemodel.backbone.0.layers.3.blocks.0.mlp.fc2.bias: True\n",
            "841 - basemodel.backbone.0.layers.3.blocks.1.norm1.weight: True\n",
            "842 - basemodel.backbone.0.layers.3.blocks.1.norm1.bias: True\n",
            "843 - basemodel.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table: True\n",
            "844 - basemodel.backbone.0.layers.3.blocks.1.attn.qkv.weight: True\n",
            "845 - basemodel.backbone.0.layers.3.blocks.1.attn.qkv.bias: True\n",
            "846 - basemodel.backbone.0.layers.3.blocks.1.attn.proj.weight: True\n",
            "847 - basemodel.backbone.0.layers.3.blocks.1.attn.proj.bias: True\n",
            "848 - basemodel.backbone.0.layers.3.blocks.1.norm2.weight: True\n",
            "849 - basemodel.backbone.0.layers.3.blocks.1.norm2.bias: True\n",
            "850 - basemodel.backbone.0.layers.3.blocks.1.mlp.fc1.weight: True\n",
            "851 - basemodel.backbone.0.layers.3.blocks.1.mlp.fc1.bias: True\n",
            "852 - basemodel.backbone.0.layers.3.blocks.1.mlp.fc2.weight: True\n",
            "853 - basemodel.backbone.0.layers.3.blocks.1.mlp.fc2.bias: True\n",
            "854 - basemodel.backbone.0.norm1.weight: True\n",
            "855 - basemodel.backbone.0.norm1.bias: True\n",
            "856 - basemodel.backbone.0.norm2.weight: True\n",
            "857 - basemodel.backbone.0.norm2.bias: True\n",
            "858 - basemodel.backbone.0.norm3.weight: True\n",
            "859 - basemodel.backbone.0.norm3.bias: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "lr = 0.0001\n",
        "\n",
        "train_losses = run(model, epochs, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6D5nsIvOQRgq",
        "outputId": "f9d25e01-b3f6-45a9-f37e-801a3864d619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting run function\n",
            "ITEM 0 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male']\n",
            "y_hat_labels_str = ['male']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male']\n",
            "y_labels_int_v2 = tensor([89], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4916, 0.5000, 0.8798, 0.9447]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male']\n",
            "y_hat_bboxes_v2 = tensor([[0.5028, 0.4981, 0.9207, 0.9749]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0078, 0.7724, 0.0198, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 6.228259086608887 = 0.6784026622772217 + 5.549856662750244\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-3.2807e-04, -3.7916e-04,  2.1335e-05,  1.3080e-04, -5.9444e-04,\n",
            "        -3.2303e-04,  4.1231e-04, -5.7042e-04, -1.5616e-04, -2.3429e-04,\n",
            "         2.8679e-04,  1.3734e-04, -9.6223e-05,  1.8450e-04,  6.8160e-04,\n",
            "         1.3153e-04, -3.5760e-04,  1.4959e-04,  5.0988e-04,  3.5423e-04,\n",
            "        -2.4914e-04,  7.8661e-05,  1.1617e-04,  4.1651e-04,  9.6095e-05,\n",
            "         4.6690e-04, -6.0756e-04, -9.7943e-05,  6.7374e-04,  1.2299e-04,\n",
            "         1.7948e-04, -1.4082e-04,  3.6106e-04,  2.5205e-04, -4.1122e-04,\n",
            "         3.0144e-04,  2.7899e-04, -1.0362e-04, -7.5101e-04,  2.3416e-04,\n",
            "         3.0667e-05,  4.2531e-04, -5.0432e-04, -4.6024e-04,  1.1370e-04,\n",
            "         4.2095e-04, -4.3708e-04,  5.4756e-04, -4.3779e-04,  7.1910e-04,\n",
            "         4.2993e-04, -3.1254e-04, -2.1602e-04, -8.6843e-05, -3.6151e-04,\n",
            "        -2.6558e-04, -3.0561e-05, -1.5274e-04, -3.0552e-04,  4.8133e-04,\n",
            "         2.1929e-04,  3.1582e-04,  2.3759e-05,  2.4857e-04,  4.8651e-05,\n",
            "         1.5408e-04, -1.8575e-04, -3.6741e-04, -9.1170e-05, -1.9439e-04,\n",
            "         2.5526e-04,  3.7371e-04,  3.5636e-04,  1.2505e-04, -4.7926e-04,\n",
            "        -5.8408e-04, -1.4257e-04,  4.3275e-04, -6.2864e-04, -4.4846e-04,\n",
            "         3.1555e-05,  3.6104e-04,  2.3277e-06,  1.4829e-04, -6.5481e-05,\n",
            "         6.5414e-06, -7.8283e-04, -2.3113e-04,  1.1544e-04, -1.1034e-04,\n",
            "        -1.4981e-04,  5.9902e-05,  1.3410e-04,  1.3024e-04, -2.8326e-04,\n",
            "        -1.3215e-04, -1.2003e-04, -5.4685e-05, -4.3751e-05, -5.8805e-06,\n",
            "         3.3715e-04, -2.2762e-04, -2.9492e-04, -3.5462e-04,  1.7194e-04,\n",
            "        -2.4634e-04, -5.1159e-05, -6.3939e-05,  3.0844e-04,  5.2830e-05,\n",
            "         3.9193e-04, -2.9510e-04,  8.3685e-04,  6.7818e-04, -6.1127e-04,\n",
            "         4.1922e-04, -1.0898e-04,  3.3925e-04,  4.1924e-04,  1.4218e-04,\n",
            "        -2.3439e-05,  5.4801e-04, -1.8715e-04,  1.1263e-04,  1.4878e-04,\n",
            "         4.0785e-04,  6.5209e-05,  7.9587e-06,  4.7244e-04,  1.3947e-04,\n",
            "        -4.2149e-04, -5.2120e-04,  4.4393e-04,  5.8648e-04, -3.3701e-05,\n",
            "         2.6387e-04, -1.0519e-04,  5.8958e-05, -2.5706e-04, -4.9396e-04,\n",
            "         7.5378e-05, -8.0244e-05,  2.5687e-04,  3.9139e-04, -3.6066e-04,\n",
            "        -4.2468e-04,  4.6483e-05, -3.9994e-04, -2.6486e-04, -8.2613e-05,\n",
            "        -7.3057e-04, -1.2038e-04,  9.1887e-05, -3.5191e-04, -4.5387e-04,\n",
            "        -3.2365e-05,  1.3173e-05, -2.6066e-04,  1.2035e-04,  3.0760e-05,\n",
            "        -4.1688e-04, -8.0630e-05, -3.0763e-04, -2.4346e-05,  1.0577e-04,\n",
            "        -1.7847e-04, -8.3169e-05, -4.3028e-04,  1.3185e-04,  1.7430e-04,\n",
            "        -1.6671e-04,  5.9359e-04, -6.2347e-05, -3.9425e-04, -5.0544e-05,\n",
            "         4.3076e-05,  2.1346e-04,  2.1645e-04, -1.2320e-04, -1.7563e-04,\n",
            "         1.0050e-04,  1.2391e-04,  1.3409e-04,  2.9879e-04, -6.4372e-04,\n",
            "        -4.1632e-04, -2.1343e-04,  3.2733e-04, -3.3051e-04,  1.1542e-04,\n",
            "        -3.4396e-04, -1.1874e-03, -5.7208e-04, -1.7207e-06, -2.3035e-04,\n",
            "        -1.2507e-04, -2.2740e-04, -1.9714e-04,  4.3963e-04, -6.1820e-05,\n",
            "        -5.8079e-04, -2.4233e-04,  2.8886e-04,  2.3505e-04,  1.0346e-04,\n",
            "        -2.6790e-04,  8.8507e-06,  1.3507e-04, -2.5583e-04, -3.3641e-04,\n",
            "         3.3957e-04,  9.3511e-05,  2.4110e-04,  3.6069e-04,  3.3908e-04,\n",
            "         4.1952e-04,  3.2130e-04, -4.8548e-04,  4.4637e-04, -3.6941e-05,\n",
            "        -7.6608e-04,  2.3444e-05, -1.2990e-04, -3.1054e-04, -1.6950e-04,\n",
            "        -3.5822e-04,  6.6366e-05,  5.4487e-06, -3.7421e-04,  3.9226e-04,\n",
            "         6.9962e-04,  4.5037e-04,  1.1246e-04,  1.0973e-03,  1.5120e-04,\n",
            "        -1.7920e-05, -1.0773e-04, -2.8426e-04, -6.3843e-04, -3.9511e-04,\n",
            "        -5.6982e-04, -3.6947e-04, -1.0837e-04, -8.1969e-05, -1.6701e-05,\n",
            "         7.2816e-05,  1.6391e-04,  6.6779e-04,  1.5389e-05,  5.1940e-04,\n",
            "        -2.0775e-04,  1.1293e-05,  2.8888e-04,  2.0036e-04, -3.9326e-04,\n",
            "        -2.5023e-04,  2.3405e-04, -4.7487e-04, -6.3270e-05, -2.8135e-04,\n",
            "        -3.7268e-04, -2.4633e-04,  6.0979e-04,  3.4158e-04,  9.9424e-04,\n",
            "        -6.7575e-04,  3.7439e-04,  4.1413e-04, -2.6582e-04,  9.4411e-06,\n",
            "         7.0879e-04, -4.6743e-04,  3.8603e-04,  2.2263e-04, -4.1793e-04,\n",
            "        -1.6182e-04, -4.5253e-04, -5.9682e-04, -1.9912e-04,  2.9594e-04,\n",
            "        -4.6824e-04,  2.4435e-04,  7.0814e-04,  8.5540e-05, -2.7660e-04,\n",
            "         1.7980e-04, -1.0665e-04,  9.1264e-04,  1.5148e-04, -4.4244e-04,\n",
            "        -5.4630e-04, -9.6294e-05, -1.7940e-04, -2.4074e-04, -2.4381e-04,\n",
            "        -5.2665e-04,  1.2944e-04, -7.2075e-04,  1.1021e-03,  3.1278e-04,\n",
            "        -7.8957e-05,  1.4343e-04, -2.4482e-05, -8.3567e-04, -7.5513e-05,\n",
            "         8.1911e-04,  1.9178e-04, -3.2383e-04,  4.4718e-04, -6.0364e-04,\n",
            "        -1.0674e-03, -3.7377e-06,  5.3249e-04,  6.8969e-04, -2.5449e-04,\n",
            "        -6.1175e-05,  4.7820e-04, -5.1946e-04, -3.5158e-04,  1.1285e-04,\n",
            "         5.4762e-04, -4.3169e-04,  3.7759e-05,  2.4417e-04,  1.7749e-04,\n",
            "        -6.2083e-04,  3.2123e-04,  3.4489e-04, -1.0577e-05,  5.7629e-05,\n",
            "         5.7291e-04,  6.8649e-04, -2.0893e-04,  2.1781e-04,  3.0057e-04,\n",
            "         2.9856e-04,  2.7711e-04, -7.3003e-04, -5.4710e-04, -8.1985e-06,\n",
            "         2.9493e-04,  2.8749e-04, -4.4699e-05,  2.3575e-04, -2.3526e-04,\n",
            "         4.7852e-04, -5.3731e-04, -4.4809e-04,  8.1576e-05,  1.4631e-04,\n",
            "         3.0339e-04,  4.0776e-04,  3.8059e-04, -1.5948e-04, -3.8219e-06,\n",
            "        -5.3969e-04, -7.3176e-04, -3.6136e-04,  2.1715e-04, -3.6320e-04,\n",
            "         7.4734e-04,  5.4837e-04, -1.0266e-04,  7.3206e-04, -8.8780e-04,\n",
            "        -3.8998e-05, -4.7753e-04,  1.0819e-04,  2.4563e-04, -6.6150e-05,\n",
            "        -5.1483e-04, -1.0602e-03,  1.1532e-03,  1.0700e-04,  6.2654e-05,\n",
            "        -1.4130e-04, -3.6005e-04, -1.9534e-04,  4.9312e-04, -4.9052e-04,\n",
            "        -1.0613e-04, -3.1210e-04,  3.4277e-04, -8.3342e-04, -3.9196e-04,\n",
            "        -6.1829e-05, -9.9475e-05, -1.0248e-04, -1.7858e-04,  2.6103e-04,\n",
            "        -1.6528e-04, -1.6530e-04,  1.7983e-04,  2.4021e-04, -4.3303e-04,\n",
            "        -1.0458e-04,  3.6417e-05,  6.1358e-04, -6.2281e-04, -9.8676e-05,\n",
            "         2.3071e-04, -3.3622e-04, -3.6207e-04, -2.3009e-04,  2.1031e-04,\n",
            "         2.7498e-04, -2.3298e-04,  1.5659e-04,  2.8177e-04,  3.1228e-04,\n",
            "        -3.4606e-04, -6.0703e-04,  2.2257e-04,  1.5870e-04, -1.3423e-04,\n",
            "         9.1545e-04, -6.1291e-04,  1.1095e-04,  2.4732e-04,  2.2125e-04,\n",
            "        -9.6561e-05,  8.1804e-04,  3.5387e-04,  3.0516e-04, -3.2582e-04,\n",
            "        -3.6772e-04, -1.8265e-04, -3.7583e-05, -3.1955e-04, -6.2632e-04,\n",
            "        -1.6016e-05,  1.6624e-04, -3.9269e-04, -2.4698e-04,  1.6061e-04,\n",
            "         1.8724e-04, -1.4186e-04,  1.4087e-04,  2.8808e-04, -5.2693e-05,\n",
            "         2.3902e-04,  1.3472e-04, -3.6669e-04,  3.0908e-04, -5.4162e-04,\n",
            "        -3.3654e-04,  3.2376e-05,  5.0518e-04, -3.9204e-04, -3.2334e-04,\n",
            "        -2.7719e-04,  2.6037e-04,  7.9092e-04, -3.8071e-04,  2.1646e-04,\n",
            "        -2.6928e-04, -4.8531e-04,  1.9672e-04,  4.6575e-04, -7.7455e-05,\n",
            "         3.7395e-04, -2.6021e-04, -3.2736e-04, -1.5670e-04, -2.0641e-04,\n",
            "         3.4837e-04, -3.3910e-04,  1.0512e-04,  4.9920e-04,  5.5143e-04,\n",
            "        -7.9206e-04,  5.6063e-04, -1.0657e-04, -1.4177e-04, -8.0061e-05,\n",
            "        -3.1712e-04,  8.3297e-05,  8.9874e-05,  2.4081e-04,  2.7236e-05,\n",
            "        -3.8631e-04, -2.2216e-04, -6.4224e-06,  6.1763e-04,  1.5495e-04,\n",
            "         4.6684e-04, -4.5315e-04,  9.2798e-04,  2.1391e-04,  7.6368e-04,\n",
            "        -3.1367e-04, -5.3602e-04,  3.4245e-04,  9.3901e-05, -1.3605e-04,\n",
            "        -2.3987e-04,  1.9462e-04, -2.2877e-04, -4.0480e-04,  9.3184e-05,\n",
            "        -2.1793e-05,  2.8991e-04, -9.6182e-05,  3.3765e-04, -1.9214e-04,\n",
            "        -4.1572e-04,  4.8963e-04,  2.2927e-04,  2.3010e-04,  5.2331e-04,\n",
            "         3.0886e-06, -5.6978e-05,  3.9623e-04, -9.8064e-05, -1.8443e-04,\n",
            "         5.5664e-04, -1.0034e-03,  6.8462e-05,  4.9410e-04, -3.5530e-05,\n",
            "        -4.0747e-05,  1.0906e-04, -3.8867e-04, -8.2680e-05, -3.0490e-04,\n",
            "         4.3132e-04, -1.6414e-04, -1.8968e-04,  6.6828e-04,  3.9009e-04,\n",
            "         1.7498e-04, -4.8599e-04,  5.2611e-04,  4.7293e-04,  2.8559e-04,\n",
            "         2.2362e-04,  3.8693e-04,  2.8265e-04, -6.8548e-04,  4.4998e-04,\n",
            "        -5.2813e-04, -3.2922e-04,  8.0913e-04,  8.4442e-05, -8.6153e-04,\n",
            "         5.8084e-04,  2.6079e-04,  5.4707e-04, -6.9563e-04, -1.6028e-04,\n",
            "         1.4194e-04,  3.9304e-04,  1.4159e-04,  4.4527e-05,  2.9413e-04,\n",
            "         2.4672e-05, -2.4949e-04,  3.3412e-05, -2.6538e-04, -3.6835e-05,\n",
            "         4.8389e-04, -2.7334e-04, -6.8603e-05, -2.4594e-04, -4.0864e-04,\n",
            "        -8.4582e-05,  2.3302e-04,  2.1840e-04,  7.3492e-05,  8.0131e-04,\n",
            "        -3.6723e-04,  6.8484e-04,  3.8127e-04, -5.4069e-04,  1.0235e-04,\n",
            "         4.5742e-04,  2.7392e-04,  3.3757e-04,  4.7873e-04, -6.1785e-04,\n",
            "        -4.0481e-04, -6.9273e-05, -4.1284e-04,  4.3110e-04, -4.0749e-04,\n",
            "         9.7105e-06, -9.3695e-05,  1.8179e-04, -6.4837e-04, -2.9803e-04,\n",
            "         5.4979e-04,  6.1803e-04, -2.9191e-04,  4.9640e-04,  1.2573e-04,\n",
            "        -6.3693e-04, -9.1591e-06,  5.5574e-04,  7.4668e-05, -2.4875e-04,\n",
            "         3.9342e-05, -3.0206e-04, -5.6202e-04, -1.0925e-05,  5.5410e-06,\n",
            "         3.7323e-05,  7.9639e-04, -2.1134e-04,  1.1232e-04, -1.9743e-04,\n",
            "         3.9396e-04, -1.6279e-04,  1.6146e-04, -7.1607e-04, -5.0282e-04,\n",
            "         4.5297e-04, -4.6858e-05, -7.2522e-04, -1.3786e-04, -3.3699e-05,\n",
            "        -5.9400e-04,  3.4309e-04,  5.0918e-04, -2.4461e-04,  2.1021e-06,\n",
            "        -1.2487e-04,  6.2311e-05,  4.9625e-04, -2.8074e-04,  7.1075e-04,\n",
            "         6.6926e-04, -3.2629e-05, -2.8507e-05,  3.3272e-04, -3.1113e-06,\n",
            "         1.5413e-04,  3.3363e-04, -1.2124e-05, -1.5207e-04,  8.5516e-04,\n",
            "         3.3148e-04, -3.1393e-04,  2.5963e-05,  9.3900e-04, -1.1617e-04,\n",
            "         3.4046e-04,  2.3173e-04,  4.2252e-04, -8.8076e-04, -2.6847e-04,\n",
            "        -9.7457e-05,  6.5038e-04, -5.5793e-04,  6.9531e-04, -2.4023e-04,\n",
            "         8.4952e-05, -2.4518e-04,  7.2094e-04,  3.9432e-04,  8.6886e-05,\n",
            "        -4.6981e-04,  2.0121e-04,  1.7756e-04, -1.4600e-04, -2.2548e-04,\n",
            "        -5.4163e-05, -8.5253e-05,  5.3005e-04, -3.3932e-04,  7.4207e-05,\n",
            "         3.0981e-04, -3.2203e-04, -2.2887e-04,  4.8290e-05,  2.5536e-04,\n",
            "        -1.9520e-04,  2.3136e-04,  4.5693e-04,  4.1915e-04, -8.6822e-05,\n",
            "         1.4333e-05,  5.3889e-04, -5.4752e-06,  1.3037e-05,  3.7391e-04,\n",
            "         2.3982e-05,  1.2132e-05,  3.4523e-04, -4.8182e-04,  7.5571e-04,\n",
            "         5.6238e-04, -5.2036e-04, -1.8475e-04,  6.6557e-04, -2.9567e-05,\n",
            "         8.0939e-04,  2.1885e-04,  2.3957e-04,  8.8093e-04,  3.1199e-04,\n",
            "        -5.6643e-04, -5.9268e-04, -5.1243e-04, -2.7170e-04, -5.0044e-04,\n",
            "        -7.1291e-04,  3.6684e-04, -3.8298e-04,  4.3691e-04, -1.5427e-05,\n",
            "        -1.9145e-04,  1.6567e-04, -1.1485e-04, -5.1898e-05, -2.8148e-05,\n",
            "        -6.9031e-04,  2.7950e-04,  3.5242e-04,  9.4828e-05, -3.9027e-04,\n",
            "         4.9409e-04, -1.9999e-05,  4.6321e-04, -3.3984e-04,  6.4062e-06,\n",
            "        -8.9980e-04, -2.8202e-04,  1.1196e-03,  3.1140e-04, -2.2900e-04,\n",
            "        -1.0280e-04,  5.6907e-05, -2.3302e-04, -3.6653e-04, -4.5800e-05,\n",
            "        -1.5753e-04,  3.9179e-05, -3.3024e-04,  5.2601e-04, -5.4358e-04,\n",
            "        -7.3855e-05, -6.8728e-04, -1.1663e-03,  1.8809e-04,  5.4807e-04,\n",
            "        -1.3431e-04, -6.4869e-04,  6.8320e-04, -2.3856e-04, -3.3649e-04,\n",
            "         1.1638e-03,  5.5425e-05, -7.1747e-05, -3.3898e-04, -1.5139e-04,\n",
            "        -5.7030e-05,  3.9822e-04, -8.9765e-04, -3.1751e-04,  2.4261e-04,\n",
            "        -3.4421e-05,  3.5981e-04,  3.5295e-04,  2.9489e-04,  1.6501e-04,\n",
            "         5.7757e-05, -1.0127e-04,  3.3278e-04], device='cuda:0')\n",
            "ITEM 1 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['bottle', 'painting', 'diningTable', 'dog', 'cat', 'window', 'door']\n",
            "y_hat_labels_str = ['window', 'bottle', 'dog', 'dog', 'painting', 'painting', 'door', 'door']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['bottle', 'painting', 'dog', 'window', 'door']\n",
            "y_labels_int_v2 = tensor([ 17,  98,  45, 160,  48], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4808, 0.4615, 0.0745, 0.1466],\n",
            "        [0.5072, 0.2332, 0.1731, 0.1899],\n",
            "        [0.3245, 0.7188, 0.4736, 0.3149],\n",
            "        [0.8582, 0.2812, 0.2572, 0.2933],\n",
            "        [0.2236, 0.4387, 0.3125, 0.6322]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['bottle', 'painting', 'dog', 'window', 'door']\n",
            "y_hat_bboxes_v2 = tensor([[0.4808, 0.4601, 0.0664, 0.1327],\n",
            "        [0.5075, 0.2374, 0.1718, 0.1917],\n",
            "        [0.3185, 0.7174, 0.4830, 0.3360],\n",
            "        [0.8568, 0.2899, 0.2699, 0.3171],\n",
            "        [0.2209, 0.4421, 0.3196, 0.6251]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0036, 0.0074, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0070, 0.4296, 0.0113,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0031, 0.0276, 0.0021,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0059, 0.0298, 0.0038,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0036, 0.0366, 0.0030,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0', grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.638002395629883 = 0.08911912888288498 + 5.548883438110352\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 2.2804e-04, -2.5793e-04, -1.2607e-04,  1.7835e-05,  9.4824e-05,\n",
            "        -9.9791e-05, -7.3419e-05,  3.3955e-04,  1.4817e-04, -1.7289e-04,\n",
            "        -3.1919e-05, -4.4796e-05, -7.6128e-05, -2.0211e-05,  1.6279e-04,\n",
            "        -5.7773e-05, -1.4838e-04, -1.1710e-04, -7.0716e-05,  1.6177e-05,\n",
            "         3.0336e-04,  2.7020e-04,  2.5466e-04, -3.3672e-04, -5.2254e-04,\n",
            "         1.2908e-04,  2.2007e-04, -3.9509e-04,  2.5521e-04, -7.6673e-06,\n",
            "        -4.1581e-05,  1.8799e-04,  2.2974e-04, -1.7764e-04,  6.2342e-05,\n",
            "        -9.6828e-05, -1.3755e-04, -1.1653e-04, -1.5245e-04, -2.0882e-04,\n",
            "        -4.1113e-05, -2.3656e-04, -4.0097e-04, -8.9444e-06,  3.1491e-05,\n",
            "         2.2039e-04,  1.6121e-04,  2.0479e-04, -1.7643e-04,  5.0952e-04,\n",
            "         2.5151e-04, -1.6048e-04,  1.4387e-04,  3.3571e-04,  7.7285e-05,\n",
            "         3.6420e-04, -7.6920e-05,  1.5588e-04, -1.5807e-04, -9.4905e-05,\n",
            "         2.5079e-04,  1.2724e-04,  1.4539e-04,  1.6656e-04,  3.7077e-04,\n",
            "         1.6911e-05,  4.3760e-05, -3.6562e-05,  1.7422e-04,  4.0156e-05,\n",
            "        -4.1758e-06,  1.5788e-04,  1.3188e-04,  1.5608e-04, -7.5172e-05,\n",
            "        -8.6046e-05, -1.9406e-04,  7.2123e-05, -1.0602e-04,  3.6574e-04,\n",
            "         2.5760e-05, -1.5630e-04, -5.7492e-04, -7.6066e-05,  9.0306e-05,\n",
            "         9.9256e-05,  1.2203e-04, -3.0745e-04,  4.3214e-04, -2.4148e-04,\n",
            "        -4.2867e-05,  2.0984e-04,  5.0908e-05,  7.6061e-05,  2.5410e-04,\n",
            "         2.3384e-04,  3.2123e-04, -1.3600e-04, -3.6218e-04, -1.8558e-04,\n",
            "         1.0461e-04, -7.9756e-05, -3.0920e-04,  2.5805e-04, -3.3455e-04,\n",
            "         4.6330e-05, -5.6324e-04,  1.2000e-04,  6.1772e-05,  8.8632e-05,\n",
            "        -4.6594e-05, -1.0514e-05,  2.2570e-04,  2.6429e-04, -2.6334e-05,\n",
            "         2.9891e-06, -8.3000e-05, -2.5091e-04, -1.3882e-04,  2.2808e-04,\n",
            "        -2.1189e-04, -2.0794e-04, -1.7928e-04,  8.1946e-06, -3.3388e-04,\n",
            "        -2.5311e-04, -2.7701e-04,  5.8272e-06,  7.0428e-05, -2.7815e-05,\n",
            "         1.2740e-04, -8.1306e-07,  6.4335e-05, -1.7302e-04,  1.7017e-04,\n",
            "        -4.3048e-05, -1.8748e-04,  3.5383e-04,  5.5738e-05,  1.8049e-04,\n",
            "        -3.6073e-04,  3.7287e-04, -1.0576e-04, -4.3209e-05,  6.7884e-05,\n",
            "         8.4700e-05,  3.2465e-04, -4.2539e-04,  5.5863e-05,  3.4560e-04,\n",
            "         3.0196e-04,  1.1888e-05, -6.7175e-05,  2.9783e-04,  1.7387e-04,\n",
            "        -1.5662e-04,  2.0740e-04,  2.0989e-04,  2.8603e-04, -8.3709e-05,\n",
            "        -2.3680e-04, -5.1177e-05, -2.3745e-05, -1.0854e-04, -5.9149e-05,\n",
            "        -1.0199e-04, -2.2194e-04,  2.2283e-04, -8.0776e-05,  2.0984e-04,\n",
            "         1.9564e-05,  5.3655e-05, -9.7412e-05,  2.1243e-04,  1.6215e-05,\n",
            "        -6.3489e-05, -1.2016e-04, -1.0749e-04,  1.5290e-04, -9.3398e-05,\n",
            "        -9.4342e-05,  2.0286e-05, -7.2497e-05, -1.3063e-04,  2.4194e-05,\n",
            "        -2.2109e-05,  2.2804e-04,  4.2649e-06, -2.0342e-04,  1.8965e-04,\n",
            "        -1.4277e-04, -1.2044e-04, -1.7743e-04,  1.4698e-04, -1.4740e-04,\n",
            "         1.1956e-04, -2.7395e-05,  2.3644e-05, -6.8256e-05,  4.8094e-04,\n",
            "        -8.0396e-05, -7.6142e-05, -1.5909e-04, -1.7089e-04,  1.1341e-05,\n",
            "         4.1767e-05,  2.4736e-04,  2.9056e-04,  1.0394e-06, -8.2193e-05,\n",
            "         6.1025e-05,  2.3960e-04, -4.2907e-05, -2.9677e-05,  2.2713e-04,\n",
            "        -1.8943e-04, -5.0043e-04, -5.0308e-04, -4.2749e-05,  1.4153e-04,\n",
            "         1.0966e-05, -7.6957e-05, -1.7925e-04,  2.5902e-04,  1.6044e-04,\n",
            "         3.8474e-05, -1.6358e-05, -1.4769e-04,  1.8559e-04,  1.4306e-04,\n",
            "        -1.0770e-04, -1.2428e-04,  1.4728e-04, -4.5327e-05,  2.3515e-04,\n",
            "         1.5147e-06, -3.6905e-05,  2.6551e-04,  6.5598e-06, -7.3992e-05,\n",
            "        -1.8417e-04,  2.6379e-04, -2.6462e-04, -1.7089e-04,  1.4437e-04,\n",
            "         1.1540e-04,  5.8711e-05,  3.0995e-04,  6.7186e-05,  2.0038e-04,\n",
            "         4.0587e-04, -1.4543e-04,  1.9723e-05, -3.1993e-04, -1.3621e-04,\n",
            "         1.0550e-05, -1.2480e-04,  4.2212e-05,  4.9726e-04, -3.2027e-04,\n",
            "        -1.9927e-04,  1.2981e-04, -1.5918e-04, -1.9773e-04, -2.9479e-05,\n",
            "         3.2365e-04,  1.3266e-04,  3.5500e-04, -3.1030e-05, -1.1632e-04,\n",
            "         2.5436e-04, -3.3753e-04,  1.4886e-04,  2.2926e-04,  1.0328e-04,\n",
            "         1.5648e-04, -1.1290e-04,  1.1321e-04,  1.7390e-04, -2.7798e-05,\n",
            "         4.1327e-05, -1.6064e-04,  1.2087e-04, -1.1759e-04,  1.7590e-04,\n",
            "         1.3016e-04, -1.1003e-04, -2.0174e-04,  2.9602e-05,  3.5097e-04,\n",
            "         1.6448e-04, -1.4227e-04,  2.8732e-04,  1.5020e-04, -1.1362e-04,\n",
            "         1.3533e-04,  3.4796e-04,  4.5762e-04,  1.7570e-04,  8.8291e-05,\n",
            "         3.9974e-05, -2.4555e-04,  1.9235e-04, -1.5753e-04,  2.2721e-04,\n",
            "         1.2499e-04,  1.7717e-04, -9.5504e-05, -4.1142e-04, -2.5803e-05,\n",
            "        -3.2949e-04,  3.7453e-04, -1.2892e-04, -3.3108e-05, -1.1203e-04,\n",
            "        -2.3583e-05,  4.3428e-04, -1.5376e-04, -1.4177e-04,  1.7683e-04,\n",
            "         1.9937e-04,  2.5089e-04, -3.3370e-04,  8.8877e-05,  4.1468e-04,\n",
            "         8.5924e-05,  9.3008e-05, -5.8817e-05,  4.0407e-04,  2.9776e-05,\n",
            "         3.7391e-04,  1.8271e-05, -1.8672e-04,  2.1554e-04, -5.8212e-05,\n",
            "        -6.1528e-05, -5.0766e-05, -3.5189e-05,  2.3691e-06, -7.8086e-06,\n",
            "        -1.9059e-04, -1.5151e-05, -1.4201e-04,  2.8515e-04, -1.6180e-04,\n",
            "         2.0979e-06,  2.2661e-06,  7.7920e-06, -1.4957e-04,  1.6353e-04,\n",
            "         6.3185e-05, -1.4807e-04, -2.7790e-06, -8.1161e-05,  2.3804e-04,\n",
            "        -1.1399e-04,  7.7360e-05,  2.5788e-04, -2.6002e-04, -1.9429e-04,\n",
            "         8.4899e-05, -3.5726e-04,  2.2853e-04,  3.3293e-04, -3.0514e-04,\n",
            "         3.9014e-04,  7.9693e-05, -4.8028e-05,  9.7713e-05, -2.5058e-04,\n",
            "         4.3829e-05,  4.0035e-04, -1.1018e-04, -1.5738e-04,  6.9135e-05,\n",
            "         1.8299e-04,  2.3746e-04,  6.3262e-05, -1.5746e-04, -1.3865e-04,\n",
            "        -1.4546e-04,  1.0766e-04, -1.5705e-04, -1.5687e-04, -7.1249e-05,\n",
            "         1.0038e-04,  1.5664e-04, -2.0344e-05,  1.8184e-04,  2.7580e-05,\n",
            "        -1.2775e-04, -1.4779e-04,  1.7032e-04, -7.6625e-05,  1.1479e-04,\n",
            "        -1.9312e-05, -3.6690e-05,  2.1236e-04, -2.2215e-04, -1.3945e-04,\n",
            "        -1.7082e-05,  1.6689e-04,  5.7289e-05, -1.7247e-04, -1.0321e-04,\n",
            "        -2.4619e-04, -3.2945e-05, -1.0794e-04, -6.8429e-05, -4.1311e-04,\n",
            "        -3.8078e-05, -6.2625e-05, -6.1805e-05,  1.1004e-04, -2.7592e-04,\n",
            "         3.8308e-06, -7.9977e-05, -1.3248e-04,  3.3888e-05, -1.1764e-04,\n",
            "        -3.5811e-04,  7.3716e-05, -1.8258e-04, -2.4389e-04, -5.1973e-04,\n",
            "        -1.0761e-04,  2.3750e-04, -1.6930e-05, -3.0237e-04, -2.9311e-04,\n",
            "         2.9402e-04, -4.4268e-04, -9.3922e-05,  2.2774e-04,  7.5006e-05,\n",
            "         1.6833e-05, -1.7039e-04, -1.5900e-04,  9.9646e-05,  9.5276e-05,\n",
            "        -1.3663e-04, -8.3367e-05,  1.4052e-04,  1.7239e-04, -3.6582e-04,\n",
            "         1.0452e-04, -5.8754e-05,  2.5538e-04, -1.4365e-04, -2.8134e-04,\n",
            "        -1.9588e-04,  9.7800e-05, -1.5030e-04,  8.3676e-05,  1.4049e-04,\n",
            "        -9.3722e-05,  1.2184e-04, -2.1977e-04, -3.5866e-04, -1.0094e-04,\n",
            "        -1.8246e-04,  2.5967e-04,  2.4256e-04,  9.6359e-05, -2.1197e-04,\n",
            "         4.6189e-06, -1.8743e-04, -9.1932e-06, -9.3660e-05,  1.6582e-04,\n",
            "        -1.7862e-04,  3.0493e-04, -3.8216e-05, -6.7949e-05, -8.0367e-05,\n",
            "         8.8145e-05, -2.3225e-04,  5.1843e-05,  1.0049e-04,  1.3930e-05,\n",
            "        -1.1032e-04,  3.1306e-04, -2.0416e-04, -9.5818e-05,  1.6424e-06,\n",
            "        -5.1704e-05,  2.1236e-04, -3.0615e-04,  7.1145e-04,  2.5480e-04,\n",
            "        -9.4146e-05,  1.0322e-04, -2.5474e-04, -1.4810e-04, -2.3316e-04,\n",
            "         3.3875e-04,  1.1076e-04, -1.4415e-05,  5.3689e-05,  2.5189e-05,\n",
            "        -2.1113e-04,  3.7599e-04, -2.9855e-04, -5.7588e-05,  1.5328e-04,\n",
            "         1.7681e-04,  2.6363e-04,  9.7528e-05, -8.2210e-05,  1.6462e-04,\n",
            "         2.9927e-04,  1.6846e-04,  4.8965e-06,  2.6645e-05, -1.1792e-04,\n",
            "        -1.7877e-04, -5.2229e-04,  1.2440e-04, -1.4440e-04, -1.9771e-04,\n",
            "         1.1802e-04, -1.5851e-04,  3.4325e-05, -8.5134e-07,  4.6080e-04,\n",
            "         1.6949e-04, -5.0303e-05, -2.3202e-04,  1.3703e-04,  1.4957e-04,\n",
            "         2.7960e-04,  4.4891e-06, -3.6457e-04, -8.4070e-05,  1.2402e-04,\n",
            "         1.4298e-05,  3.3480e-04, -1.2936e-04, -1.7975e-04, -1.9119e-04,\n",
            "        -9.9210e-05, -1.4680e-04,  4.3738e-04,  9.8118e-05, -3.1864e-04,\n",
            "        -3.5564e-04,  1.4868e-04,  4.1875e-05,  1.2828e-04,  1.9356e-05,\n",
            "        -1.0576e-04, -6.1791e-05,  1.2352e-04, -1.2998e-04, -2.1195e-04,\n",
            "        -3.9437e-04, -2.2988e-05, -1.0980e-04, -9.7626e-05, -3.6841e-05,\n",
            "         2.0044e-04, -2.2781e-04, -3.7244e-05, -1.9037e-04,  1.3878e-04,\n",
            "        -9.9287e-05, -3.9699e-04, -2.0788e-05, -1.4147e-05,  1.3529e-04,\n",
            "         2.4491e-04, -3.8563e-04,  1.1589e-04,  4.2718e-05,  2.3168e-04,\n",
            "         2.0366e-05,  4.1837e-05, -1.5134e-04,  2.5453e-04, -1.2612e-04,\n",
            "        -2.2300e-05,  1.2293e-04, -1.2955e-04,  1.9088e-04,  2.3511e-04,\n",
            "        -4.0416e-05, -4.7954e-05,  9.1433e-05, -1.0172e-04,  2.8328e-04,\n",
            "        -2.1404e-04, -7.8983e-05, -4.3720e-05, -9.5391e-05,  2.9323e-04,\n",
            "        -2.1152e-04, -1.0116e-04, -1.5410e-04,  3.4023e-05, -1.6018e-04,\n",
            "         1.6886e-04,  1.2344e-04, -1.0866e-04, -1.6608e-04, -8.6451e-05,\n",
            "         4.1685e-04, -7.7481e-05, -1.5162e-04,  1.3116e-04,  2.2685e-04,\n",
            "         1.1211e-04, -1.1044e-04,  1.9266e-05,  2.4034e-05, -1.8510e-04,\n",
            "         1.8057e-04,  4.0132e-04, -1.1652e-04, -3.0963e-04,  1.5862e-04,\n",
            "        -1.1749e-04,  9.0511e-05, -2.8670e-04,  6.8855e-05, -5.4149e-05,\n",
            "        -7.7138e-05,  2.7471e-04,  1.3839e-04, -5.1846e-04,  2.2605e-04,\n",
            "         6.6845e-05, -1.2359e-06,  7.8434e-05, -2.2376e-04,  6.7397e-05,\n",
            "         4.2240e-06,  9.4670e-05,  3.8695e-05, -6.8022e-06,  4.4638e-05,\n",
            "        -1.6793e-04, -8.0610e-05, -1.3955e-04, -4.5083e-06,  1.5106e-04,\n",
            "        -1.6181e-04,  9.6435e-05,  1.5405e-05,  3.6466e-06, -6.2874e-05,\n",
            "        -2.2131e-04,  5.1825e-04,  3.2701e-04,  9.2058e-05,  8.5157e-05,\n",
            "         5.9594e-05,  7.7304e-05,  7.9380e-06, -2.5993e-04,  4.0393e-04,\n",
            "        -5.5811e-04, -1.7953e-04, -1.1787e-05,  2.3750e-04, -4.7842e-05,\n",
            "         1.0626e-04,  1.0784e-04, -5.5012e-05, -1.5516e-04, -8.2208e-06,\n",
            "        -4.5612e-05,  1.6864e-04, -1.3974e-04,  2.4620e-04, -6.1690e-05,\n",
            "         1.5403e-04,  4.1343e-05, -2.5466e-04,  1.8634e-04,  1.9756e-05,\n",
            "         9.4628e-05, -1.3578e-04, -2.3852e-04,  7.0472e-05, -8.0337e-05,\n",
            "         6.6639e-05, -1.1546e-04, -9.9266e-05, -2.2663e-04, -1.5115e-04,\n",
            "        -3.8780e-04,  2.4680e-04,  3.8380e-06,  2.7097e-05,  1.6906e-04,\n",
            "        -9.0469e-06, -1.2677e-04,  3.1475e-04, -8.2980e-05, -3.0372e-04,\n",
            "        -1.1539e-04,  2.1258e-04, -2.6593e-05, -2.1641e-04,  1.2590e-04,\n",
            "        -3.3869e-04, -2.7332e-04, -1.8382e-04,  1.8848e-04,  1.8567e-04,\n",
            "        -5.4299e-05,  1.3308e-04,  1.7655e-05,  7.1073e-05,  3.0210e-04,\n",
            "         1.5225e-06,  2.7388e-04, -1.3301e-05,  3.0762e-04,  5.8100e-05,\n",
            "        -5.7408e-05,  3.6907e-05, -4.4859e-05,  1.4625e-04, -1.9350e-04,\n",
            "        -1.9803e-04,  1.9335e-05,  3.9930e-05, -1.6650e-04,  1.1701e-04,\n",
            "        -1.0020e-05, -3.9278e-05, -4.1982e-05,  2.0219e-04, -2.0479e-04,\n",
            "         1.4005e-04,  9.6703e-05, -1.0054e-04, -3.2468e-04, -3.0309e-04,\n",
            "         9.2647e-05,  1.2353e-04, -1.0833e-04, -4.7328e-04, -7.2307e-05,\n",
            "        -2.2572e-04,  5.6621e-05,  1.5359e-04, -7.9592e-05,  2.1932e-04,\n",
            "         4.9840e-05, -2.5773e-04, -2.0567e-04, -7.1346e-05, -2.6388e-04,\n",
            "         5.2114e-05, -1.5587e-04, -3.4157e-04, -1.2280e-04,  2.0843e-04,\n",
            "         2.2931e-04, -3.8207e-04, -4.2000e-04,  6.9331e-05,  3.7912e-04,\n",
            "        -1.3059e-04, -2.1850e-04, -5.4911e-05], device='cuda:0')\n",
            "ITEM 2 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['painting', 'female', 'male', 'barrel']\n",
            "y_hat_labels_str = ['painting', 'male', 'female', 'barrel']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['female', 'male', 'barrel']\n",
            "y_labels_int_v2 = tensor([55, 89,  5], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4099, 0.3101, 0.2885, 0.4688],\n",
            "        [0.6082, 0.6514, 0.3221, 0.5120],\n",
            "        [0.5156, 0.8353, 0.1490, 0.1683]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['female', 'male', 'barrel']\n",
            "y_hat_bboxes_v2 = tensor([[0.3665, 0.3468, 0.4809, 0.5527],\n",
            "        [0.6124, 0.6506, 0.3258, 0.5188],\n",
            "        [0.5112, 0.8333, 0.1403, 0.1599]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0032, 0.5948, 0.0122, 0.1256, 0.0070, 0.0010, 0.0010, 0.0072, 0.0023,\n",
            "         0.0032, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0040, 0.1576, 0.0069, 0.6130, 0.0089, 0.0041, 0.0017, 0.0127, 0.0023,\n",
            "         0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0034, 0.0124, 0.0034, 0.0382, 0.0042, 0.4783, 0.0039, 0.0354, 0.0037,\n",
            "         0.0033, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 9.352249145507812 = 3.96291446685791 + 5.3893351554870605\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 1.1496e-03,  5.5687e-04,  1.1557e-03,  6.3690e-04, -2.5133e-03,\n",
            "        -8.3560e-04,  4.6656e-04, -1.1517e-03, -1.6569e-04, -1.7080e-03,\n",
            "         1.2815e-04,  5.8528e-04, -2.4412e-03,  1.8611e-03,  1.7088e-03,\n",
            "        -9.9405e-04, -4.5450e-04,  2.7135e-04,  1.2500e-03,  3.4519e-04,\n",
            "         6.8551e-04,  1.1982e-03, -2.2207e-03, -1.1012e-03,  2.2521e-04,\n",
            "        -1.6765e-03,  1.6645e-03, -2.2298e-03, -2.7583e-04,  1.8118e-03,\n",
            "        -1.7602e-03, -9.4044e-04, -8.1212e-04,  1.2505e-03,  2.6752e-03,\n",
            "         2.7385e-03, -4.4765e-04, -2.1703e-03, -5.8794e-04,  2.4798e-03,\n",
            "        -4.1477e-04,  5.5696e-04, -1.3070e-03, -2.5505e-03, -5.7251e-04,\n",
            "        -1.1218e-03,  1.5982e-04, -1.8299e-03, -7.0981e-04,  1.1119e-03,\n",
            "        -9.0589e-04, -5.2131e-04, -1.9166e-03, -9.5921e-04, -1.9419e-03,\n",
            "         1.1341e-03, -2.2445e-04,  8.5178e-04,  8.4944e-05,  8.6688e-05,\n",
            "         1.7248e-03,  1.5050e-03,  3.2717e-03,  8.4640e-04, -6.1629e-04,\n",
            "        -9.7976e-04, -1.2487e-03,  1.9707e-04,  6.9281e-04, -7.5245e-04,\n",
            "        -1.7929e-03,  5.5864e-04,  2.5932e-05,  1.8181e-03,  8.0868e-04,\n",
            "        -1.1628e-03,  1.8075e-04,  1.7719e-04, -7.0677e-04, -2.0742e-03,\n",
            "         7.1257e-04,  1.4525e-03, -1.5989e-03,  1.1431e-03,  9.8083e-04,\n",
            "         1.8579e-03, -1.7722e-04, -1.9320e-03,  3.0181e-03,  2.0465e-03,\n",
            "        -5.3221e-04,  1.5455e-03, -6.7667e-04,  7.2397e-04, -5.2100e-04,\n",
            "         5.4011e-04,  9.5604e-05, -8.6780e-04,  1.7219e-04, -1.5485e-03,\n",
            "         4.8909e-04, -2.4489e-04, -2.6108e-03, -1.5277e-03,  1.2242e-03,\n",
            "        -4.4346e-05, -1.9012e-03, -2.5410e-03, -4.2754e-04, -4.5593e-04,\n",
            "         2.7456e-04,  8.4969e-04, -2.1677e-04, -1.2849e-03, -2.5052e-03,\n",
            "        -1.0437e-04, -2.9981e-03,  3.4367e-03,  7.2631e-04,  1.1617e-03,\n",
            "         2.2303e-03, -1.1113e-03,  6.5352e-04, -1.0358e-03,  1.9833e-04,\n",
            "         6.3419e-04, -1.9821e-03,  1.1478e-03,  2.0435e-03, -1.4027e-03,\n",
            "        -4.6202e-04, -1.7284e-05, -4.8061e-04, -2.3597e-04,  9.7134e-04,\n",
            "         5.2252e-04, -1.8936e-04,  7.7246e-04, -1.6197e-03, -1.5696e-03,\n",
            "         2.4047e-05, -5.2466e-04, -1.1701e-03, -7.3420e-05, -2.0823e-03,\n",
            "         8.6530e-04,  1.5396e-03, -1.0834e-03, -2.7279e-03, -2.6616e-04,\n",
            "         4.6237e-04,  3.9266e-04, -9.6042e-05, -6.1631e-04, -2.4833e-04,\n",
            "        -1.0857e-03, -2.4910e-04,  3.7625e-04,  2.3891e-03, -1.7012e-03,\n",
            "        -2.0324e-03, -4.6772e-03, -1.0902e-04, -6.2165e-04,  8.4173e-05,\n",
            "         1.0621e-04, -1.5754e-05, -9.0418e-04,  1.8147e-03, -1.7088e-03,\n",
            "         4.1055e-04,  3.7919e-04, -6.8911e-04, -5.1139e-05, -3.1546e-03,\n",
            "        -9.6307e-04, -2.4435e-04, -3.2347e-04, -3.1063e-04, -1.3247e-04,\n",
            "         1.6525e-03,  2.0836e-03, -1.1690e-03,  1.6797e-03,  2.5938e-03,\n",
            "        -2.3416e-03, -9.2473e-05,  2.7093e-03, -7.4903e-04,  1.5413e-04,\n",
            "        -6.7924e-04, -3.1812e-03,  1.1627e-03,  4.5376e-04, -5.7896e-04,\n",
            "        -2.8046e-03, -1.3347e-03, -2.6440e-03, -6.3384e-04, -7.4719e-04,\n",
            "        -4.3256e-05,  1.5754e-03, -9.6101e-04,  5.2262e-04,  4.7516e-04,\n",
            "         2.7656e-03,  6.3406e-04,  7.3656e-04, -1.6021e-03,  7.2561e-04,\n",
            "         1.7712e-03, -1.1082e-04, -2.7646e-04,  1.8186e-04, -2.0546e-03,\n",
            "         4.7111e-04, -8.2766e-04,  6.5050e-04,  3.0021e-03,  9.8436e-04,\n",
            "        -2.8407e-04, -1.0621e-03, -7.9067e-04,  2.4361e-03,  2.1972e-03,\n",
            "         1.4560e-03,  1.2031e-03,  8.6829e-04, -2.3321e-03, -1.3070e-03,\n",
            "         1.0317e-03, -2.7922e-04,  7.8887e-04, -2.0531e-04,  1.8132e-03,\n",
            "        -2.0095e-03,  3.6432e-04, -1.8537e-03, -7.1898e-05,  4.9433e-04,\n",
            "         1.9607e-05, -6.9740e-04, -4.7724e-04,  1.4318e-03,  9.0880e-04,\n",
            "        -7.8738e-04, -1.5928e-04,  1.7958e-03, -1.0642e-03, -1.8124e-03,\n",
            "         1.0321e-03, -1.5830e-03,  8.7315e-04, -9.9141e-04, -1.2048e-03,\n",
            "         3.8360e-04,  2.0802e-05,  2.7750e-03,  3.6142e-04,  3.8270e-04,\n",
            "         1.1353e-03,  9.2197e-04,  8.9307e-04,  6.6719e-04,  2.3814e-03,\n",
            "        -1.7719e-03, -8.1393e-04,  5.6197e-04, -9.4246e-04, -9.0350e-04,\n",
            "         3.0105e-03,  1.2778e-03, -5.7670e-04,  1.6555e-03, -1.0971e-04,\n",
            "         2.7511e-03, -2.8616e-03,  2.7824e-03,  2.1226e-03,  5.4024e-04,\n",
            "         2.9750e-03,  1.7033e-03, -1.5738e-04,  9.0277e-04,  2.0332e-04,\n",
            "        -1.7294e-04, -3.5832e-04, -1.3016e-03, -3.0667e-03,  1.8105e-03,\n",
            "        -1.7905e-03,  1.2110e-03, -4.1322e-03,  1.0718e-03, -1.3428e-03,\n",
            "        -1.0995e-03,  2.5986e-04,  4.1165e-03,  2.1237e-03,  2.4044e-04,\n",
            "         2.0921e-04, -1.1079e-04,  1.2659e-04, -1.0266e-03,  3.7200e-04,\n",
            "        -1.0822e-04,  1.6342e-03, -1.8709e-03, -1.8058e-03, -2.6503e-05,\n",
            "        -1.4204e-03,  1.0114e-04,  1.2932e-04,  9.5854e-04, -9.5457e-04,\n",
            "         8.2050e-04,  8.3520e-04, -1.4289e-03,  1.9014e-03, -1.7180e-03,\n",
            "         7.5336e-04, -1.2866e-03,  8.8197e-05,  3.1058e-04,  1.5643e-03,\n",
            "        -2.1878e-03, -3.8927e-04,  2.4045e-04,  3.2675e-04,  1.5253e-04,\n",
            "         1.4579e-03,  6.8707e-04,  9.7258e-04, -9.7918e-04,  2.5429e-03,\n",
            "        -1.1516e-03,  2.2309e-03,  2.7740e-04,  1.5301e-04, -6.5035e-04,\n",
            "         5.9648e-04, -8.3993e-04, -2.5779e-03, -1.2483e-03,  5.7974e-04,\n",
            "        -9.4841e-04, -1.0572e-03, -1.6019e-03, -1.0806e-03,  1.1266e-03,\n",
            "         1.6905e-03, -2.7902e-03,  1.7805e-04, -3.7411e-04, -6.3446e-04,\n",
            "         3.0849e-05, -3.5900e-04, -8.4544e-04,  2.4026e-03, -8.1630e-05,\n",
            "         1.7079e-04, -6.2933e-04, -9.3763e-04, -9.8736e-04, -2.2706e-03,\n",
            "        -5.6416e-04, -2.2843e-03, -2.8072e-03,  1.4468e-03,  6.1552e-04,\n",
            "         1.7575e-03, -8.0378e-05,  2.1316e-03,  2.9730e-04,  1.9444e-03,\n",
            "        -1.2347e-04,  1.3744e-03,  1.3554e-03,  4.5163e-04,  1.3604e-03,\n",
            "         1.6551e-03, -7.1518e-04,  1.2659e-03, -2.2692e-03,  2.9025e-03,\n",
            "         6.1682e-04, -1.2565e-03,  3.5759e-04, -7.4984e-04,  3.8447e-04,\n",
            "        -1.1496e-03,  4.0486e-04,  1.3514e-03,  3.5756e-03, -3.8035e-05,\n",
            "        -7.6930e-04,  3.1488e-05,  2.6107e-03, -1.3682e-03, -1.9924e-03,\n",
            "         5.3082e-04,  1.7799e-03, -1.1108e-03, -4.5251e-04, -5.6894e-04,\n",
            "        -5.9138e-04, -4.6359e-04, -1.9092e-04,  2.3196e-03,  1.2361e-03,\n",
            "        -1.9437e-03, -1.6165e-03, -1.6209e-04,  7.3370e-04,  8.7950e-04,\n",
            "        -2.9583e-03, -1.1737e-03, -2.9112e-03,  3.2437e-04, -2.2614e-03,\n",
            "         9.6188e-04,  1.6793e-03,  7.1706e-04,  8.1977e-04, -3.2796e-04,\n",
            "        -3.6558e-04, -1.9666e-03,  4.8986e-04,  7.5020e-04, -2.5682e-03,\n",
            "        -1.1654e-03, -1.1376e-03, -6.8316e-04,  1.2271e-03,  1.0938e-03,\n",
            "         2.3062e-04,  4.2416e-03,  6.8112e-05, -7.0555e-04, -2.4675e-03,\n",
            "         6.9291e-04, -2.2181e-03, -6.5105e-04,  1.2142e-03,  1.0453e-03,\n",
            "        -2.0661e-04,  3.8802e-04, -1.5005e-03, -7.9861e-04,  4.4161e-04,\n",
            "        -6.3153e-04, -1.4355e-04,  3.7388e-04,  2.4129e-04, -4.8615e-04,\n",
            "        -1.4232e-03,  2.6368e-03,  5.6886e-04,  6.8184e-05,  3.0127e-04,\n",
            "         2.8099e-03,  2.0578e-05,  2.1934e-04, -1.7963e-03, -6.4404e-04,\n",
            "         2.4042e-03,  1.2819e-03,  2.2256e-04,  6.0278e-04,  3.5352e-03,\n",
            "        -1.7808e-03,  1.0969e-03, -1.9049e-04,  3.5777e-04, -1.7064e-03,\n",
            "         1.1278e-03,  4.3595e-04, -1.1973e-03,  1.2903e-03, -6.4952e-05,\n",
            "        -1.4975e-03,  7.9884e-05,  2.1609e-04,  8.6000e-04, -3.2871e-04,\n",
            "        -1.1180e-03, -1.3536e-03, -1.2267e-03, -3.6150e-05,  5.7906e-04,\n",
            "         2.3085e-03,  3.1787e-03,  1.8218e-03, -2.9889e-04, -1.0608e-03,\n",
            "         1.2876e-03,  4.5845e-04, -1.8833e-03, -1.9912e-03,  3.6003e-04,\n",
            "         1.9482e-04, -7.1185e-05,  5.2495e-04, -1.4010e-04, -2.5115e-04,\n",
            "        -1.4147e-03, -1.9951e-03,  4.0521e-04, -1.3267e-03,  1.7719e-03,\n",
            "        -1.5965e-03,  1.8190e-03,  3.0668e-04, -5.7446e-05, -1.4885e-03,\n",
            "         1.5413e-03, -1.2741e-03, -1.5365e-03, -1.8850e-03,  5.4094e-04,\n",
            "         1.8265e-03, -9.0530e-04, -1.6810e-03, -9.4913e-04,  8.1312e-04,\n",
            "         1.7120e-03, -1.9165e-03, -1.3506e-03,  5.2136e-05, -1.3468e-03,\n",
            "        -1.5908e-03, -1.0431e-03,  7.2207e-04,  1.7037e-03,  1.7652e-03,\n",
            "         6.3323e-04, -2.0734e-04,  2.1055e-03,  5.4864e-04,  2.5271e-03,\n",
            "        -2.0353e-03, -1.8414e-04,  2.3747e-03,  8.3997e-04,  8.5165e-04,\n",
            "         5.9542e-04, -1.7268e-04,  2.0372e-03, -2.5278e-04, -8.8410e-04,\n",
            "        -1.9435e-03,  6.4418e-04,  1.2986e-03,  5.7368e-05,  1.4659e-03,\n",
            "        -1.8468e-03, -5.0443e-04, -1.0360e-03, -2.0119e-04,  1.4888e-03,\n",
            "        -2.2919e-04, -1.7767e-03,  3.7742e-04, -6.7137e-04, -1.9909e-03,\n",
            "         6.1312e-04, -1.3281e-03,  7.2885e-04,  6.6329e-04,  3.9055e-04,\n",
            "        -9.2620e-04,  1.3376e-03, -1.0044e-03, -2.4124e-04, -2.2037e-03,\n",
            "         3.3466e-04,  1.6539e-03,  5.0205e-04,  3.9927e-03,  2.5709e-03,\n",
            "         8.7421e-05,  7.2072e-04,  1.2055e-03,  8.3611e-04, -3.6283e-04,\n",
            "         1.0170e-03, -1.4212e-03,  1.1644e-03,  5.9610e-04,  1.2284e-03,\n",
            "         2.0654e-03, -3.6493e-03, -7.8340e-04,  1.0598e-04, -2.5391e-03,\n",
            "         5.2392e-04,  1.3653e-03, -4.0359e-04,  1.4151e-03, -1.7826e-03,\n",
            "        -6.0825e-05, -1.1648e-03, -2.0203e-03,  1.4413e-03,  1.4470e-03,\n",
            "         2.4737e-04,  3.1137e-03,  5.4915e-04, -2.6890e-03, -7.2243e-05,\n",
            "         1.7847e-03, -1.9411e-03,  1.2856e-03,  1.0091e-04, -2.0959e-03,\n",
            "        -5.9277e-04, -3.7560e-03, -2.2916e-03, -1.5523e-04,  1.6471e-03,\n",
            "        -1.2014e-03,  3.7922e-04,  3.1409e-04,  1.7958e-03,  1.7471e-03,\n",
            "         1.0326e-03,  1.3862e-04,  2.9547e-03, -1.5059e-03,  2.6136e-04,\n",
            "         3.5573e-03,  1.6088e-04, -9.9349e-04,  1.4342e-03,  3.8076e-03,\n",
            "        -3.0768e-03,  4.8247e-04, -1.3199e-04, -1.8870e-04, -7.0581e-06,\n",
            "        -1.6876e-03, -1.5097e-04,  1.5296e-03,  7.6371e-04,  3.5388e-03,\n",
            "         1.2738e-03,  2.7125e-03, -1.7180e-03, -5.0271e-04,  2.3081e-03,\n",
            "         7.8351e-04, -1.4124e-03, -4.6389e-04, -6.1341e-05, -1.5784e-04,\n",
            "        -2.0925e-03,  9.1180e-04,  1.5758e-03, -5.2129e-05,  2.0956e-03,\n",
            "        -2.7609e-03, -1.3010e-03,  1.8932e-03, -2.6332e-03, -9.7086e-04,\n",
            "        -6.0733e-04,  7.8723e-04,  1.9800e-03, -1.1430e-04, -1.6437e-03,\n",
            "        -1.2261e-03,  2.8986e-03,  3.6532e-04,  1.4990e-03, -1.8164e-03,\n",
            "         1.9270e-03, -7.1305e-04, -2.2582e-04, -5.5704e-04,  2.1816e-03,\n",
            "        -2.1734e-03,  1.5743e-03, -1.9012e-03,  1.5229e-03, -2.7349e-04,\n",
            "         3.7419e-04, -2.2466e-03,  2.1348e-03, -2.8129e-04,  1.7452e-03,\n",
            "         2.4445e-04, -1.8084e-03, -1.5541e-03,  4.4447e-04, -4.3198e-04,\n",
            "         1.1791e-03, -1.6043e-03,  3.4387e-05,  9.7921e-04, -2.9226e-03,\n",
            "        -1.9111e-03, -1.6829e-03,  3.6656e-04,  2.5762e-04,  5.3816e-04,\n",
            "         1.9312e-04,  9.3247e-05,  9.5333e-04,  6.6739e-05,  3.2227e-03,\n",
            "         7.0169e-04,  1.5162e-04, -1.1214e-03, -1.0945e-03, -3.1271e-05,\n",
            "        -1.7559e-03, -5.5793e-04,  2.2300e-03,  5.7104e-04,  1.0532e-03,\n",
            "        -7.2918e-04, -1.6069e-03,  5.9813e-04,  1.5850e-03, -2.9863e-04,\n",
            "        -2.0963e-03, -1.6545e-03,  1.3276e-03, -1.1017e-03,  1.2021e-03,\n",
            "        -5.1448e-04,  9.3891e-04, -2.3317e-03, -1.9197e-03,  2.3194e-03,\n",
            "        -6.4532e-04, -2.0605e-03, -1.8901e-03, -1.3809e-03, -3.4417e-04,\n",
            "         8.5323e-04, -9.3257e-04, -3.1811e-03, -4.8883e-04,  1.3526e-03,\n",
            "        -1.2445e-03,  4.9810e-04,  3.0605e-03,  8.8337e-04,  4.0356e-04,\n",
            "        -3.4477e-04, -1.3702e-03, -5.0590e-04,  7.7368e-05, -1.2234e-03,\n",
            "         7.1733e-04, -2.6026e-04, -1.0392e-04,  9.9275e-04, -5.0102e-04,\n",
            "        -5.3803e-04, -9.1773e-04,  1.4835e-05, -1.9052e-03,  2.0576e-03,\n",
            "        -4.9771e-04, -1.8489e-03, -7.6054e-04], device='cuda:0')\n",
            "ITEM 3 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male', 'gun', 'gun', 'male']\n",
            "y_hat_labels_str = ['male', 'male', 'gun']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male', 'gun', 'male']\n",
            "y_labels_int_v2 = tensor([89, 68, 89], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.6082, 0.4688, 0.3389, 0.8029],\n",
            "        [0.4615, 0.4375, 0.4856, 0.1995],\n",
            "        [0.3053, 0.5264, 0.3582, 0.7981]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'gun', 'male']\n",
            "y_hat_bboxes_v2 = tensor([[0.6080, 0.4564, 0.3277, 0.7445],\n",
            "        [0.4723, 0.4335, 0.4993, 0.2287],\n",
            "        [0.3189, 0.5434, 0.4053, 0.7869]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0047, 0.6893, 0.0112, 0.0335, 0.0043, 0.0048, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0032, 0.0561, 0.0033, 0.5085, 0.0057, 0.0032, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0039, 0.7482, 0.0093, 0.0337, 0.0034, 0.0039, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 6.1880598068237305 = 0.6390423774719238 + 5.549017429351807\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 4.8170e-04,  3.8459e-04, -1.2181e-03, -8.1199e-04,  2.3852e-05,\n",
            "        -5.5714e-04, -3.1846e-04,  2.5516e-06, -6.5562e-04, -1.6213e-04,\n",
            "        -9.8076e-04, -6.9455e-04, -1.2018e-03, -4.3591e-04,  5.1304e-04,\n",
            "         6.9531e-05, -1.5974e-04, -1.7730e-04,  7.0275e-04, -7.5300e-05,\n",
            "         4.4313e-04, -5.4317e-04, -4.3343e-04, -3.9914e-04,  1.8725e-04,\n",
            "         8.3438e-04,  3.3946e-04,  2.4681e-04,  1.1782e-03, -1.3247e-04,\n",
            "         9.5935e-04,  4.5910e-04,  7.3018e-04, -1.7279e-04, -3.5845e-04,\n",
            "        -2.7123e-05,  6.1401e-04,  8.4584e-05, -4.1621e-04, -2.7482e-04,\n",
            "         3.5140e-04, -1.5907e-04,  6.0367e-04,  1.3378e-03,  3.5465e-04,\n",
            "        -2.3564e-04,  6.6223e-04,  1.9444e-04, -9.7866e-04, -4.8021e-04,\n",
            "         2.1701e-04,  4.3459e-04,  1.0953e-03,  1.2769e-04,  5.9509e-04,\n",
            "        -1.4632e-03, -1.0846e-03,  9.1667e-04, -5.7621e-04, -6.8410e-04,\n",
            "        -1.8461e-04, -6.4636e-04, -3.3262e-04, -2.0798e-04, -1.0313e-03,\n",
            "         1.9578e-03, -6.7600e-05,  1.2707e-04, -1.0010e-04, -1.2042e-04,\n",
            "        -5.7799e-04, -9.4843e-05, -1.2523e-03, -5.2522e-05,  9.5517e-06,\n",
            "        -6.3160e-04, -4.3162e-04,  1.8717e-03, -3.2266e-04, -1.0074e-04,\n",
            "         3.7451e-04,  3.8855e-04, -1.3477e-03, -4.1122e-05,  5.3339e-04,\n",
            "        -2.8824e-04, -3.0353e-04, -7.6781e-04,  6.5361e-04,  6.6335e-04,\n",
            "        -4.9146e-04,  1.7601e-04, -4.2523e-04, -5.0032e-04, -7.3387e-04,\n",
            "         3.0218e-04,  1.0130e-04,  3.2538e-04, -2.3362e-04,  1.3663e-04,\n",
            "         9.6370e-05,  2.3257e-04,  9.0538e-05,  9.0220e-04, -4.7869e-04,\n",
            "         3.2876e-04, -8.8146e-05, -4.7664e-04,  4.6469e-04, -3.2641e-04,\n",
            "        -2.2629e-04,  1.5516e-04,  1.0713e-03,  9.4967e-04, -6.0073e-05,\n",
            "        -1.4280e-04,  3.8449e-04, -2.6012e-04, -2.4242e-04,  1.0555e-03,\n",
            "         2.0790e-04,  6.9776e-04, -3.4200e-04, -5.0715e-04,  1.2154e-03,\n",
            "         8.4630e-04,  4.0859e-05, -1.2047e-05, -3.4706e-05,  6.9108e-04,\n",
            "        -2.7396e-04, -1.0079e-03,  4.8758e-05,  3.8147e-04, -4.7128e-04,\n",
            "         2.3973e-04, -8.8469e-04,  6.0385e-04,  2.1053e-04,  4.8720e-04,\n",
            "        -6.7669e-05, -7.2746e-04, -4.5147e-04,  7.0755e-04, -3.3344e-04,\n",
            "        -3.7392e-05, -2.3022e-04, -6.4298e-04,  6.8819e-05, -9.2983e-05,\n",
            "        -1.1953e-03, -6.3133e-05, -9.4710e-04, -8.7229e-04,  4.0813e-04,\n",
            "         5.0876e-04,  8.7595e-04,  8.4581e-04,  2.5855e-04, -1.3299e-04,\n",
            "         1.0090e-05,  6.9449e-04, -6.7659e-04,  8.1370e-04, -4.9474e-04,\n",
            "        -2.1963e-05, -3.4418e-04, -4.5313e-04,  1.0331e-03, -1.2701e-03,\n",
            "         9.0984e-05, -1.7165e-04,  4.0395e-04,  3.2182e-05,  7.1876e-05,\n",
            "         2.0297e-04,  2.4468e-04, -1.2245e-04,  3.1920e-04, -4.6849e-04,\n",
            "         1.0738e-03, -6.6297e-04, -1.1458e-04,  6.1592e-04,  1.1442e-03,\n",
            "         6.6264e-04, -2.0641e-04, -1.4811e-04, -3.8526e-04,  1.4204e-04,\n",
            "        -6.6205e-05, -2.9787e-04, -4.7033e-04,  8.2727e-05, -3.6608e-04,\n",
            "         2.3888e-04, -8.7811e-04, -3.8968e-04,  1.5788e-04, -1.2972e-04,\n",
            "         5.1658e-04, -3.8025e-04,  7.4687e-05, -1.3000e-04, -2.4186e-04,\n",
            "        -1.4754e-04,  6.1803e-04,  3.5603e-04, -9.6006e-06,  3.7669e-04,\n",
            "        -1.8205e-04, -1.4578e-04, -1.5994e-04,  1.1654e-03,  7.3050e-04,\n",
            "         3.6975e-04, -1.0107e-03, -4.6682e-04,  7.8420e-04,  1.1761e-03,\n",
            "        -4.1396e-04, -1.3293e-03, -2.8402e-04, -1.2884e-03, -1.2190e-04,\n",
            "        -1.1011e-04, -3.2723e-04, -3.6555e-04,  1.0050e-03, -3.5251e-04,\n",
            "         7.8114e-04, -6.8299e-04,  1.1225e-03,  1.5936e-04, -1.3724e-03,\n",
            "         3.4828e-04, -1.4148e-04,  5.4866e-04, -4.3989e-04, -3.0761e-04,\n",
            "         5.3585e-04, -4.0768e-04,  3.8596e-04, -2.7093e-04,  2.6593e-04,\n",
            "         2.0255e-04,  1.3846e-03,  4.8069e-04, -1.7486e-04,  4.5908e-04,\n",
            "         4.2827e-04,  1.6712e-04,  6.3271e-04,  7.1570e-04, -4.8240e-04,\n",
            "         5.9089e-04,  1.1163e-04,  1.2687e-05, -5.6858e-04, -1.5802e-04,\n",
            "         8.4201e-04,  2.5631e-04, -3.5366e-04, -6.8352e-04, -1.5373e-05,\n",
            "        -1.1959e-03,  7.8368e-04,  2.9181e-04,  2.7091e-04,  4.2506e-05,\n",
            "         2.5397e-04, -6.6551e-04, -2.7219e-05,  2.7288e-04,  3.6331e-04,\n",
            "         5.2812e-04,  8.6493e-05, -4.9069e-04, -3.4248e-04, -5.2050e-04,\n",
            "        -6.2545e-05, -1.1726e-03,  1.6998e-04, -6.3192e-04, -5.6453e-05,\n",
            "         6.9058e-04,  2.1216e-04,  1.1310e-03,  5.4031e-04, -5.2391e-04,\n",
            "         8.1224e-04,  7.9310e-05,  2.9280e-05, -2.2069e-04,  3.1055e-04,\n",
            "        -2.4520e-04, -1.9242e-04,  9.5968e-04, -1.4592e-06,  4.6483e-04,\n",
            "         2.4011e-04, -7.5918e-04, -5.7608e-07, -8.0855e-04, -9.8658e-05,\n",
            "         4.2128e-04,  5.7753e-04,  4.1174e-04,  7.2093e-04, -1.1265e-04,\n",
            "         3.5575e-04, -4.6504e-04, -1.3189e-03, -1.5058e-05,  7.2149e-04,\n",
            "         6.2581e-04, -4.2285e-04, -1.1985e-03, -1.0544e-03, -4.4374e-05,\n",
            "         7.2988e-05, -8.7886e-04, -3.9482e-04, -7.0969e-04,  4.4838e-04,\n",
            "         3.3312e-05, -2.5318e-04, -1.7183e-03,  2.6329e-05,  7.3154e-04,\n",
            "        -4.7957e-04,  1.2926e-03,  6.2008e-05, -5.0785e-04,  8.4327e-04,\n",
            "         6.1868e-04,  1.2190e-04, -1.3582e-03, -2.1332e-04,  6.0947e-04,\n",
            "         2.0621e-04, -9.4355e-04,  3.3070e-04,  1.3417e-04, -1.4497e-04,\n",
            "         6.9248e-05,  4.4254e-04, -2.9436e-06,  1.9876e-04, -1.0749e-04,\n",
            "         7.3007e-04,  3.9993e-04,  6.1421e-05,  1.7625e-04, -3.7202e-04,\n",
            "        -1.1024e-04, -4.5853e-04,  2.9512e-04,  4.4509e-04,  2.3365e-04,\n",
            "        -4.4304e-04,  4.5979e-04, -1.0669e-04,  4.7520e-04,  3.4191e-04,\n",
            "         4.1083e-04, -8.6326e-04,  3.2061e-04,  2.9421e-04, -4.9176e-04,\n",
            "        -3.5230e-04, -3.1424e-04, -6.2620e-05, -2.4645e-04,  1.0477e-05,\n",
            "        -3.1787e-04,  1.1362e-04, -1.0984e-03, -1.4826e-04, -5.5667e-04,\n",
            "         3.1702e-04, -4.4037e-04, -2.6623e-04, -6.0760e-04,  2.5910e-06,\n",
            "         1.7641e-04,  6.1422e-04, -5.8732e-04,  5.8562e-04,  1.1286e-03,\n",
            "        -4.4107e-04, -8.8383e-05,  4.0798e-04,  9.3479e-04, -4.9101e-04,\n",
            "        -9.0474e-04,  1.7407e-04,  3.9690e-04, -8.0233e-05, -4.0421e-04,\n",
            "         2.9047e-04, -3.2923e-04, -1.9108e-06,  2.5385e-04, -8.3229e-05,\n",
            "         5.2717e-05, -6.2356e-04, -2.0545e-04,  4.5315e-04, -8.6236e-05,\n",
            "        -2.1389e-04, -1.4486e-04,  8.7534e-04,  1.6001e-04, -1.0660e-03,\n",
            "        -8.8662e-04,  7.2320e-04,  3.0311e-04, -3.0278e-04,  3.4814e-04,\n",
            "         1.3663e-03, -1.6629e-04,  4.0267e-04,  1.1791e-04, -7.0153e-04,\n",
            "        -1.1233e-04,  6.3650e-04, -9.1643e-05, -5.8447e-04,  1.8683e-04,\n",
            "         3.3784e-05,  8.3654e-04, -5.6059e-04, -2.1684e-04,  1.1889e-04,\n",
            "        -1.3920e-04, -2.7641e-04, -2.9437e-04,  5.3698e-04,  7.4981e-04,\n",
            "         3.1911e-04,  1.7046e-04, -7.2830e-04,  5.5050e-04,  1.0589e-04,\n",
            "        -6.7954e-04,  7.2796e-04,  1.3388e-03,  1.1860e-04, -7.3737e-04,\n",
            "        -1.0075e-03,  9.5146e-04,  8.0491e-04, -2.7201e-04, -2.3974e-04,\n",
            "        -2.7990e-04, -7.2957e-05,  1.0769e-04, -1.9019e-05,  6.8672e-06,\n",
            "        -2.2437e-04, -4.5172e-04,  1.2438e-03,  5.2000e-04, -6.5991e-04,\n",
            "         1.2261e-04,  1.8382e-04,  9.6701e-04, -3.0531e-04, -2.7274e-04,\n",
            "         4.0327e-04,  2.9911e-04,  3.6221e-04,  7.0111e-04,  4.3744e-04,\n",
            "        -7.5589e-04, -1.8618e-04, -2.7560e-04, -1.9684e-05,  4.6570e-04,\n",
            "         7.2504e-05,  4.6592e-05,  6.4661e-04,  6.8567e-04,  1.0633e-04,\n",
            "         5.3793e-05, -9.6322e-04,  3.1867e-05, -4.4486e-04, -8.4324e-04,\n",
            "         1.7814e-05,  6.0042e-04, -3.4411e-04, -3.3646e-06, -4.1175e-04,\n",
            "         3.5249e-04, -9.0118e-05,  5.2249e-04,  5.9541e-04, -7.0766e-04,\n",
            "        -8.7378e-04,  6.7897e-04, -6.4855e-04,  8.7536e-05, -2.9533e-04,\n",
            "         2.7343e-04,  2.3433e-04, -2.2453e-04, -3.2428e-04, -2.8664e-04,\n",
            "         5.1303e-04,  3.6834e-04,  6.6533e-04, -3.1486e-04,  1.3331e-04,\n",
            "         3.8849e-04, -8.9836e-04,  3.2682e-04,  1.0008e-03,  1.5626e-06,\n",
            "        -3.4178e-04, -4.0600e-04,  9.8405e-04,  3.1423e-05, -1.0309e-03,\n",
            "        -3.3522e-04, -2.8596e-05,  3.1914e-04,  9.5258e-04,  2.9104e-04,\n",
            "         6.9820e-04,  8.1991e-04,  7.4605e-04, -2.1935e-04, -1.2017e-03,\n",
            "         4.2060e-04,  3.5005e-04, -2.2893e-04, -7.2056e-05, -3.2949e-04,\n",
            "         1.7606e-04, -1.2324e-04,  1.1374e-03,  6.7731e-04, -7.2359e-04,\n",
            "        -3.4176e-05,  2.8241e-04,  3.3908e-04,  5.3100e-04, -6.1502e-04,\n",
            "        -2.2934e-04,  2.8446e-04,  8.0051e-04,  2.8493e-04,  6.0066e-05,\n",
            "        -1.9618e-04,  5.3530e-04, -4.8601e-04,  6.2079e-05, -9.6812e-04,\n",
            "         3.3177e-04, -4.6851e-04, -3.1014e-04,  7.4204e-04, -1.5195e-04,\n",
            "        -1.1354e-03, -1.9713e-04,  6.1885e-04, -3.6812e-04,  3.2273e-04,\n",
            "         6.5495e-04,  2.9699e-04,  7.4548e-04,  2.8871e-04,  4.2970e-04,\n",
            "         4.0385e-04, -5.3726e-04,  5.3001e-04,  1.6583e-04, -4.7838e-04,\n",
            "        -1.1457e-03,  5.7457e-04, -1.9171e-04,  3.3645e-04,  1.3213e-04,\n",
            "         2.1309e-04,  8.1005e-04, -1.2539e-03, -2.7380e-04,  5.7412e-04,\n",
            "         5.5030e-04,  5.3876e-04, -8.4921e-04, -2.5389e-04, -6.1438e-04,\n",
            "        -6.9986e-04, -7.5072e-04,  1.4615e-04, -3.1187e-04,  5.8108e-04,\n",
            "         4.1506e-04, -9.9422e-04,  4.6887e-06, -5.5192e-04, -1.0246e-03,\n",
            "         5.1300e-05,  5.0521e-04,  2.6988e-04, -6.6219e-04, -2.9022e-04,\n",
            "         2.1041e-04,  2.2335e-04, -8.9973e-04, -7.0170e-04, -9.7978e-04,\n",
            "        -6.0729e-05, -2.3419e-04,  2.7070e-04,  1.0571e-04, -2.5646e-04,\n",
            "        -6.4472e-04,  2.3486e-04,  1.3815e-05,  4.4749e-04, -8.1305e-04,\n",
            "         7.7155e-06, -7.3762e-05,  7.6852e-04, -2.3844e-04,  2.2271e-04,\n",
            "        -5.0268e-04,  2.4261e-04, -9.7168e-04, -3.7909e-04,  1.3061e-04,\n",
            "         5.3575e-04,  5.5394e-04, -2.3519e-04,  9.6003e-04,  1.9999e-04,\n",
            "         2.8415e-04, -7.3739e-04, -6.5800e-04,  2.8405e-04, -9.8276e-04,\n",
            "         1.3712e-04,  1.0653e-04,  7.3958e-04, -2.1832e-04, -5.2098e-04,\n",
            "        -1.8693e-04,  4.5833e-04, -1.1417e-03,  4.7542e-04,  5.9211e-04,\n",
            "         8.1127e-04, -7.5663e-04,  1.0481e-03, -4.7709e-04, -2.0599e-05,\n",
            "        -1.6912e-04,  2.3145e-04, -5.3477e-04,  1.4884e-05, -5.4087e-04,\n",
            "        -3.6599e-04, -1.7953e-04, -3.8890e-04,  4.7178e-04,  2.1292e-04,\n",
            "        -6.4075e-05, -3.2373e-04,  5.3241e-04,  8.3271e-04,  6.0608e-04,\n",
            "        -1.8816e-04,  6.4159e-04,  3.1337e-04,  3.4258e-04,  4.8986e-05,\n",
            "         2.3155e-04,  4.1504e-04, -3.1666e-04,  6.5661e-04, -6.4364e-04,\n",
            "        -9.0559e-05, -5.7907e-04, -2.6526e-04,  3.1889e-04, -1.8817e-04,\n",
            "         1.4693e-04, -1.3645e-03,  1.2611e-04, -2.5382e-04,  2.3014e-04,\n",
            "         1.0810e-04, -5.4727e-04, -2.4620e-04, -6.1537e-04, -7.7168e-04,\n",
            "        -5.6659e-05,  6.3011e-04,  6.0657e-04, -8.9159e-05,  1.2104e-04,\n",
            "        -5.0613e-04, -7.0395e-05,  1.4287e-04, -9.4326e-04, -4.0623e-04,\n",
            "        -6.6797e-05,  3.0476e-04,  1.6616e-04,  2.4240e-04, -1.7765e-04,\n",
            "         1.1799e-04, -1.5646e-04, -2.6333e-04, -3.2702e-04, -2.8730e-04,\n",
            "        -1.1342e-04,  1.2228e-04,  1.2491e-03,  6.6146e-04, -2.9758e-05,\n",
            "         1.9530e-05, -5.5323e-04, -4.5677e-06, -1.3083e-05,  1.1136e-03,\n",
            "        -1.0276e-04,  5.5399e-05,  2.4721e-04, -1.6798e-04,  1.0811e-03,\n",
            "         3.8109e-04,  4.1775e-04,  2.3211e-05,  4.5322e-04, -6.3750e-04,\n",
            "        -3.3984e-04, -1.8723e-05, -5.1078e-04,  3.5603e-04, -1.6831e-05,\n",
            "         1.2281e-04, -2.1514e-06, -7.6991e-04, -3.5489e-04, -9.6286e-05,\n",
            "         1.3164e-03, -3.5450e-04, -1.0412e-03,  5.6972e-04, -2.0313e-04,\n",
            "         6.7506e-04,  2.7741e-04, -3.4471e-04, -7.7782e-04, -3.4765e-04,\n",
            "         3.3332e-05, -4.6753e-04, -1.7962e-04,  7.3382e-05,  9.1961e-04,\n",
            "        -1.1502e-04, -1.5422e-04,  6.4003e-04], device='cuda:0')\n",
            "ITEM 4 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['pig', 'pig']\n",
            "y_hat_labels_str = []\n",
            "ITEM 5 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['chair', 'female', 'male', 'bottle', 'male', 'chair', 'pot']\n",
            "y_hat_labels_str = ['female male', 'chair']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['chair']\n",
            "y_labels_int_v2 = tensor([35], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.7236, 0.3005, 0.1899, 0.2861]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['chair']\n",
            "y_hat_bboxes_v2 = tensor([[0.7176, 0.3005, 0.1937, 0.2906]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0035, 0.0255, 0.0016, 0.0471, 0.0034, 0.0664, 0.0048, 0.0285, 0.0024,\n",
            "         0.5161, 0.0061, 0.0035, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.566207408905029 = 0.017627263441681862 + 5.548580169677734\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-8.2768e-06, -8.5198e-06, -2.5743e-05,  3.9100e-05, -2.1299e-05,\n",
            "         8.3342e-06, -5.1791e-05, -1.0676e-05,  2.6653e-05, -3.3630e-05,\n",
            "        -3.9234e-05, -4.2370e-05,  1.6127e-05,  2.9917e-05, -3.9938e-08,\n",
            "         2.7068e-05, -2.2333e-06, -2.2716e-05,  9.1790e-06, -7.1710e-06,\n",
            "         6.3911e-05,  1.9536e-05, -7.8826e-06,  2.5090e-05, -1.9013e-05,\n",
            "         9.8848e-06, -1.5074e-05, -4.8966e-05,  2.3388e-05,  2.4018e-05,\n",
            "        -7.0312e-06, -5.6138e-05, -6.3569e-06,  1.2160e-05,  2.9047e-05,\n",
            "         2.1153e-05, -7.7299e-06, -9.7553e-07,  3.6233e-05,  4.7638e-05,\n",
            "         7.4803e-06,  7.3884e-06,  4.0177e-05, -4.0411e-05,  1.5251e-05,\n",
            "        -2.3282e-05, -6.5642e-05, -2.4041e-05, -7.7378e-06, -5.8361e-07,\n",
            "        -2.0052e-05,  1.2431e-05,  4.6767e-05, -4.0089e-05, -1.1294e-05,\n",
            "        -5.3922e-05, -1.8202e-06, -1.5032e-05,  2.8868e-05,  5.1335e-06,\n",
            "         2.5686e-05,  1.5270e-05, -7.8105e-06, -3.1125e-05,  4.5847e-05,\n",
            "        -3.7119e-06, -3.2093e-05,  3.3904e-05,  1.6296e-05, -6.0116e-06,\n",
            "         3.0372e-05, -1.8543e-06,  8.8960e-06, -2.6674e-05,  3.5777e-05,\n",
            "         1.7010e-05, -2.7457e-05,  4.8865e-06, -4.6487e-05, -1.5659e-05,\n",
            "         3.5788e-05, -1.6313e-05, -2.1625e-05, -1.5154e-06,  2.2877e-05,\n",
            "         1.0734e-05, -4.6581e-05, -7.0506e-05,  7.4126e-06, -1.1983e-05,\n",
            "         1.5960e-05,  4.1385e-06,  2.1309e-05, -1.7100e-05,  4.5502e-05,\n",
            "        -4.6034e-06, -4.5293e-05,  1.0283e-06,  3.7001e-05, -6.3132e-05,\n",
            "         5.1707e-06,  4.0121e-05,  1.2168e-05, -3.9007e-05,  2.5115e-05,\n",
            "         2.1606e-05,  5.0580e-05, -8.1487e-07, -7.3660e-06, -2.7424e-05,\n",
            "         4.4480e-06, -1.5623e-05, -2.1299e-05,  1.8783e-05, -5.4461e-05,\n",
            "        -2.5484e-05, -1.9414e-06,  8.1882e-06,  5.2076e-06, -6.0839e-05,\n",
            "         5.8470e-06, -4.3376e-05,  3.0911e-05, -1.6327e-05,  4.4749e-05,\n",
            "         1.2012e-05, -1.7842e-06, -1.2748e-05,  2.1301e-05,  5.1509e-05,\n",
            "        -1.1184e-05,  5.0974e-06, -1.1652e-05,  4.1253e-05,  2.3317e-05,\n",
            "         1.1885e-05,  5.6823e-05, -3.0014e-06, -1.0981e-05, -4.8274e-05,\n",
            "        -1.3952e-05, -2.8898e-05, -5.3822e-05, -3.2954e-05, -1.6842e-05,\n",
            "        -2.6595e-05,  1.1484e-06,  3.0463e-05, -8.6359e-06, -4.3947e-05,\n",
            "        -2.8916e-05,  2.1324e-05,  3.2369e-05, -1.2853e-05, -7.9536e-06,\n",
            "        -2.2548e-05, -1.9298e-05, -2.8208e-05,  1.7894e-05,  5.9427e-05,\n",
            "        -1.2972e-05, -9.3819e-06,  2.3810e-05,  5.4787e-05,  5.4032e-07,\n",
            "        -1.2767e-05,  1.5041e-05, -4.3744e-05, -5.5924e-05,  5.7717e-06,\n",
            "         1.1605e-05,  3.4304e-06,  4.1392e-05, -3.4800e-05, -2.2934e-05,\n",
            "         5.3386e-06,  1.4786e-05, -1.0396e-05,  9.8344e-06, -2.0829e-05,\n",
            "        -3.4010e-05,  2.5460e-05,  4.1979e-05,  2.9670e-05,  5.9097e-06,\n",
            "        -8.7667e-06,  7.8749e-07,  8.8639e-06,  2.7921e-05,  4.0749e-05,\n",
            "         4.7907e-06, -1.1335e-05,  2.1707e-05, -6.7591e-05, -3.3516e-05,\n",
            "        -1.7499e-05,  9.9767e-06, -3.1302e-05,  3.1246e-05, -4.8726e-05,\n",
            "         2.0637e-05,  3.9859e-07, -5.9529e-05, -1.9348e-05, -8.8020e-06,\n",
            "         2.9022e-06,  1.8729e-05,  1.5395e-05, -1.5118e-05, -1.3768e-05,\n",
            "        -2.4931e-05,  1.3949e-05, -2.2349e-05,  5.2469e-07,  4.0889e-05,\n",
            "         3.0640e-05,  3.7186e-05, -2.5391e-05, -7.3677e-06,  4.2214e-05,\n",
            "        -5.6039e-05, -6.0071e-05, -2.6032e-05,  5.7516e-06, -2.1695e-06,\n",
            "         2.8273e-05,  5.6107e-05,  8.7184e-06,  9.3663e-06, -2.3023e-05,\n",
            "         3.2424e-05,  4.3071e-05, -8.9683e-05,  4.6440e-06,  1.8867e-05,\n",
            "         4.2502e-05,  2.9345e-05, -3.6613e-05, -6.7003e-05,  2.6422e-05,\n",
            "         3.7373e-05, -3.4936e-05,  2.5215e-05,  4.6601e-05, -1.6588e-05,\n",
            "        -2.6627e-05,  3.4366e-05,  6.1313e-05, -7.6164e-05,  2.1279e-05,\n",
            "        -3.0029e-05,  9.1052e-05,  1.2225e-05, -2.2692e-05, -4.1034e-05,\n",
            "        -1.3635e-05,  7.3024e-05,  1.6038e-05, -3.6881e-05, -4.1309e-05,\n",
            "        -1.3016e-05,  4.4982e-05,  4.6572e-06,  1.3092e-06,  1.5521e-05,\n",
            "        -1.3647e-05,  2.2094e-05,  4.2777e-06, -1.4229e-05,  1.7993e-05,\n",
            "        -1.1733e-05,  3.1086e-05,  1.2584e-05, -5.2149e-05,  4.7286e-05,\n",
            "         2.2398e-05,  5.1547e-06,  1.3193e-05,  1.9105e-05, -4.5521e-05,\n",
            "         5.3772e-06, -7.1419e-06, -3.2233e-05,  4.8305e-06,  5.6134e-06,\n",
            "        -4.2715e-05,  2.8334e-05,  9.7861e-06, -4.7738e-05, -2.6469e-05,\n",
            "        -8.9705e-06, -6.5425e-05,  3.3717e-06,  4.2849e-07, -1.6706e-05,\n",
            "         1.7205e-05, -4.0774e-05, -5.4597e-05,  6.0109e-05,  3.1077e-05,\n",
            "        -4.5384e-06, -3.2857e-05,  3.8889e-05, -3.2121e-05, -3.1537e-06,\n",
            "         2.8994e-05,  2.8757e-06, -3.6941e-05,  1.4980e-05, -1.2682e-06,\n",
            "         5.0147e-06, -3.8620e-05,  1.7568e-07,  8.9173e-06,  1.3629e-05,\n",
            "         3.7239e-06,  1.0557e-05, -3.9098e-06,  5.8892e-06, -5.7328e-05,\n",
            "        -7.1155e-06, -2.8671e-05,  1.7893e-05, -3.4029e-05, -3.0423e-05,\n",
            "        -1.7295e-05,  1.1824e-06, -2.6876e-05,  1.0915e-05,  1.4634e-05,\n",
            "         2.2472e-05,  6.2947e-05, -5.3800e-06, -2.7204e-05,  1.2195e-05,\n",
            "         2.1407e-06, -7.4298e-05, -5.4615e-05,  1.9783e-05,  1.2038e-05,\n",
            "         4.7386e-05, -5.3155e-05, -5.2829e-07, -3.5948e-05, -6.4738e-06,\n",
            "         7.8708e-05,  2.4471e-05, -3.3100e-05,  1.3085e-05,  2.5206e-05,\n",
            "         3.5767e-05,  5.7760e-06, -3.4792e-06,  3.4044e-05,  5.8758e-06,\n",
            "         2.7613e-06, -1.6128e-05,  2.5042e-05,  5.1056e-05,  4.1314e-05,\n",
            "        -3.5758e-05,  1.5258e-05, -6.3513e-05, -3.0834e-05, -3.7409e-05,\n",
            "         5.4953e-05, -1.1324e-05,  1.6999e-05,  5.0248e-05, -6.8538e-06,\n",
            "         2.6937e-06, -6.0250e-05, -1.6288e-05,  1.3578e-05,  1.8407e-05,\n",
            "         4.1720e-05,  1.5043e-05,  2.0300e-05, -2.0812e-05,  2.0120e-07,\n",
            "         3.7874e-05,  1.3050e-05,  6.1632e-05,  1.0841e-05,  2.1386e-05,\n",
            "        -1.9459e-05,  5.7275e-05, -4.0621e-05,  8.8230e-07, -1.1775e-05,\n",
            "        -1.9148e-05,  4.5363e-05,  1.1584e-05, -1.3823e-05,  9.8557e-06,\n",
            "        -3.1463e-05,  2.9021e-05, -3.6916e-05,  3.3417e-05, -8.1919e-06,\n",
            "         3.7330e-05,  6.9964e-06, -9.9219e-05, -1.5116e-05,  2.8033e-06,\n",
            "        -1.6429e-05,  6.3328e-06, -3.0006e-06, -1.6660e-05,  2.7174e-05,\n",
            "        -1.6951e-05,  9.9951e-06, -5.8610e-05, -3.4324e-05, -2.6330e-05,\n",
            "        -4.8614e-06,  1.5714e-05, -5.2729e-05, -3.8195e-05,  1.2026e-05,\n",
            "         1.0099e-05,  3.1513e-06, -3.8647e-05,  3.8477e-05,  3.3669e-05,\n",
            "         2.2392e-05,  6.2044e-05, -4.5468e-05, -3.3659e-05, -1.2420e-06,\n",
            "         9.8916e-06,  2.6476e-05, -7.8561e-06, -5.2291e-05, -2.3423e-05,\n",
            "         5.8057e-05,  2.4161e-05, -2.4217e-05, -2.5573e-06, -5.5075e-06,\n",
            "         5.0564e-06, -1.3559e-05,  2.0519e-06,  2.5229e-05, -3.8365e-06,\n",
            "         4.4390e-05,  3.7493e-05,  1.5441e-05,  7.8593e-06, -2.0802e-05,\n",
            "         2.4618e-06,  1.8045e-05,  2.9658e-05,  5.3038e-05, -5.1572e-06,\n",
            "         2.1475e-05, -1.5553e-06,  9.1460e-05, -2.1139e-05, -4.8135e-05,\n",
            "         3.7588e-05, -1.8101e-05, -2.0260e-05, -2.7022e-05,  2.8876e-05,\n",
            "         5.5223e-06, -3.4985e-05, -1.5289e-06,  7.8981e-06,  5.6319e-08,\n",
            "         2.9442e-05,  5.1698e-06, -1.9101e-05,  1.6211e-05,  3.6716e-05,\n",
            "        -5.1289e-06,  1.6332e-05, -2.0291e-05, -4.9064e-05,  1.1902e-05,\n",
            "         2.0592e-05, -3.3907e-05,  4.8808e-08,  3.8321e-05,  8.3313e-06,\n",
            "         5.3907e-05, -1.0019e-05,  4.6314e-05,  1.4440e-05, -6.9280e-05,\n",
            "        -3.1175e-05, -6.4010e-07,  2.9432e-06,  5.5605e-05,  2.0332e-05,\n",
            "        -7.0119e-05, -2.3751e-05,  8.8490e-07, -2.6352e-05,  3.4676e-05,\n",
            "        -3.7018e-05,  2.7824e-05, -4.4000e-05, -3.0014e-06, -9.0727e-06,\n",
            "         2.4573e-05,  3.7761e-05, -3.8323e-06,  5.1330e-06, -1.7343e-05,\n",
            "         2.2011e-05, -1.3286e-05,  4.0169e-05,  3.3046e-06,  1.1915e-05,\n",
            "         6.5873e-06, -3.1566e-05, -4.9678e-05, -1.3933e-05, -9.8211e-06,\n",
            "         1.3030e-05,  6.7333e-05, -2.3142e-05, -7.2087e-05, -3.9037e-05,\n",
            "         4.4755e-05,  1.4350e-05, -7.8800e-06,  4.9709e-05, -1.0747e-05,\n",
            "        -2.1163e-05,  4.5308e-05,  2.3558e-05,  4.5286e-05,  4.3826e-05,\n",
            "         2.9933e-05,  9.7703e-06, -9.1695e-06,  6.6505e-06,  9.5944e-06,\n",
            "         2.6569e-05, -3.4228e-06, -2.9922e-06,  2.1496e-05, -2.3411e-05,\n",
            "         2.2795e-05, -1.8248e-05, -1.6530e-05,  1.8830e-05,  3.2619e-05,\n",
            "        -2.9083e-05, -4.9602e-05, -1.2743e-05,  4.1009e-06,  3.3274e-05,\n",
            "        -1.8965e-05, -5.7184e-05,  2.3927e-05,  2.8788e-05,  5.7473e-05,\n",
            "        -3.3404e-05,  2.7071e-06, -1.9411e-05,  2.7833e-05, -2.7381e-05,\n",
            "         1.8459e-05,  8.8729e-06, -9.5510e-07,  2.0217e-05,  3.6380e-05,\n",
            "        -1.0648e-05,  2.6801e-05,  1.4700e-05,  2.9396e-06,  2.7100e-05,\n",
            "        -1.7322e-07, -6.7733e-06,  3.9422e-05,  5.9114e-06,  2.2411e-05,\n",
            "         7.2383e-06, -7.1159e-06,  2.7591e-05, -1.6165e-05, -4.4466e-05,\n",
            "         4.5692e-05,  1.2594e-05, -3.5569e-05,  2.1841e-05, -2.9476e-05,\n",
            "        -3.5311e-08, -4.7663e-05, -6.9862e-05,  5.9509e-07, -3.7333e-05,\n",
            "         4.3564e-06, -3.5644e-05,  3.5377e-06, -2.4539e-05, -4.2920e-05,\n",
            "        -2.4649e-05, -2.2126e-05,  1.6418e-05,  9.9331e-07, -3.0477e-05,\n",
            "         3.2343e-05,  5.6739e-05, -1.6316e-05, -8.4122e-06, -3.3579e-05,\n",
            "        -1.5937e-05, -7.2496e-07, -3.7453e-06, -1.3555e-05,  3.7850e-05,\n",
            "        -9.1013e-06,  9.6800e-06, -5.1804e-05,  3.3767e-05,  4.4360e-05,\n",
            "        -4.0611e-05, -2.2497e-05,  4.3064e-05,  1.9707e-05,  3.7610e-05,\n",
            "        -3.3287e-05, -2.2722e-05, -1.0336e-05, -2.0694e-05, -1.2168e-05,\n",
            "         2.2336e-05, -2.8566e-05,  1.1059e-05, -1.6845e-05,  3.9931e-05,\n",
            "         3.5356e-07,  6.2520e-05,  2.7862e-05, -6.7477e-06,  3.0184e-05,\n",
            "        -2.4171e-05, -1.9836e-05, -1.7610e-05, -2.1494e-05,  2.7738e-05,\n",
            "        -2.2351e-05, -1.1278e-05, -3.9220e-05, -2.9598e-05,  2.1787e-05,\n",
            "         4.3230e-05,  2.1154e-05, -2.7887e-05, -5.0740e-06,  2.6837e-05,\n",
            "         1.4829e-05, -3.8559e-05,  7.0819e-06,  3.5447e-05, -2.6574e-05,\n",
            "         8.2004e-05,  3.7217e-05, -2.5908e-05,  4.7689e-06, -3.4090e-05,\n",
            "        -5.9455e-05, -5.1020e-06,  2.4407e-05, -7.7380e-06, -2.2235e-05,\n",
            "        -4.6311e-06, -1.3923e-05,  7.0938e-06,  2.0528e-05, -7.6850e-06,\n",
            "        -1.4809e-05,  5.4215e-05,  1.9766e-05,  2.8488e-05,  4.4061e-05,\n",
            "        -1.2461e-05,  1.0466e-05,  2.4612e-05, -1.3263e-05, -3.9954e-05,\n",
            "         3.1661e-06, -3.8593e-07,  6.6247e-06,  3.6315e-05,  4.2957e-05,\n",
            "         1.1171e-06, -2.0936e-05,  2.7326e-05,  7.7657e-06,  6.8488e-06,\n",
            "        -3.0130e-06,  3.9411e-05, -1.8678e-05, -5.6071e-05, -9.5505e-06,\n",
            "        -2.1918e-05,  7.7437e-06, -1.2472e-05, -4.5295e-05,  3.1497e-05,\n",
            "        -3.2232e-05,  6.6487e-06,  4.3435e-05, -2.1042e-05, -5.1948e-06,\n",
            "        -2.9237e-05, -4.9445e-05, -2.5500e-06, -1.0853e-05,  1.3888e-05,\n",
            "        -3.1609e-05,  1.6254e-05, -2.5219e-05,  2.6654e-06, -2.0983e-06,\n",
            "        -8.0747e-07,  1.6950e-05, -1.3836e-05, -8.3593e-06,  2.9977e-05,\n",
            "        -1.9342e-05,  3.5861e-05,  2.0757e-05, -1.2682e-05,  1.5411e-05,\n",
            "         5.7961e-05,  2.3272e-06,  2.5391e-05, -7.6683e-06, -4.3201e-05,\n",
            "        -8.8799e-06,  7.2078e-06,  1.9504e-05, -3.3866e-05,  2.1190e-05,\n",
            "         9.9986e-06,  3.1057e-05, -2.0050e-05, -2.8656e-05, -3.2397e-05,\n",
            "        -4.3046e-05, -1.3924e-05, -3.1206e-06,  2.3993e-05, -1.8844e-05,\n",
            "        -1.7653e-05, -2.7422e-06, -3.1975e-05,  4.3746e-05,  1.1892e-05,\n",
            "        -3.4739e-05, -4.1660e-05, -1.8180e-05, -3.5641e-05, -8.4334e-06,\n",
            "         4.9430e-06,  6.8756e-06,  2.2285e-05,  4.3415e-05, -1.2813e-05,\n",
            "         2.6798e-05, -5.4338e-05,  4.6858e-05], device='cuda:0')\n",
            "ITEM 6 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male', 'male']\n",
            "y_hat_labels_str = ['male', 'male']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male', 'male']\n",
            "y_labels_int_v2 = tensor([89, 89], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.7825, 0.4856, 0.2668, 0.4495],\n",
            "        [0.5337, 0.4844, 0.3966, 0.5817]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'male']\n",
            "y_hat_bboxes_v2 = tensor([[0.7909, 0.4837, 0.2651, 0.4478],\n",
            "        [0.5125, 0.4882, 0.3765, 0.5913]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0056, 0.6935, 0.0116, 0.0056, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0053, 0.8766, 0.0148, 0.0053, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.680066108703613 = 0.1301119029521942 + 5.549954414367676\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 7.6990e-03, -5.0872e-03,  3.6654e-03,  2.5811e-03, -3.9294e-03,\n",
            "         1.2287e-03, -1.4822e-03, -5.5484e-03,  2.6339e-03, -3.6201e-04,\n",
            "        -2.1103e-03,  4.2207e-03, -3.9025e-03,  4.0228e-03, -1.9189e-03,\n",
            "         2.2024e-03,  1.0635e-03,  6.3086e-04, -2.0256e-03, -8.8221e-04,\n",
            "         1.4638e-03, -1.9352e-03,  3.0507e-03,  7.8182e-04,  2.0847e-03,\n",
            "         6.8033e-04, -3.7719e-03,  8.1941e-04, -7.9351e-03, -1.5131e-03,\n",
            "        -1.4677e-03, -3.3518e-03, -6.6864e-03, -4.9892e-04,  7.8062e-04,\n",
            "         2.0492e-03, -7.2781e-04,  4.9424e-04,  5.9350e-03,  3.3906e-03,\n",
            "        -2.8570e-03, -3.9064e-03,  2.7549e-03,  6.0376e-05, -1.2264e-04,\n",
            "         2.1764e-04, -8.3069e-03, -6.3571e-05,  8.5266e-04, -3.8245e-03,\n",
            "        -2.1443e-03,  1.9774e-03, -5.0054e-05, -1.5429e-03, -4.0753e-03,\n",
            "         3.3348e-03, -1.0091e-03, -1.2145e-03,  4.9031e-03,  4.4995e-03,\n",
            "        -1.8168e-03,  2.4929e-03,  3.4478e-03, -1.4736e-03,  1.8709e-03,\n",
            "        -6.4165e-03, -5.1497e-03, -2.8267e-03,  1.3846e-03,  4.7060e-03,\n",
            "         1.7878e-03, -8.2390e-03,  6.2438e-03,  1.4608e-03,  4.1617e-03,\n",
            "        -9.6067e-04, -3.7348e-03, -5.5068e-03,  5.1128e-04, -3.9284e-04,\n",
            "        -2.5100e-03, -1.2278e-03,  2.1974e-03,  2.3667e-03,  9.8839e-04,\n",
            "        -2.8599e-03,  3.4090e-03,  6.2881e-04, -1.6943e-03,  3.7849e-03,\n",
            "        -2.1856e-03, -4.6171e-04, -2.6127e-03, -1.1583e-03,  7.7248e-04,\n",
            "        -4.0634e-03, -3.5377e-03, -2.0909e-03, -3.8618e-03, -3.1025e-03,\n",
            "         4.4164e-03, -1.7440e-03, -4.2299e-04, -3.5778e-04,  2.6149e-03,\n",
            "        -1.1241e-03,  4.8445e-03, -5.3873e-03, -7.1443e-04, -2.3459e-03,\n",
            "         1.4827e-03, -2.1478e-04,  2.3713e-03, -4.1368e-03,  1.9366e-04,\n",
            "        -1.9246e-03, -1.8596e-03, -4.0936e-05,  1.0349e-03,  2.4692e-03,\n",
            "        -1.8538e-03, -1.1666e-03, -3.4936e-03,  3.9102e-03, -1.0624e-03,\n",
            "         7.2986e-03,  1.5079e-03,  4.0697e-03,  2.0928e-04, -2.6636e-03,\n",
            "         1.5196e-03,  2.4567e-03, -1.9681e-04, -3.1709e-03, -3.6442e-03,\n",
            "        -1.3545e-03,  2.8956e-03, -1.9827e-03,  1.9188e-03,  6.6456e-04,\n",
            "         2.9352e-03, -4.4475e-05, -7.3551e-04, -5.4977e-04,  1.9987e-04,\n",
            "        -2.2336e-03,  1.1564e-03,  3.5571e-03, -4.8105e-04,  1.6672e-03,\n",
            "         2.9432e-03,  2.1656e-03,  5.0513e-03,  5.7843e-04, -4.1433e-03,\n",
            "        -3.2109e-04, -2.8834e-03,  1.1296e-03,  4.2585e-04, -2.4237e-03,\n",
            "         2.6000e-03,  1.6910e-03,  2.2333e-03, -6.5029e-03, -1.8992e-03,\n",
            "        -1.6685e-03,  9.7017e-06,  5.7174e-04,  1.6593e-04,  4.6686e-03,\n",
            "         6.5152e-04,  4.4103e-03,  1.6554e-03, -8.8211e-04,  9.1347e-04,\n",
            "         6.4352e-04, -2.1890e-04, -4.5095e-03,  7.2487e-03,  3.7331e-03,\n",
            "        -4.0550e-03,  1.1538e-03,  7.8916e-04,  1.0270e-03,  4.0165e-03,\n",
            "        -1.3249e-03, -1.1055e-03,  4.4790e-03,  3.4413e-03,  1.1513e-03,\n",
            "         2.6405e-03,  3.4208e-03,  3.1612e-03, -3.3164e-03,  4.3350e-04,\n",
            "        -8.1082e-03,  5.1415e-04,  1.2646e-03, -1.6286e-03, -3.0435e-03,\n",
            "        -3.7456e-04, -6.3713e-04,  4.2004e-03,  1.3791e-03,  2.6474e-04,\n",
            "         1.8174e-03, -1.1873e-03, -2.5397e-03,  3.3023e-03,  6.6212e-03,\n",
            "         1.9347e-03,  6.5188e-03, -4.1590e-04,  1.0297e-03, -3.3044e-03,\n",
            "        -6.4216e-03,  3.8892e-03,  1.5454e-04,  4.6457e-04, -6.8876e-04,\n",
            "         3.0687e-03,  1.3872e-03, -3.4223e-03,  1.2499e-03, -1.5288e-03,\n",
            "         3.9510e-03,  7.5370e-04,  2.4885e-03, -1.4181e-04,  2.9292e-03,\n",
            "        -2.7480e-03,  3.0524e-04, -8.2672e-03, -1.6264e-03, -1.3248e-03,\n",
            "         9.1026e-04, -1.2268e-05,  2.9300e-04,  6.5259e-03,  3.3059e-03,\n",
            "         3.5144e-03,  1.3097e-03,  8.7167e-04,  1.1445e-03,  5.2706e-04,\n",
            "         2.2320e-04, -3.1128e-04,  3.6166e-03,  1.8774e-03,  4.9853e-04,\n",
            "        -7.4220e-04,  1.8669e-03, -6.7810e-04, -1.2821e-03,  3.2616e-03,\n",
            "        -2.8432e-03, -5.7539e-03,  2.5165e-03, -6.7192e-03,  2.4478e-03,\n",
            "        -3.3251e-03,  4.8283e-04,  8.1970e-04, -4.6024e-05, -1.3123e-03,\n",
            "        -2.4069e-03, -1.4996e-05, -3.6721e-03,  2.2057e-03,  1.3118e-03,\n",
            "        -5.3961e-05, -6.4811e-04, -1.7470e-03, -3.9853e-03, -6.6594e-04,\n",
            "        -2.0560e-03,  6.4812e-04, -3.0880e-03,  2.7876e-03,  1.8515e-03,\n",
            "         1.3697e-03,  4.9774e-03,  5.8393e-04,  6.2389e-03,  2.9821e-03,\n",
            "        -2.8925e-03, -4.2810e-03, -2.6060e-03, -2.5036e-03, -4.2260e-04,\n",
            "        -4.7834e-03, -9.2862e-04, -2.6827e-03, -1.5973e-03,  1.8210e-03,\n",
            "         2.4836e-03, -1.9683e-03, -6.1812e-03, -1.5930e-04,  2.2124e-03,\n",
            "         4.0410e-04, -7.6411e-04, -5.3253e-03,  4.0019e-03, -3.5030e-03,\n",
            "        -1.1022e-03,  1.6871e-03, -4.7406e-04, -3.9058e-03, -2.3826e-03,\n",
            "         2.3627e-03, -2.8964e-03,  5.4259e-03, -1.0606e-04, -3.1733e-03,\n",
            "        -4.0783e-03, -4.2291e-03,  7.7594e-03,  2.0512e-03, -1.0946e-03,\n",
            "        -1.8296e-03, -2.4015e-03,  1.5388e-03,  1.9456e-03,  2.5628e-03,\n",
            "        -2.3956e-04,  1.6912e-03, -2.3084e-03, -3.0752e-05, -7.1188e-03,\n",
            "         6.6559e-04, -4.6144e-03,  3.9896e-03, -2.4631e-03,  2.4199e-03,\n",
            "        -4.1509e-03, -3.9446e-03, -1.6821e-03,  2.3906e-03, -4.8542e-04,\n",
            "         5.2795e-04,  2.9562e-04,  1.2083e-03, -1.9038e-03, -5.5826e-04,\n",
            "        -1.7553e-03,  2.1905e-04,  4.3610e-03, -4.3747e-03,  1.9170e-04,\n",
            "         5.4693e-04, -2.5672e-03,  3.7808e-03, -5.3335e-04,  2.2127e-05,\n",
            "         6.2863e-03,  3.3614e-03, -2.5798e-03, -3.4227e-04,  3.9192e-03,\n",
            "         1.1505e-03,  3.8690e-03,  4.3531e-04, -3.3378e-04,  1.3505e-03,\n",
            "        -7.0285e-04,  4.2240e-04,  2.7198e-03, -6.4715e-04,  1.2875e-03,\n",
            "         4.4233e-04, -3.9428e-03,  1.5187e-05, -1.2282e-05, -1.6558e-03,\n",
            "         1.6151e-03, -2.0653e-03,  5.4568e-03,  5.1293e-03, -2.6131e-04,\n",
            "         3.7838e-03, -3.1794e-03,  2.3052e-03,  1.0916e-03,  1.8743e-03,\n",
            "        -1.6192e-03, -1.4834e-03,  6.6330e-04,  7.5241e-04,  2.4596e-03,\n",
            "         2.5456e-03, -8.2578e-05, -1.8166e-03, -5.3227e-03, -9.0751e-04,\n",
            "         2.3389e-03, -6.2050e-05, -1.1893e-03,  2.1332e-03, -4.1575e-03,\n",
            "        -7.7239e-04,  3.5425e-03, -3.0315e-03,  4.1349e-04,  7.7880e-04,\n",
            "        -1.6988e-03, -1.7141e-03, -1.8216e-04,  7.2638e-04,  3.2695e-04,\n",
            "         1.8935e-03, -2.4818e-03, -3.7666e-03,  2.7561e-03,  2.2298e-03,\n",
            "         1.6883e-03,  1.4494e-03, -3.5074e-03,  9.7151e-04, -9.8558e-04,\n",
            "        -9.4407e-04,  8.9140e-04, -3.6327e-04, -1.6939e-03,  1.0138e-03,\n",
            "         2.0128e-03, -2.4519e-03, -9.5410e-04,  6.3707e-03,  2.5596e-03,\n",
            "        -4.6169e-03,  4.5281e-04, -1.7590e-03, -1.8647e-03, -3.7297e-03,\n",
            "         3.6685e-04,  2.4778e-03, -8.0451e-04,  1.4546e-03, -4.5591e-03,\n",
            "         3.3007e-04, -2.2182e-03, -3.6760e-03, -1.9722e-03, -1.5769e-04,\n",
            "         4.1266e-03,  3.9509e-03, -4.6038e-03,  1.1736e-03,  5.0506e-03,\n",
            "        -1.1492e-03,  3.9279e-03, -2.8451e-03, -2.4134e-04, -2.2773e-03,\n",
            "         3.3379e-03,  2.7920e-05,  5.2561e-03,  2.2676e-03, -9.3662e-04,\n",
            "         1.4914e-03,  4.2835e-03, -3.6797e-03, -5.7451e-03, -6.1823e-04,\n",
            "         5.5024e-04, -2.9130e-03,  1.9177e-03, -2.1067e-03, -1.0397e-03,\n",
            "        -1.3573e-04, -4.1069e-03,  4.3385e-03,  2.4298e-03,  4.5662e-04,\n",
            "        -3.1457e-04, -3.7485e-03,  1.3283e-03, -2.6710e-03,  1.2748e-04,\n",
            "         1.2964e-03, -3.2914e-03,  1.2299e-03, -4.0960e-03, -7.6296e-04,\n",
            "         1.3385e-03,  2.3175e-03,  2.9305e-03, -7.4690e-04, -1.0241e-03,\n",
            "         1.6192e-03, -1.4473e-03, -5.4716e-03, -5.0642e-03,  3.1133e-03,\n",
            "         1.2802e-04,  2.1759e-03, -6.0521e-04, -7.1888e-03,  1.9448e-03,\n",
            "         3.3169e-04,  3.2064e-03,  1.1027e-03,  2.4324e-03,  3.1490e-03,\n",
            "        -6.1435e-04,  1.3213e-03,  2.3014e-03,  1.9969e-03, -2.1248e-03,\n",
            "         8.0716e-05,  2.8196e-03, -3.1164e-03, -3.5590e-04, -1.2942e-03,\n",
            "        -3.3483e-03,  2.3987e-03,  2.0030e-03, -5.0863e-03,  2.5901e-03,\n",
            "         1.4954e-03, -3.7249e-04, -4.3801e-03,  1.5498e-03,  3.1092e-04,\n",
            "         3.1596e-03, -2.0527e-03, -3.8233e-03, -2.2866e-03, -6.9357e-04,\n",
            "         1.1839e-03, -1.6161e-03, -2.7894e-03,  1.5903e-03,  1.8523e-03,\n",
            "        -1.0303e-03, -3.7685e-03,  1.8404e-03,  5.0730e-03, -7.9035e-04,\n",
            "         3.0749e-03,  3.6233e-04, -7.4764e-03, -7.4834e-04,  5.0545e-04,\n",
            "        -1.9952e-03, -2.3280e-03,  2.9750e-03,  1.0065e-03, -2.3020e-03,\n",
            "        -5.3985e-03, -7.2636e-04, -2.0713e-03,  2.6492e-04, -3.9541e-03,\n",
            "        -2.9080e-04, -2.8636e-03,  5.3305e-03, -4.0888e-03,  5.1824e-03,\n",
            "        -2.3534e-03,  2.9256e-03, -1.3241e-03,  1.4679e-03,  3.0291e-03,\n",
            "        -7.2563e-04, -6.1431e-04, -2.6539e-03, -1.2515e-03, -1.7910e-03,\n",
            "        -3.3963e-03, -5.2551e-04,  2.6660e-03,  2.0952e-03, -2.7649e-03,\n",
            "        -6.5550e-04,  4.9790e-03, -4.2317e-03, -5.4925e-03,  1.9277e-03,\n",
            "         3.9675e-03,  1.3230e-03, -1.4590e-03, -3.7113e-03, -3.1140e-03,\n",
            "         5.7173e-04, -8.2593e-04,  7.6303e-04, -1.1668e-03, -1.6574e-03,\n",
            "        -3.8587e-03, -5.0555e-04, -1.4650e-04, -3.2947e-04, -3.2955e-03,\n",
            "        -1.9710e-03, -4.1834e-04, -2.4996e-03, -3.6792e-03, -5.7865e-03,\n",
            "        -7.2664e-04,  2.3488e-03,  2.8753e-03,  2.8665e-03,  1.3107e-03,\n",
            "        -1.2350e-03,  7.8153e-04, -1.5450e-03,  1.1390e-03,  3.6427e-03,\n",
            "        -2.1285e-04, -2.4071e-03,  2.6834e-05,  2.6317e-03,  4.4901e-03,\n",
            "         2.9951e-03,  2.3649e-03,  3.6149e-03,  2.5277e-03, -1.5850e-04,\n",
            "         2.9817e-03, -1.4053e-03, -2.7184e-03, -1.5215e-03, -6.0302e-04,\n",
            "         1.3199e-03,  3.0495e-04, -4.3410e-03,  3.0356e-03, -8.5543e-04,\n",
            "         5.3877e-03, -6.8514e-04,  3.7956e-03,  1.3206e-03,  2.4108e-03,\n",
            "        -1.4199e-03, -7.3328e-04,  1.8110e-03, -4.9246e-03, -2.7245e-03,\n",
            "        -1.2890e-03,  1.8051e-03,  1.1656e-03,  3.4376e-03,  1.2272e-03,\n",
            "        -1.5386e-03, -6.1991e-03, -3.9026e-03,  2.5819e-03, -3.5694e-03,\n",
            "         4.9139e-03, -5.2212e-04,  3.2214e-03, -2.7039e-03, -1.4790e-03,\n",
            "        -1.2544e-03,  3.0772e-03, -1.3367e-03, -1.3115e-04,  3.5148e-05,\n",
            "         7.0681e-03, -1.4874e-04, -4.0194e-03,  2.7681e-03,  3.6164e-03,\n",
            "        -3.2649e-03, -5.5190e-04,  2.6100e-03,  5.7632e-03, -2.5290e-03,\n",
            "         5.1959e-03, -1.2597e-03,  4.9797e-04, -1.4620e-03, -4.2353e-03,\n",
            "         2.3497e-03, -3.7824e-03,  1.4311e-03, -3.5445e-03, -1.9011e-04,\n",
            "        -1.0281e-03, -1.2936e-04, -1.8922e-03, -5.6840e-03, -9.6239e-04,\n",
            "         5.2983e-04,  3.4679e-05, -8.8973e-04, -9.6226e-05,  4.9465e-04,\n",
            "         2.4571e-03, -1.6235e-03, -1.4949e-03,  2.8477e-04, -2.1192e-03,\n",
            "         1.1549e-03,  3.2590e-03, -3.0361e-03,  6.0491e-04,  2.3879e-03,\n",
            "         2.6217e-03, -5.2019e-03, -1.6472e-03, -3.5002e-04,  1.7412e-03,\n",
            "         1.9260e-03, -1.8321e-03,  1.1554e-04,  1.8620e-03, -3.3906e-03,\n",
            "        -3.1115e-04, -1.5392e-03, -4.3694e-03,  2.3133e-03,  3.1684e-04,\n",
            "         3.6579e-03, -6.3993e-04, -2.7445e-03, -1.1501e-03,  6.3176e-04,\n",
            "         5.5951e-03, -4.6258e-03, -3.9678e-03, -3.7529e-03,  1.8017e-03,\n",
            "        -1.1885e-03,  2.5209e-03, -1.6907e-04,  4.0901e-03,  3.1749e-03,\n",
            "         3.9648e-03, -1.4693e-03,  1.1802e-03,  3.4709e-03, -5.4397e-04,\n",
            "         1.6086e-03,  6.4457e-04, -3.9821e-03,  1.8024e-03,  7.3066e-03,\n",
            "        -4.3320e-03, -2.7025e-04,  5.0711e-03, -1.1086e-03, -3.0461e-03,\n",
            "        -6.5229e-04,  1.1563e-03, -9.3387e-04,  1.6452e-03, -4.8429e-03,\n",
            "         1.4643e-03,  6.8336e-04,  2.2788e-03, -5.4961e-03,  6.1550e-03,\n",
            "         3.9179e-03,  1.9963e-03,  6.4272e-03,  3.1202e-03, -7.3830e-04,\n",
            "        -1.1432e-03,  4.1037e-03, -7.8297e-04, -5.4660e-04, -7.7244e-04,\n",
            "         7.0669e-04, -5.1693e-04, -9.0832e-03], device='cuda:0')\n",
            "ITEM 7 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male', 'male', 'male']\n",
            "y_hat_labels_str = ['male', 'male']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male', 'male', 'male']\n",
            "y_labels_int_v2 = tensor([89, 89, 89], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4255, 0.5144, 0.0337, 0.1370],\n",
            "        [0.4495, 0.5144, 0.0385, 0.1322],\n",
            "        [0.5216, 0.4784, 0.0889, 0.1827]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'male', 'male']\n",
            "y_hat_bboxes_v2 = tensor([[0.4250, 0.5112, 0.0440, 0.1282],\n",
            "        [0.4250, 0.5112, 0.0440, 0.1282],\n",
            "        [0.5243, 0.4768, 0.0865, 0.1659]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0050, 0.3828, 0.0076, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0050, 0.3828, 0.0076, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0051, 0.4287, 0.0086, 0.0051, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.643260955810547 = 0.09610319882631302 + 5.5471577644348145\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-3.1140e-05,  7.1818e-05, -4.1733e-05,  1.2136e-06,  4.9085e-05,\n",
            "         1.0656e-06, -1.4889e-05, -2.8811e-05,  9.9902e-06,  2.2372e-05,\n",
            "        -7.5938e-05, -2.0617e-05,  3.8562e-06,  2.0405e-05, -7.4000e-06,\n",
            "        -2.8089e-05, -1.2148e-05, -5.4321e-05, -3.0074e-06,  1.9548e-05,\n",
            "         2.6289e-05, -8.7833e-06,  3.9471e-05, -8.9128e-05,  9.2107e-06,\n",
            "         1.3556e-06,  3.0822e-05,  4.4628e-06,  6.5359e-06, -3.6909e-05,\n",
            "         4.1881e-06, -4.2391e-05,  2.7516e-05, -6.8116e-05, -3.6973e-05,\n",
            "        -5.2988e-05,  1.6540e-05,  6.1329e-06,  3.9174e-05,  1.2156e-05,\n",
            "         3.9165e-05,  3.7645e-05, -2.3137e-05,  3.6592e-05,  1.1781e-06,\n",
            "        -6.5019e-05,  2.5254e-05,  1.1638e-06,  2.1179e-06, -4.3340e-05,\n",
            "        -4.5904e-06, -2.2417e-05,  3.5697e-05,  2.9195e-05,  6.5527e-05,\n",
            "        -9.9183e-06, -1.1853e-05, -2.0824e-05, -3.9071e-05, -2.2444e-05,\n",
            "        -4.6709e-05, -7.4889e-06, -5.9509e-05, -3.4851e-05,  1.6049e-06,\n",
            "         3.0676e-06, -1.5755e-06,  5.5756e-05, -8.9693e-06, -1.0475e-05,\n",
            "         1.4420e-06,  6.2869e-05, -1.0873e-05, -5.1660e-05,  4.7111e-07,\n",
            "        -2.8956e-05,  2.5760e-05,  4.3822e-05,  1.7576e-06,  4.2482e-05,\n",
            "        -1.2181e-05,  1.9870e-05, -3.0961e-05, -3.5208e-05,  2.8930e-05,\n",
            "        -4.1735e-05,  2.6478e-05, -2.3335e-06,  4.7346e-05, -5.2692e-05,\n",
            "        -3.4479e-05, -1.7241e-05, -6.4130e-05, -9.6000e-05, -3.2831e-05,\n",
            "         7.1472e-05,  4.1560e-05, -1.8672e-05, -8.9220e-06,  2.1502e-05,\n",
            "        -8.7667e-06, -1.9881e-05,  2.8725e-05, -1.5771e-05, -1.6590e-05,\n",
            "         1.7483e-05, -2.9199e-05,  1.9753e-05,  4.4774e-05, -2.7636e-05,\n",
            "        -9.6025e-06,  3.6390e-05, -3.4568e-05, -2.1439e-05, -3.4304e-06,\n",
            "        -3.7996e-05, -1.2973e-05, -4.7412e-05,  5.6718e-05, -2.3425e-05,\n",
            "        -7.8124e-06,  1.1326e-05, -2.1598e-05,  6.2473e-06, -4.0704e-06,\n",
            "        -1.5723e-05, -4.2982e-05, -2.8911e-05, -2.7753e-05,  3.4873e-05,\n",
            "         1.3505e-05, -3.5382e-06, -3.3596e-05,  1.6022e-05, -1.4407e-05,\n",
            "        -5.0901e-05, -1.2191e-05,  1.9754e-05, -2.7347e-05, -5.0322e-05,\n",
            "        -3.9563e-05, -1.5739e-05,  8.4641e-06, -6.8987e-06,  7.6097e-06,\n",
            "         4.5265e-05, -8.6896e-06, -4.6103e-05,  7.8522e-05,  2.4597e-05,\n",
            "        -2.0069e-05,  1.5442e-05, -5.7706e-06,  4.7890e-05, -3.5027e-07,\n",
            "        -1.9279e-05,  4.2993e-05,  2.6121e-05,  4.1143e-05, -1.5861e-07,\n",
            "        -6.1494e-06,  2.1040e-05, -1.9329e-05,  4.0980e-06, -3.2264e-05,\n",
            "        -5.2292e-05, -4.4728e-05,  4.6323e-05,  4.3133e-06,  2.0720e-05,\n",
            "        -1.5300e-05, -2.2349e-05,  2.4326e-05, -2.3933e-06,  2.8946e-05,\n",
            "        -5.8647e-05,  1.4121e-06, -2.7714e-05,  6.2114e-06,  1.1572e-05,\n",
            "         1.1955e-05, -6.2706e-05, -2.5860e-05, -6.3812e-06, -4.3594e-06,\n",
            "        -6.9346e-05, -2.5042e-05, -1.1521e-05, -4.7526e-06,  3.7462e-05,\n",
            "        -6.6205e-06,  6.6697e-06, -2.7639e-05,  4.0788e-05,  8.4122e-06,\n",
            "         2.8571e-05,  6.0663e-05,  1.4681e-05, -7.9627e-05, -1.8559e-05,\n",
            "        -4.4224e-05, -5.3348e-05, -4.4562e-05,  1.9773e-05, -2.2652e-05,\n",
            "        -2.5121e-05,  2.2933e-05, -5.8791e-06, -5.8350e-05, -2.7891e-05,\n",
            "        -1.2864e-05,  5.1133e-05,  3.3351e-05, -2.4529e-05,  3.7705e-05,\n",
            "         6.4196e-05, -6.0399e-06, -5.3427e-05, -2.8838e-06,  2.2722e-05,\n",
            "        -6.1375e-05,  3.6397e-05,  8.8055e-06,  3.4079e-05,  2.7859e-06,\n",
            "         1.7519e-05, -1.4060e-05,  1.0126e-06, -4.2886e-06, -1.7988e-05,\n",
            "        -1.7052e-05,  1.1551e-05,  1.9329e-05, -2.0452e-05, -1.6156e-05,\n",
            "         3.4134e-05, -3.1655e-05,  2.7933e-05, -4.6951e-05,  1.1078e-05,\n",
            "        -1.0848e-05, -6.0412e-06, -9.2367e-06,  2.3360e-05,  6.1644e-05,\n",
            "        -3.5584e-05,  9.9102e-06,  2.4451e-05,  4.7784e-05, -3.0538e-05,\n",
            "        -4.2323e-05,  1.0392e-05,  3.2996e-05,  2.3516e-05,  1.5629e-06,\n",
            "         1.4574e-05, -4.0054e-06, -2.2687e-05,  6.4822e-05, -2.3256e-05,\n",
            "         4.3487e-06,  2.1289e-05, -9.4908e-06,  3.5137e-06,  1.0085e-05,\n",
            "         5.7910e-05,  4.7025e-05, -1.9362e-06, -3.4932e-05,  2.5812e-05,\n",
            "         4.1246e-06, -2.9098e-05,  1.0486e-05,  4.9075e-06,  1.9432e-05,\n",
            "         3.2019e-05, -1.6512e-05,  2.7716e-05,  1.6031e-05, -6.5086e-05,\n",
            "        -2.9394e-05, -5.1131e-05, -1.4492e-05, -4.9364e-05, -2.6921e-05,\n",
            "         1.8516e-06,  3.6257e-05, -2.0624e-06,  6.2053e-05,  1.5437e-06,\n",
            "         4.7446e-05, -3.2008e-05,  5.8958e-05,  2.3662e-05, -1.8348e-05,\n",
            "         9.3892e-08,  3.0759e-06, -5.3386e-05, -3.0282e-05, -6.0696e-05,\n",
            "         9.1345e-05, -7.9507e-05,  4.2448e-05,  6.7385e-05, -4.8832e-05,\n",
            "         3.9968e-05,  3.6037e-05, -5.6855e-06, -3.8297e-05,  1.9583e-05,\n",
            "        -1.8645e-06,  1.3491e-05, -2.7007e-05,  2.1705e-05,  1.0502e-05,\n",
            "         1.3514e-06, -1.3511e-05, -1.2324e-05, -2.9904e-05,  4.6805e-06,\n",
            "        -2.1567e-05,  4.9155e-05, -4.0195e-05,  1.2576e-05, -3.9506e-05,\n",
            "        -2.7885e-06, -1.8934e-05, -3.2680e-05, -2.0604e-05, -4.3781e-06,\n",
            "         2.7446e-05, -3.9652e-07,  2.6754e-05, -1.3765e-05, -2.1587e-06,\n",
            "        -4.9544e-05,  1.1004e-05, -2.4859e-05, -1.6536e-05,  6.8869e-05,\n",
            "        -3.7905e-05,  5.9627e-06, -2.7029e-05,  8.2168e-06,  1.2565e-05,\n",
            "         5.5937e-06,  1.6155e-05, -7.3291e-05,  7.0239e-06,  3.4334e-05,\n",
            "        -3.2175e-05,  5.8548e-05,  3.7569e-05,  5.2382e-05,  3.3519e-05,\n",
            "         7.3584e-09, -5.6208e-05,  1.4984e-07,  1.9629e-05, -6.1112e-05,\n",
            "        -3.3778e-05, -1.4384e-06,  1.5253e-05, -1.0023e-05,  2.6587e-06,\n",
            "         7.8078e-06,  8.2757e-06, -2.4950e-05,  9.7771e-05,  8.4958e-06,\n",
            "         6.2356e-05,  1.6737e-05, -1.3367e-05, -9.7418e-06,  2.7984e-05,\n",
            "         4.1795e-05,  4.6827e-05,  3.1311e-05, -1.8733e-05, -3.5791e-05,\n",
            "        -9.4082e-07,  2.5760e-05, -2.0870e-05,  2.1144e-06,  5.5450e-05,\n",
            "         8.4754e-06,  2.7260e-05, -3.0875e-05,  3.9086e-05,  2.1805e-05,\n",
            "         6.7364e-06, -7.3662e-06,  2.4046e-05, -2.5437e-05,  4.7073e-05,\n",
            "        -1.8935e-05,  7.6077e-05, -7.7215e-06,  4.4130e-05,  4.4946e-05,\n",
            "         4.6577e-05, -1.6866e-05,  5.3559e-05,  1.3881e-05,  2.1595e-05,\n",
            "         5.7219e-05,  4.6550e-05,  2.3682e-06,  2.5455e-06, -3.9092e-06,\n",
            "        -1.9115e-06,  3.4993e-05,  5.1017e-05, -6.5040e-05, -4.6128e-05,\n",
            "         1.2466e-05,  6.3351e-06,  2.0528e-05, -7.3886e-06, -1.3830e-05,\n",
            "        -8.5159e-06,  5.8386e-06,  1.4047e-05, -5.7892e-05,  1.1939e-05,\n",
            "        -4.9858e-06,  4.4682e-05,  1.1850e-05,  3.1328e-05,  1.0263e-05,\n",
            "         1.1949e-05, -3.1602e-05, -8.4371e-06, -2.2464e-06,  2.5188e-05,\n",
            "         6.5223e-05,  2.1244e-05, -3.2677e-05,  1.6372e-05,  5.9871e-05,\n",
            "        -1.3948e-05,  5.0885e-05,  1.6426e-07,  1.5516e-05,  2.7942e-05,\n",
            "        -4.7406e-05, -3.0569e-06,  4.6071e-05, -3.4759e-05, -6.3819e-05,\n",
            "        -2.0060e-05,  8.7282e-05, -3.1633e-05, -1.9009e-05,  4.7375e-05,\n",
            "        -2.1027e-05,  7.9522e-07, -3.7348e-05,  6.1615e-05, -7.1898e-05,\n",
            "        -7.5400e-06,  1.5034e-05,  3.4944e-05,  1.7946e-05,  5.8637e-07,\n",
            "         1.0577e-06, -1.2024e-05,  3.5702e-05,  3.2011e-05, -4.2881e-05,\n",
            "         1.1069e-05,  5.2574e-06,  4.5437e-05,  3.5533e-05, -1.8464e-05,\n",
            "         3.4610e-05,  4.3854e-08, -3.4773e-06, -1.6330e-05, -5.6420e-05,\n",
            "        -3.7812e-05, -2.0391e-05, -2.7635e-05, -3.7585e-05,  1.6435e-06,\n",
            "         2.2252e-05,  2.9510e-05,  3.2475e-05,  5.2109e-05,  1.2337e-05,\n",
            "        -3.4149e-05, -1.8766e-05, -7.8047e-07, -1.7532e-05, -9.5301e-06,\n",
            "         3.6276e-05, -3.0118e-05,  2.3554e-05,  2.3013e-05,  5.6261e-06,\n",
            "        -2.7980e-05, -6.1879e-05,  1.3910e-05, -4.5021e-05, -2.0695e-05,\n",
            "         5.2562e-05,  2.2554e-05, -8.2705e-06, -5.8585e-05,  1.4775e-05,\n",
            "         1.0158e-05, -1.9017e-05, -4.2047e-05,  4.1615e-05,  2.1701e-05,\n",
            "         1.2958e-05, -3.3540e-05,  4.9111e-06, -2.7665e-05, -1.1618e-04,\n",
            "        -6.7645e-06, -3.2543e-05,  8.5406e-06,  1.3256e-06,  1.5450e-05,\n",
            "        -7.9788e-06, -1.2886e-05,  2.3131e-05,  7.5642e-05,  1.0200e-05,\n",
            "         1.6441e-05,  6.7458e-05,  1.9067e-05, -5.9716e-05,  1.2297e-05,\n",
            "        -1.0268e-05, -4.4737e-06,  2.9689e-05,  3.2183e-07,  8.0631e-06,\n",
            "         2.0949e-05, -6.0604e-05,  2.5451e-05, -3.5849e-05, -1.0008e-05,\n",
            "        -2.0708e-05, -2.5231e-05,  2.2781e-05,  7.8986e-06,  3.3436e-06,\n",
            "        -3.3500e-05, -4.0790e-05,  5.9988e-05, -1.3099e-05, -1.2429e-05,\n",
            "         1.9758e-05, -1.6119e-05,  4.9782e-05,  7.5586e-05,  1.8251e-05,\n",
            "         3.8501e-06,  4.1909e-05, -9.7465e-06, -1.1487e-05,  2.1243e-05,\n",
            "        -4.7380e-05, -3.0886e-05,  4.0154e-05,  4.0319e-05,  7.3986e-07,\n",
            "         3.3314e-05, -9.0545e-05,  2.5819e-05, -3.2408e-05,  1.2779e-05,\n",
            "         3.2334e-05, -3.1123e-05, -4.7935e-08,  1.0044e-05, -4.7619e-05,\n",
            "         5.6300e-06, -2.9033e-05,  6.2673e-05,  6.2047e-05,  1.6743e-05,\n",
            "         1.6812e-05,  3.1420e-05, -1.0269e-05,  6.9379e-05, -5.2099e-05,\n",
            "         1.6499e-05, -2.2623e-05,  3.2003e-06, -1.1055e-05,  1.9360e-05,\n",
            "         1.9656e-05, -5.5685e-05,  8.2101e-06,  3.1187e-05,  2.0174e-05,\n",
            "         4.7207e-05,  3.1101e-05, -7.0714e-06,  3.7371e-06,  1.3937e-05,\n",
            "        -9.4064e-06,  6.1462e-07,  3.1005e-05,  8.8565e-06, -4.4648e-05,\n",
            "         1.2423e-05, -2.5851e-06,  1.0457e-05,  5.3035e-05, -1.4828e-05,\n",
            "         9.3630e-06,  1.8140e-05,  1.5654e-05,  4.7361e-06,  8.7741e-06,\n",
            "         3.4792e-06,  4.9244e-05, -1.4295e-05, -1.5860e-05,  3.1602e-05,\n",
            "        -5.2879e-05,  2.3018e-05, -2.0622e-05, -4.4135e-06,  3.1621e-05,\n",
            "        -7.1829e-05, -1.9467e-05, -4.5830e-05, -1.4931e-06,  7.8513e-07,\n",
            "         2.4793e-05, -1.3964e-06, -4.9121e-06,  3.0350e-05, -3.2881e-05,\n",
            "         2.9268e-05, -4.4647e-05, -6.7450e-05,  3.9315e-05,  1.2315e-05,\n",
            "         2.0332e-05,  2.7421e-05,  1.8518e-05,  4.3733e-06,  4.1026e-05,\n",
            "        -5.4130e-05, -2.8730e-07,  3.5961e-05,  1.9480e-06,  3.1352e-05,\n",
            "         1.5930e-05, -4.5166e-05, -8.4843e-06, -3.0744e-05, -2.9829e-05,\n",
            "        -4.2099e-05,  2.5865e-06, -4.9106e-06,  2.8987e-05,  3.8350e-05,\n",
            "        -1.5798e-05, -8.8757e-06,  2.1081e-05,  3.9283e-06, -2.0814e-05,\n",
            "        -2.6533e-06,  3.3741e-05,  6.4804e-05,  1.0119e-05, -1.2132e-05,\n",
            "        -1.4012e-06, -2.5065e-05, -3.1617e-05, -1.0485e-05,  2.8728e-05,\n",
            "         1.4994e-05, -1.9201e-05, -1.3861e-05, -2.4443e-05,  4.1134e-06,\n",
            "         1.0280e-05,  3.4174e-05, -1.5673e-05,  4.2279e-05, -4.3495e-05,\n",
            "        -5.7976e-05,  1.0644e-05, -4.4960e-05, -1.4430e-05, -6.2812e-05,\n",
            "        -5.1933e-06, -2.2710e-05, -6.9542e-06, -2.2537e-05, -1.0061e-05,\n",
            "        -6.1057e-05,  1.4244e-05,  1.0163e-04,  6.0430e-05,  1.5155e-05,\n",
            "        -5.5562e-06, -1.6459e-05, -4.0007e-07,  1.9492e-05, -4.4496e-05,\n",
            "         1.5170e-05, -2.1471e-05, -5.3931e-06, -3.7613e-08,  7.3679e-06,\n",
            "         3.5088e-05,  1.0611e-06,  1.3264e-05, -5.6128e-05,  2.2518e-05,\n",
            "         1.8162e-05,  1.3980e-05, -1.3000e-05,  3.5891e-05,  1.3658e-05,\n",
            "        -2.2653e-05, -1.6633e-05, -4.6150e-06, -6.6431e-05,  1.3831e-07,\n",
            "        -6.1477e-06, -3.4049e-05,  4.3336e-05,  4.0121e-05, -6.2312e-05,\n",
            "        -7.9498e-07,  2.6170e-06,  3.4053e-05, -3.8446e-05,  1.6882e-07,\n",
            "        -1.5627e-05, -4.8289e-06,  3.1195e-05, -2.3720e-05,  1.9029e-05,\n",
            "        -5.3926e-06, -7.6959e-06,  3.0356e-05, -6.1758e-05, -1.4685e-05,\n",
            "         1.7963e-05, -3.2547e-05, -4.1169e-05,  5.4038e-05, -3.3512e-05,\n",
            "        -4.3701e-05, -4.9870e-06, -5.8454e-06,  4.5930e-05,  3.1483e-05,\n",
            "         6.4951e-05, -1.8894e-05, -3.7681e-05,  5.0485e-05, -7.1619e-06,\n",
            "         6.1661e-06,  2.7878e-05,  4.1347e-05], device='cuda:0')\n",
            "ITEM 8 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['sheep', 'cow', 'bird', 'monkey', 'rhino', 'dog', 'tree', 'tree']\n",
            "y_hat_labels_str = ['tree', 'tree']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['tree', 'tree']\n",
            "y_labels_int_v2 = tensor([148, 148], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4279, 0.3353, 0.1923, 0.3726],\n",
            "        [0.8341, 0.2776, 0.2356, 0.4159]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['tree', 'tree']\n",
            "y_hat_bboxes_v2 = tensor([[0.4306, 0.2890, 0.1890, 0.3129],\n",
            "        [0.8320, 0.4212, 0.2604, 0.7201]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0052, 0.0088, 0.0016, 0.0110, 0.0013, 0.0277, 0.0028, 0.0190, 0.0023,\n",
            "         0.0118, 0.0018, 0.3737, 0.0053, 0.0091, 0.0017, 0.0053, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0045, 0.0063, 0.0014, 0.0056, 0.0010, 0.0188, 0.0023, 0.0132, 0.0019,\n",
            "         0.0081, 0.0014, 0.4141, 0.0045, 0.0066, 0.0013, 0.0045, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 20.483938217163086 = 14.936491966247559 + 5.5474467277526855\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-7.0141e-04,  1.8426e-03,  1.9425e-04, -2.9467e-03,  3.9211e-03,\n",
            "         1.0339e-03,  1.1744e-03,  1.6477e-03,  7.1282e-04, -1.1408e-03,\n",
            "        -1.1929e-04,  1.0280e-03, -2.0217e-03, -9.8881e-04, -2.1792e-04,\n",
            "        -2.2744e-03, -1.9539e-03, -8.0132e-04,  1.9387e-04, -1.7402e-03,\n",
            "        -1.4919e-03, -2.3531e-03,  1.2130e-03,  3.5604e-04, -3.6510e-03,\n",
            "         4.3364e-04,  2.1012e-03, -4.5234e-04, -6.7205e-04,  8.4596e-04,\n",
            "         2.6560e-03,  2.1081e-03, -6.2001e-04,  1.7097e-04, -9.0302e-04,\n",
            "        -1.0089e-03,  1.1041e-03,  1.1054e-03,  7.2562e-04, -1.5431e-03,\n",
            "         1.2291e-03, -2.7127e-03, -3.7493e-03,  1.1700e-03, -1.4984e-03,\n",
            "        -9.9578e-06,  3.1122e-03,  1.9614e-03, -2.1834e-03,  1.9908e-03,\n",
            "        -4.8279e-05,  7.1043e-04,  2.8228e-05,  4.3997e-04,  1.5163e-03,\n",
            "         1.7713e-03, -1.1055e-03,  1.0922e-03, -1.6845e-03, -3.3861e-04,\n",
            "         9.1360e-04,  3.8998e-04, -1.1213e-03,  1.3358e-03,  2.4779e-03,\n",
            "         1.6008e-04,  2.7322e-03,  9.0280e-04,  3.5774e-04, -1.2949e-03,\n",
            "        -3.3158e-03,  2.6939e-03, -1.5667e-03,  7.0795e-04,  3.7743e-04,\n",
            "         1.9372e-03,  7.8349e-04,  1.9588e-03, -1.8677e-03,  2.8422e-03,\n",
            "         1.9559e-04,  3.3599e-04, -5.0118e-03,  6.6784e-04, -1.7601e-03,\n",
            "         1.8610e-03, -6.8219e-04, -9.8722e-05,  1.2518e-03, -1.2280e-03,\n",
            "        -2.2766e-03,  6.8836e-04, -6.3967e-04,  8.8892e-04, -9.9360e-04,\n",
            "         2.8688e-03,  2.1309e-03, -4.1836e-03, -9.6957e-04,  8.9834e-04,\n",
            "         3.1736e-03, -3.6543e-04, -9.6153e-04,  7.0248e-04, -1.6590e-03,\n",
            "         6.7974e-04, -3.1516e-03,  4.7405e-04,  8.8870e-04,  1.6462e-03,\n",
            "         1.7347e-03,  1.0142e-03,  8.9675e-04,  3.1687e-03, -3.0756e-04,\n",
            "        -9.6019e-04, -2.6444e-04, -1.0330e-03,  1.1361e-04,  2.6135e-04,\n",
            "        -1.4247e-03,  8.0759e-04, -1.1613e-03, -4.4608e-04,  6.9238e-04,\n",
            "        -1.9554e-03, -2.0700e-03,  1.7859e-03, -2.2222e-04, -7.6605e-04,\n",
            "        -1.1297e-03,  4.8936e-04,  1.1080e-03, -1.0654e-03, -1.1870e-03,\n",
            "        -2.2461e-03, -1.4198e-03,  1.9970e-03,  3.0127e-04,  2.0893e-04,\n",
            "        -2.9133e-03,  1.4392e-03, -2.2013e-03,  5.1462e-04,  4.7411e-04,\n",
            "         1.6772e-03,  1.2140e-03, -1.7766e-03, -2.2048e-03,  1.7682e-04,\n",
            "        -8.1773e-04, -7.2934e-04,  6.2321e-04, -8.5635e-04,  3.3263e-03,\n",
            "        -8.2111e-04,  2.1179e-03,  1.3981e-03,  2.2215e-03, -1.2668e-03,\n",
            "        -1.9256e-03, -1.9305e-03,  5.4491e-04,  1.8876e-03,  1.4866e-03,\n",
            "        -2.3412e-04, -2.1170e-03,  2.5514e-03,  1.2929e-03,  1.6399e-03,\n",
            "         3.4610e-04,  1.2494e-04,  3.6404e-04, -1.6557e-03,  1.2062e-04,\n",
            "        -1.1255e-03, -2.2393e-03,  1.9241e-03,  3.3454e-04, -2.4702e-04,\n",
            "         1.6877e-03,  5.5592e-04,  1.5360e-03, -3.3527e-04,  2.1165e-03,\n",
            "         2.0029e-03,  4.3944e-04,  1.7815e-03, -1.3429e-03, -9.5016e-05,\n",
            "        -9.2639e-04, -2.8049e-03,  6.9906e-04,  1.6622e-03, -1.0611e-03,\n",
            "         8.1213e-04, -5.6417e-04, -1.3342e-03, -8.6529e-04,  2.8390e-03,\n",
            "        -2.6775e-03, -1.0975e-03, -2.0895e-03,  8.6780e-04, -2.2901e-04,\n",
            "         9.2863e-04,  1.1843e-03, -1.7700e-03,  9.5127e-04,  3.2883e-04,\n",
            "        -1.3582e-04, -9.3405e-06,  1.8467e-03, -7.0411e-04,  1.1171e-03,\n",
            "        -2.1933e-03, -2.9365e-03, -5.7247e-04,  1.0066e-03,  5.3799e-04,\n",
            "        -7.0681e-05, -3.4197e-04,  1.4093e-03, -1.3749e-03, -3.7650e-04,\n",
            "        -3.2056e-04, -5.7584e-04,  5.2750e-04, -7.0922e-04, -1.6942e-03,\n",
            "         1.3014e-03, -3.2982e-03,  3.1820e-03,  1.3307e-04,  1.0977e-03,\n",
            "        -3.2024e-04, -6.8551e-04,  2.6588e-04, -3.4279e-03, -1.5984e-03,\n",
            "        -7.8669e-04,  2.4197e-03, -1.2132e-03,  5.9504e-05,  3.1650e-05,\n",
            "        -4.5943e-04,  8.2395e-04,  1.0364e-03,  2.4094e-04,  1.5977e-03,\n",
            "         2.4788e-03, -1.3488e-03, -1.2433e-04, -1.7562e-03, -2.2481e-03,\n",
            "         7.9889e-04,  4.2833e-04,  3.1983e-03,  1.1922e-03, -1.7068e-03,\n",
            "         1.3471e-03,  1.5773e-03,  4.9194e-04, -6.8459e-04,  1.2309e-03,\n",
            "         8.5290e-04,  8.6199e-04, -1.1813e-03, -1.3021e-04,  1.0158e-04,\n",
            "         2.4685e-03, -2.9179e-03,  1.1481e-03,  1.0712e-03,  2.0627e-03,\n",
            "         3.2601e-04, -2.0526e-03,  1.5301e-03, -9.2884e-04,  9.2507e-04,\n",
            "         2.1598e-04, -5.5557e-04, -1.5078e-03, -7.5800e-04, -7.8143e-05,\n",
            "        -6.6311e-04, -1.0486e-03,  2.8330e-04,  1.7292e-04,  2.1850e-03,\n",
            "         1.6723e-03, -5.4486e-04, -2.1563e-05,  1.4430e-03,  6.7598e-04,\n",
            "         5.0002e-04,  7.2621e-04,  2.2716e-03, -6.4465e-05, -6.1641e-04,\n",
            "        -5.7422e-04,  2.5924e-03,  4.6561e-04, -1.5935e-03,  1.4589e-03,\n",
            "         9.0801e-04, -5.6875e-04, -1.0322e-03, -2.6355e-03,  2.1876e-03,\n",
            "        -3.6591e-03, -4.3452e-04,  7.2241e-04,  8.4406e-05, -2.2545e-04,\n",
            "        -1.0969e-03,  3.7219e-03, -2.1713e-03,  9.2085e-04,  4.7879e-04,\n",
            "         1.9430e-03,  2.6963e-03,  2.0168e-03,  9.9704e-04,  5.1442e-04,\n",
            "         1.8612e-04,  7.3334e-04, -9.4377e-05,  9.6182e-04,  8.0437e-04,\n",
            "         2.0786e-03,  6.2704e-04, -2.1408e-03,  4.6752e-03, -1.3258e-03,\n",
            "        -1.5360e-03,  8.1307e-04,  9.2782e-04, -1.8063e-03,  1.8170e-03,\n",
            "        -9.5308e-04,  2.3980e-04,  2.4914e-04,  1.7173e-03, -1.2672e-03,\n",
            "        -2.1353e-03,  1.4849e-03, -1.9568e-03, -1.1916e-03,  1.9869e-03,\n",
            "         6.8678e-04,  7.9702e-05, -3.8990e-04,  2.3241e-05, -1.4101e-03,\n",
            "        -7.2156e-04, -1.4135e-04, -6.4721e-04, -1.0916e-03, -3.9082e-03,\n",
            "        -1.6369e-03, -2.1930e-04,  2.9381e-03,  2.4109e-04,  1.6754e-04,\n",
            "         8.4024e-04, -5.0534e-04,  3.4455e-04,  1.6522e-03, -2.4561e-03,\n",
            "        -1.8275e-04,  2.4461e-03, -6.5379e-05,  2.2914e-05, -2.5296e-04,\n",
            "         1.4803e-03,  1.9293e-03, -1.3309e-03, -1.6996e-03,  3.7250e-04,\n",
            "        -3.4959e-03, -1.6455e-03, -3.9331e-03, -3.0542e-04,  7.2844e-04,\n",
            "         2.3395e-04,  5.3938e-04, -1.6438e-03, -3.4989e-04,  7.3968e-04,\n",
            "         3.0507e-03, -1.9826e-03,  4.1341e-04,  2.8612e-04, -1.3040e-03,\n",
            "        -8.2562e-04, -1.2264e-03,  1.9066e-04, -2.8749e-03,  1.3417e-03,\n",
            "         1.5866e-03,  7.1413e-04, -2.3217e-03, -2.1824e-03,  1.3015e-03,\n",
            "         7.3284e-04, -1.2140e-03, -6.4340e-04,  1.1597e-03,  3.9652e-04,\n",
            "        -3.9308e-04, -9.0929e-04,  1.0435e-03,  3.1620e-04, -1.5836e-03,\n",
            "         2.1570e-03,  5.1862e-04, -2.3048e-04, -1.0709e-03, -2.6454e-04,\n",
            "        -3.9118e-04,  2.0986e-03,  1.1082e-03,  1.7818e-03, -4.1413e-03,\n",
            "         1.5888e-06, -4.1031e-05,  1.0436e-03, -1.3892e-03, -1.7292e-03,\n",
            "         2.7765e-03, -1.0644e-03,  1.3545e-03,  3.4307e-04,  1.0308e-03,\n",
            "         7.7448e-04, -9.3123e-04,  1.0104e-03,  1.5041e-03,  9.4431e-04,\n",
            "         9.0927e-05,  3.0863e-05,  1.3547e-03, -4.9881e-04,  3.7202e-04,\n",
            "        -7.5655e-04, -2.0448e-03,  1.2922e-03, -1.5820e-03, -2.4564e-03,\n",
            "        -2.6167e-03, -2.0660e-04,  7.8135e-04, -1.4430e-04, -3.4974e-04,\n",
            "         2.2852e-03,  3.2858e-04, -1.5442e-03,  1.2832e-04, -1.7167e-03,\n",
            "        -9.2001e-04,  2.8501e-03,  8.5391e-04,  1.3695e-03,  1.4598e-03,\n",
            "         4.4995e-04, -9.3686e-04,  2.2240e-03,  1.0126e-03,  8.7933e-04,\n",
            "        -1.7207e-03,  1.5582e-03, -1.7274e-03,  2.4685e-03, -1.8236e-03,\n",
            "         4.0543e-04,  2.2327e-04,  8.7235e-04,  1.8576e-03,  3.5119e-04,\n",
            "        -1.4138e-04,  4.0765e-04, -2.4675e-04, -1.4821e-03, -6.7711e-04,\n",
            "        -1.9585e-03,  2.7927e-03, -1.6834e-03,  1.3537e-03,  5.2110e-04,\n",
            "        -3.4233e-03, -3.7506e-06,  1.0715e-03,  9.2002e-04, -7.5489e-04,\n",
            "         3.6769e-04,  1.6376e-03, -1.5088e-03, -1.3603e-03,  9.5105e-05,\n",
            "        -2.1368e-03,  4.0161e-03, -2.6243e-04, -8.9015e-04,  3.7048e-04,\n",
            "        -1.6735e-04,  4.9709e-04, -9.0465e-04,  1.2107e-04,  2.8299e-03,\n",
            "         1.3446e-03,  1.7904e-03, -3.6995e-04, -1.0571e-03, -1.1455e-03,\n",
            "        -5.0262e-04, -4.6226e-03, -7.3050e-05, -6.3729e-04, -4.5050e-04,\n",
            "         2.6193e-03,  2.1161e-04,  5.7957e-04,  1.1447e-04,  2.4683e-03,\n",
            "         1.9151e-04, -3.7074e-04,  2.7099e-04,  1.2292e-03,  9.3736e-04,\n",
            "         4.0662e-04,  1.1387e-04, -4.2854e-03, -2.6738e-03,  4.7896e-04,\n",
            "         1.2024e-03,  4.4930e-04,  2.3582e-03,  7.0146e-04, -4.7386e-04,\n",
            "        -1.6563e-03,  1.6481e-03,  2.8353e-03, -2.6506e-03,  1.3675e-03,\n",
            "        -2.7541e-03,  9.7122e-04,  4.5835e-04, -2.8325e-03,  8.0901e-04,\n",
            "        -1.1304e-03,  1.6333e-03,  1.4999e-03,  2.3893e-04, -1.3364e-03,\n",
            "        -2.4497e-03,  1.1017e-04,  8.8852e-04, -3.7332e-04,  5.5324e-04,\n",
            "         1.3833e-03, -1.3964e-03, -3.9179e-04,  6.0834e-04, -2.0373e-03,\n",
            "        -3.9029e-04, -5.5810e-04,  4.2064e-04,  1.6012e-04,  1.2551e-03,\n",
            "        -9.6882e-04, -1.7958e-03,  5.3423e-04,  8.8130e-04,  1.1020e-03,\n",
            "         1.8460e-03,  1.3111e-03, -9.7187e-04,  2.7598e-04, -2.7759e-03,\n",
            "         5.9799e-04,  3.0785e-04,  1.6582e-03,  1.2037e-03,  1.0243e-03,\n",
            "         1.7976e-03,  3.0718e-04,  3.4847e-04, -1.8733e-04,  1.6651e-03,\n",
            "         2.3200e-03, -4.6594e-04, -3.1974e-03, -8.6403e-04,  4.3744e-03,\n",
            "         1.6428e-03,  7.4912e-04,  7.8731e-04, -3.9569e-04,  4.1954e-04,\n",
            "         2.1959e-03, -5.7609e-04, -5.3203e-04,  7.5893e-05,  1.8184e-03,\n",
            "        -3.3977e-04, -3.9136e-04, -1.0877e-03,  2.3154e-03, -2.4884e-03,\n",
            "         3.9636e-04,  1.0642e-03,  1.0441e-03, -1.1624e-03,  4.2131e-05,\n",
            "         4.0557e-04,  3.0064e-03, -1.5881e-03, -2.6013e-03, -2.1755e-04,\n",
            "         1.0537e-03,  9.9345e-04, -1.8344e-03, -2.4667e-03,  1.7706e-03,\n",
            "         1.4903e-03,  1.6131e-03, -1.1560e-03, -1.5035e-05,  3.3053e-03,\n",
            "        -1.6228e-03,  2.3785e-03, -2.8653e-03,  3.2682e-04, -2.3380e-03,\n",
            "         2.9280e-04, -1.3568e-03,  8.1116e-04,  6.4713e-04, -9.5999e-04,\n",
            "        -2.2397e-04, -1.1621e-03, -2.5107e-03, -1.3013e-03, -1.1905e-04,\n",
            "         7.5353e-04,  1.1283e-03, -1.4576e-04, -2.2714e-04, -1.1826e-03,\n",
            "        -2.0802e-03,  1.3241e-03,  4.3726e-03,  1.8624e-03, -2.8796e-04,\n",
            "        -2.6780e-03,  1.7703e-03,  3.2539e-04, -4.0304e-03,  3.2112e-03,\n",
            "        -3.0849e-03, -1.0570e-03,  1.1593e-03,  1.9800e-03,  2.8124e-03,\n",
            "         6.8923e-04, -4.1422e-04,  1.5593e-03, -1.8904e-03, -2.1495e-04,\n",
            "        -2.4559e-03, -1.4654e-04,  1.2307e-03,  2.3411e-03, -3.8334e-03,\n",
            "         3.5324e-04,  2.4605e-05, -1.1066e-03,  3.5584e-03,  2.8790e-03,\n",
            "         7.1388e-04,  1.6225e-03,  2.7660e-04,  1.5534e-03, -1.5737e-03,\n",
            "         4.6334e-05,  5.8294e-04, -9.3761e-04, -1.1058e-03, -1.1095e-03,\n",
            "         6.7315e-04,  2.5932e-03, -1.2096e-03, -1.4878e-03, -1.1831e-03,\n",
            "         1.4631e-03, -1.5736e-03,  1.6335e-03, -1.1320e-03, -2.8713e-03,\n",
            "         6.1728e-04,  6.9238e-04, -4.4028e-05, -1.2604e-03,  1.9359e-03,\n",
            "        -1.9100e-04, -1.1784e-03,  1.1412e-03, -5.0696e-04,  2.1887e-04,\n",
            "        -1.4209e-03,  3.1906e-04, -4.0872e-04,  3.5377e-03,  1.2908e-03,\n",
            "        -1.2627e-03, -6.9922e-04,  2.0828e-03,  7.7470e-04,  1.1342e-03,\n",
            "        -1.1020e-03, -3.5041e-04,  7.6988e-05,  1.8789e-04, -6.8606e-04,\n",
            "        -3.2155e-03, -1.1874e-03,  9.1828e-04, -2.8453e-04,  1.3751e-03,\n",
            "        -2.1670e-03, -2.4886e-03,  1.7288e-03,  1.1160e-03, -3.8499e-04,\n",
            "         1.6068e-04,  1.9096e-03, -1.8146e-03, -2.3099e-03, -1.0786e-03,\n",
            "         1.9564e-03,  2.6879e-04, -6.2241e-04, -9.4729e-04, -2.1119e-03,\n",
            "        -1.2031e-03,  1.0788e-03,  9.2907e-04, -1.1360e-03,  4.0231e-04,\n",
            "         4.5298e-04, -2.2997e-03, -1.2494e-03,  3.3577e-04, -1.7714e-03,\n",
            "         1.2286e-03, -1.7944e-03, -2.9780e-03,  7.9854e-04,  1.2777e-03,\n",
            "         2.9644e-04, -8.0542e-04,  3.0299e-04,  2.0010e-05,  2.9393e-03,\n",
            "         9.4955e-04, -4.1396e-03,  2.1284e-04], device='cuda:0')\n",
            "ITEM 9 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male', 'female', 'curtain', 'curtain']\n",
            "y_hat_labels_str = ['male', 'female', 'curtain', 'curtain']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male', 'female', 'curtain']\n",
            "y_labels_int_v2 = tensor([89, 55, 42], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.7524, 0.6082, 0.2788, 0.5216],\n",
            "        [0.3125, 0.5409, 0.5192, 0.8125],\n",
            "        [0.8834, 0.4195, 0.2236, 0.7572]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'female', 'curtain']\n",
            "y_hat_bboxes_v2 = tensor([[0.7589, 0.6109, 0.3010, 0.5425],\n",
            "        [0.3138, 0.5427, 0.5258, 0.8087],\n",
            "        [0.8871, 0.4187, 0.2238, 0.7599]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0043, 0.0058, 0.0021, 0.5337, 0.0107, 0.2003, 0.0062, 0.0043, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0045, 0.0730, 0.0045, 0.1623, 0.0109, 0.4980, 0.0123, 0.0045, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0040, 0.4566, 0.0064, 0.0374, 0.0063, 0.0543, 0.0053, 0.0040, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.637134075164795 = 0.0885857567191124 + 5.548548221588135\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-8.3699e-05, -5.7076e-05, -3.3893e-05,  1.3665e-05, -2.4850e-06,\n",
            "        -4.6688e-06, -2.0906e-05,  5.8401e-06,  8.7970e-06, -2.8186e-05,\n",
            "         2.5205e-05, -1.3099e-05, -1.7900e-05, -3.9491e-05, -6.9136e-07,\n",
            "         2.7801e-05, -4.2043e-05, -6.2104e-05,  3.4590e-05, -4.8015e-05,\n",
            "        -9.4894e-05, -1.3844e-05, -9.0182e-06,  1.8647e-05, -2.1361e-05,\n",
            "        -1.2277e-05, -1.1712e-05,  1.4393e-05, -1.2401e-05,  7.8208e-05,\n",
            "         2.1073e-05,  3.7733e-06,  1.6050e-06,  1.0771e-05,  3.1159e-05,\n",
            "         3.5911e-05, -2.2352e-05, -2.2909e-05,  4.9389e-06, -7.8366e-06,\n",
            "         2.4118e-05, -1.0714e-05,  5.2083e-05, -1.1340e-05,  1.5025e-05,\n",
            "        -3.4124e-05, -2.3334e-05, -1.1903e-05, -4.2680e-05, -2.0484e-05,\n",
            "        -9.2394e-06, -2.4548e-05,  2.8016e-05, -1.1371e-05,  3.3732e-05,\n",
            "        -6.7673e-05, -4.5915e-05, -2.1101e-05, -3.1640e-06,  1.4069e-05,\n",
            "         2.1488e-05, -5.1010e-05,  8.2735e-05,  9.0726e-06, -7.3872e-06,\n",
            "         5.5529e-05,  7.2460e-06,  2.0378e-06, -1.7214e-05, -4.2275e-05,\n",
            "         2.7124e-05, -3.3546e-05, -2.1067e-05,  5.0873e-06,  8.9754e-06,\n",
            "        -6.5081e-06,  6.6943e-07,  2.5041e-05, -3.4567e-06, -9.2698e-06,\n",
            "         3.7004e-05,  2.6831e-06,  7.3021e-05, -3.3701e-05, -6.9469e-06,\n",
            "         9.9439e-06,  6.2601e-06,  8.8341e-06, -2.6734e-05, -6.7706e-07,\n",
            "        -1.5922e-05,  8.9455e-06,  1.6844e-05, -5.7106e-05, -1.8814e-05,\n",
            "        -1.9166e-05, -3.1354e-05,  1.2489e-05, -4.0665e-06,  2.4731e-05,\n",
            "        -2.0425e-05,  1.4673e-05,  2.7548e-05, -3.7520e-05,  2.0483e-05,\n",
            "         3.4982e-05,  6.0149e-05, -2.5691e-05,  3.4899e-05,  1.3667e-05,\n",
            "         9.6386e-06, -3.6456e-05, -2.3447e-05,  1.1467e-05,  5.9678e-05,\n",
            "        -4.3569e-06,  4.7351e-05,  3.7994e-05, -2.7222e-05, -1.0744e-05,\n",
            "        -3.4697e-06,  2.5276e-05,  2.9738e-05, -4.2719e-05,  3.8400e-05,\n",
            "         2.1690e-05,  1.5728e-05, -3.9134e-05,  2.3313e-05, -1.9183e-05,\n",
            "         3.1008e-05,  1.0422e-05, -6.7140e-06, -6.0663e-05,  1.0930e-04,\n",
            "        -2.3335e-05, -8.9688e-07, -4.8793e-06,  2.9944e-05,  8.2567e-06,\n",
            "         3.0564e-05, -3.8991e-05,  4.0206e-06,  1.6940e-05, -8.0866e-06,\n",
            "        -2.6854e-05, -3.2989e-05,  9.3225e-06, -1.1481e-05,  2.7248e-06,\n",
            "        -2.7682e-05, -2.6937e-05,  4.3884e-05, -1.2103e-05, -1.1794e-05,\n",
            "         6.0939e-05, -1.0817e-05,  2.7774e-05, -1.5859e-05,  4.1906e-05,\n",
            "         5.4707e-07,  7.8670e-06,  5.6589e-05,  6.0238e-05, -1.2121e-05,\n",
            "         1.2905e-05,  1.1585e-05, -5.3085e-05, -4.6001e-05, -8.1204e-05,\n",
            "         5.7680e-06, -4.1804e-05,  5.9252e-06, -3.4837e-05,  2.9702e-05,\n",
            "        -2.1548e-06,  4.8636e-05,  3.6539e-06,  1.3342e-06,  5.5850e-05,\n",
            "         9.3049e-06, -2.5310e-05, -1.1021e-05,  6.2317e-05,  9.8477e-06,\n",
            "         1.5833e-05, -6.2046e-05, -1.6691e-05, -5.8894e-05,  3.0402e-05,\n",
            "        -4.4983e-05, -2.0741e-06,  2.8365e-05,  1.9386e-05, -2.0678e-05,\n",
            "        -2.6822e-05,  8.9415e-06,  4.4882e-05, -9.5602e-06, -4.6555e-05,\n",
            "         3.2417e-05,  5.8231e-06,  1.2374e-05, -8.4444e-06,  2.1083e-05,\n",
            "        -1.1689e-05,  4.9946e-06,  3.0716e-05, -2.0995e-05,  4.3820e-05,\n",
            "        -2.2592e-05, -3.6968e-05,  4.7942e-05, -1.7568e-05, -4.7782e-05,\n",
            "        -3.5546e-06,  1.3461e-05, -1.0792e-05, -2.8013e-05,  3.1789e-05,\n",
            "         1.8872e-05, -2.2712e-05,  2.7709e-05, -1.9144e-05,  2.3997e-05,\n",
            "        -3.8966e-05, -3.4266e-05,  7.4776e-06,  2.7487e-05, -3.4172e-05,\n",
            "         1.3851e-05,  3.4192e-06,  1.3625e-05,  1.0244e-05, -2.3471e-05,\n",
            "         1.0704e-05,  1.4572e-05,  1.1014e-05, -4.1891e-05,  3.8909e-05,\n",
            "         1.7323e-05, -3.6704e-05,  5.0693e-05, -4.5147e-05,  2.2137e-05,\n",
            "        -3.5593e-05, -3.5422e-05,  3.2113e-06, -6.1712e-05, -3.7699e-05,\n",
            "         1.6714e-05, -5.1376e-06, -2.2718e-05,  3.1856e-05,  2.4501e-05,\n",
            "        -1.2613e-05, -1.8059e-05,  3.4411e-06, -9.3463e-06,  8.0352e-05,\n",
            "         6.4384e-05, -2.7570e-05,  5.9762e-05,  2.2638e-05, -2.3056e-05,\n",
            "        -1.8595e-05, -4.4231e-05, -1.2870e-05,  6.3851e-05,  5.2904e-05,\n",
            "        -6.1271e-06,  5.6207e-05, -1.8276e-05, -8.0205e-06, -1.3981e-05,\n",
            "         3.6308e-05, -1.5961e-05, -1.0517e-05, -3.2090e-05,  3.9796e-06,\n",
            "        -7.6965e-06,  1.0637e-05,  1.5366e-05,  3.6947e-05, -1.5271e-05,\n",
            "         4.7759e-05,  3.4606e-05,  1.0116e-05, -8.0312e-06, -3.8891e-05,\n",
            "        -3.3028e-05, -7.7408e-06,  1.4793e-06, -5.7850e-06,  1.9170e-05,\n",
            "        -4.2808e-05, -6.0894e-05,  2.6669e-05,  5.0958e-07,  2.0439e-05,\n",
            "         1.9129e-05,  1.0820e-05,  5.1728e-05, -3.6129e-05, -8.2635e-06,\n",
            "        -1.9621e-05, -1.4731e-05,  1.0444e-05,  1.2848e-05,  3.7182e-05,\n",
            "         3.9872e-05, -5.7767e-05, -1.4548e-05,  6.6127e-06,  5.4607e-05,\n",
            "        -6.0922e-07, -2.6074e-05, -2.1588e-06,  3.2357e-05,  2.0709e-05,\n",
            "        -2.5064e-05, -4.1812e-05,  4.8139e-06, -2.8435e-05, -5.9683e-05,\n",
            "         4.4047e-05,  3.8115e-05, -2.7104e-05,  1.1621e-05,  2.5895e-05,\n",
            "        -3.3072e-05, -2.0706e-05, -1.1611e-05, -3.9213e-05, -1.3892e-05,\n",
            "         3.6558e-05, -1.4055e-05, -2.6597e-05, -4.3403e-06, -5.5173e-05,\n",
            "         3.8381e-05, -3.7397e-05, -2.2018e-05, -1.8945e-05, -1.0545e-05,\n",
            "        -1.1395e-06, -4.7887e-05,  3.3445e-06,  3.1365e-05, -2.1831e-05,\n",
            "         1.8914e-05, -4.5955e-05, -4.4588e-05, -4.6770e-05,  2.8581e-05,\n",
            "         1.4812e-05, -4.1750e-05, -5.0915e-06,  4.7297e-05,  5.0774e-05,\n",
            "         1.3676e-05, -2.3507e-07,  4.0412e-05, -3.4575e-05,  3.7703e-05,\n",
            "        -9.0936e-06,  2.6970e-05, -2.1364e-05, -1.2330e-05,  6.2635e-05,\n",
            "         4.7994e-05,  3.5057e-05, -1.8345e-05,  3.3083e-05,  6.4169e-05,\n",
            "         2.6690e-05,  1.0104e-05,  1.9311e-05,  3.0509e-05,  3.7855e-05,\n",
            "         4.2930e-05,  2.4318e-05,  1.9667e-05,  8.9985e-06, -3.8368e-05,\n",
            "        -1.6506e-05, -1.3559e-05,  9.6641e-06, -9.7108e-06,  3.8153e-05,\n",
            "        -2.5231e-05, -1.9136e-06, -3.9343e-05,  2.9000e-05,  9.9846e-06,\n",
            "        -5.5170e-05,  2.0070e-05, -5.9976e-05,  3.3954e-06, -2.8595e-05,\n",
            "         1.8657e-05,  7.4630e-07, -2.9865e-05,  9.5107e-05,  4.6921e-05,\n",
            "        -1.8914e-05,  7.7661e-06,  3.0742e-05,  5.3545e-07,  4.8901e-05,\n",
            "        -4.4433e-06,  6.9992e-05,  6.5002e-06,  2.0741e-05,  1.4273e-05,\n",
            "        -7.2140e-05,  4.8729e-05,  4.5091e-05, -3.6368e-05, -4.0495e-06,\n",
            "         1.7356e-05, -5.3329e-06,  2.5600e-05,  3.3308e-05,  5.2861e-05,\n",
            "         5.1523e-05,  5.1311e-05,  1.1134e-05,  6.0096e-05,  1.3273e-05,\n",
            "         2.7306e-06,  2.5108e-05, -2.3629e-05,  3.9161e-05,  9.4243e-06,\n",
            "        -4.9887e-05, -1.6720e-05,  1.0866e-05, -2.7578e-05, -1.2682e-05,\n",
            "        -3.7772e-05,  2.4307e-05,  8.5127e-06, -6.3063e-06,  1.3506e-05,\n",
            "        -5.8706e-06, -4.6094e-06,  2.1698e-05, -2.8635e-05,  3.9763e-05,\n",
            "         2.7574e-06,  1.5198e-05, -1.3941e-05,  4.5568e-07,  1.4887e-05,\n",
            "        -1.8531e-05, -2.0416e-05,  1.2856e-05, -2.3306e-05,  5.3957e-05,\n",
            "         2.4493e-06, -2.0042e-05,  6.7015e-06, -4.3166e-05,  8.9635e-06,\n",
            "        -3.7170e-05, -3.1843e-05, -8.5778e-06, -3.8790e-05, -2.6858e-05,\n",
            "         2.2257e-05,  2.5992e-05, -1.5501e-05, -3.2632e-05, -5.2862e-05,\n",
            "         8.6424e-07,  2.9906e-05, -2.6286e-05, -5.8970e-05, -8.6572e-06,\n",
            "         1.9334e-06,  4.7956e-05,  3.3837e-05,  5.4019e-06,  1.4722e-05,\n",
            "        -2.8801e-05, -3.3657e-05, -1.5343e-05,  1.1357e-05,  1.3100e-05,\n",
            "         1.9514e-05,  4.9328e-06, -2.4902e-05,  2.0666e-05, -1.0585e-05,\n",
            "        -1.7621e-05, -4.2368e-06, -4.8331e-05,  3.4338e-05,  1.0856e-05,\n",
            "        -6.2792e-06, -1.1959e-05, -7.2320e-06, -1.1445e-05,  2.8109e-05,\n",
            "        -2.5406e-05, -5.3792e-05,  5.8774e-06, -5.2099e-05, -4.1733e-05,\n",
            "        -6.9863e-05, -2.9374e-05, -1.9761e-05,  1.0937e-05, -1.2822e-06,\n",
            "        -6.7201e-06,  5.3655e-05, -4.1996e-05,  7.3164e-05, -4.8975e-06,\n",
            "        -2.6809e-05, -2.0386e-05,  3.7540e-05,  1.7654e-06,  4.0726e-06,\n",
            "        -3.9370e-05,  1.0974e-05,  3.1760e-05, -2.8677e-05, -4.5388e-05,\n",
            "        -2.1820e-05,  9.1349e-06, -8.8079e-06, -9.4664e-06, -4.1147e-06,\n",
            "         4.8985e-06,  1.2717e-05, -7.2870e-06,  3.2534e-05, -5.4285e-06,\n",
            "         6.6860e-06,  5.0166e-06, -2.6741e-05, -1.0281e-05,  2.0017e-05,\n",
            "         2.0338e-06, -2.8896e-05,  7.2247e-06,  6.3495e-05,  3.5627e-05,\n",
            "         2.7564e-05,  2.3446e-06, -5.3975e-05,  4.9056e-05,  1.4606e-05,\n",
            "         1.7901e-05,  2.9402e-05, -4.3552e-05, -2.1962e-05,  2.6518e-05,\n",
            "        -5.1597e-06, -7.0093e-06,  3.8404e-05, -1.4334e-05, -5.0414e-05,\n",
            "         4.3522e-06,  6.1423e-05, -5.9560e-06, -7.5819e-05, -1.6521e-05,\n",
            "         2.5726e-05,  2.6187e-05, -1.7084e-05, -2.5176e-05, -5.1634e-05,\n",
            "         2.9433e-06, -8.0250e-06,  5.5617e-05, -7.4062e-05, -4.8532e-06,\n",
            "         1.9886e-05,  4.4223e-05,  1.5910e-05,  3.2520e-06, -2.6625e-05,\n",
            "         7.4143e-05, -1.8945e-05, -5.6169e-05, -4.1399e-06, -2.5759e-05,\n",
            "        -4.9189e-06, -4.6094e-05, -2.4850e-05, -3.9046e-05, -5.6920e-05,\n",
            "         1.3696e-05,  6.0237e-05,  4.0614e-05, -1.6221e-06, -4.4146e-05,\n",
            "        -3.8886e-05, -3.9106e-05,  4.7723e-06, -7.0730e-06, -3.8745e-07,\n",
            "        -3.8766e-05, -5.8442e-06,  7.8703e-05, -1.4150e-05,  3.2332e-06,\n",
            "        -7.0043e-05, -2.6321e-05, -4.7508e-05, -2.8702e-06,  1.3867e-05,\n",
            "        -2.9222e-05, -1.8683e-06, -2.4803e-05,  1.9767e-05, -4.2498e-05,\n",
            "         4.9837e-05, -4.0066e-06,  3.5813e-05, -1.5939e-05,  1.1252e-05,\n",
            "         2.4225e-05, -3.1089e-05,  4.3697e-05,  3.4623e-05, -5.1202e-05,\n",
            "        -9.9987e-06, -6.2174e-07,  1.5197e-05,  2.1044e-05, -3.5462e-05,\n",
            "         8.2251e-06,  1.7006e-05, -1.8984e-06,  5.1807e-06, -9.7554e-06,\n",
            "        -2.7136e-05, -1.1391e-05,  6.9370e-05, -3.3521e-05, -1.3001e-05,\n",
            "         7.3655e-06,  3.1098e-05,  1.7681e-05,  2.0335e-05, -3.2347e-05,\n",
            "         7.0212e-07, -4.3569e-05, -3.9510e-05, -4.5815e-05, -4.6066e-06,\n",
            "        -1.4342e-05, -2.7172e-05, -1.9590e-06, -2.1387e-06, -5.6251e-05,\n",
            "         4.3770e-05,  2.4565e-06,  9.3116e-06,  1.7804e-05,  3.8514e-06,\n",
            "         1.6609e-05,  9.5834e-06, -2.4611e-05, -1.3568e-05, -8.3031e-06,\n",
            "        -6.0055e-05, -6.1413e-06,  1.6201e-05,  1.4739e-06,  1.6203e-05,\n",
            "        -1.2191e-05,  3.5042e-05,  6.5319e-06, -1.4683e-05,  6.0661e-06,\n",
            "        -2.9942e-05,  1.5339e-05,  4.1642e-05,  3.7941e-05,  5.7538e-05,\n",
            "         1.8233e-05, -1.4863e-05,  5.4911e-06,  1.1693e-05,  2.0429e-05,\n",
            "         5.6049e-06, -1.6456e-05, -6.1418e-06,  5.6551e-06, -2.3491e-05,\n",
            "        -1.1982e-05,  2.7226e-05,  3.4803e-06,  2.7505e-06,  3.8239e-06,\n",
            "         2.7242e-05, -5.0774e-05,  2.2460e-05,  4.7481e-06,  7.6094e-07,\n",
            "         2.9023e-05, -2.3427e-05, -2.6366e-05,  7.8342e-07,  3.2393e-05,\n",
            "         2.0186e-05, -7.6112e-06, -1.3705e-05, -1.3174e-05, -3.2507e-05,\n",
            "        -5.5395e-06, -1.7058e-05,  1.7621e-05,  5.4575e-06,  7.5843e-06,\n",
            "         1.2020e-05,  5.3022e-05,  1.5503e-05,  2.0774e-05,  9.8478e-06,\n",
            "         7.8066e-05,  1.5317e-05,  7.2029e-06, -3.1089e-05, -3.5031e-05,\n",
            "         4.8524e-05, -1.7511e-05, -2.3354e-05, -4.1573e-05,  2.5726e-05,\n",
            "         2.0203e-05, -6.4792e-05, -6.9248e-05, -2.9336e-05, -6.2325e-06,\n",
            "        -2.2537e-05,  2.7956e-05, -6.4321e-06,  1.0366e-05, -2.6363e-05,\n",
            "         1.3705e-06,  2.8031e-05, -9.9428e-05,  2.4996e-05,  7.5272e-06,\n",
            "        -7.2319e-06, -1.7831e-06,  1.4848e-05,  6.7418e-05, -4.7218e-07,\n",
            "        -4.3222e-05, -8.1931e-06,  4.2526e-05,  1.1769e-05, -6.0048e-05,\n",
            "        -3.8817e-05,  8.7741e-05, -7.8386e-06,  2.2106e-05, -5.4400e-05,\n",
            "        -1.0813e-05,  1.0519e-05,  3.4105e-05], device='cuda:0')\n",
            "ITEM 10 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['tie', 'cow', 'axe']\n",
            "y_hat_labels_str = ['axe']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['axe']\n",
            "y_labels_int_v2 = tensor([1], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4411, 0.8053, 0.3654, 0.3125]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['axe']\n",
            "y_hat_bboxes_v2 = tensor([[0.4508, 0.8025, 0.3778, 0.3032]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0039, 0.0729, 0.0059, 0.4159, 0.0091, 0.0416, 0.0050, 0.0040, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.56068229675293 = 0.08586204051971436 + 5.474820137023926\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 5.7602e-04, -2.0584e-04, -1.9227e-04, -5.8908e-04, -7.4278e-04,\n",
            "         1.3826e-03, -7.6204e-04, -8.3095e-04, -5.5521e-04, -2.6862e-04,\n",
            "        -2.1677e-04, -6.9370e-04, -3.9095e-04, -3.1333e-04, -3.3750e-04,\n",
            "         9.0038e-04, -7.3039e-05,  1.7369e-04,  1.0538e-03, -3.5453e-04,\n",
            "         5.9109e-05,  6.2722e-04,  5.2206e-04, -1.9620e-04, -9.6642e-04,\n",
            "         4.7964e-04, -2.4862e-04, -6.9139e-04, -3.5795e-04,  5.0966e-04,\n",
            "        -2.3221e-04,  1.4372e-04, -3.9524e-04,  7.6567e-04, -6.4764e-04,\n",
            "         2.2983e-03,  9.5524e-05,  4.4045e-04,  2.1780e-04, -3.4545e-04,\n",
            "        -9.1993e-04, -1.1350e-03, -2.9442e-04, -9.9511e-05, -2.8758e-04,\n",
            "         4.6369e-04, -1.1443e-03,  2.4955e-04, -4.9973e-04, -3.2311e-04,\n",
            "         7.8587e-04,  1.6244e-04,  6.4074e-04, -2.3640e-04,  4.8273e-04,\n",
            "        -7.5147e-04, -1.1383e-03,  1.1192e-05, -7.9706e-05,  3.5221e-04,\n",
            "         1.8108e-04, -2.4057e-04,  3.1739e-04, -1.5884e-04, -1.3427e-04,\n",
            "         3.2355e-04, -2.5221e-04, -1.2029e-03, -7.6228e-04, -6.7611e-05,\n",
            "        -5.0302e-04, -6.2815e-04,  6.6461e-05,  6.0700e-04, -5.1394e-04,\n",
            "        -6.4007e-04, -4.1706e-04, -3.8281e-04, -1.3499e-04, -3.2897e-04,\n",
            "         1.1992e-03, -2.6421e-04,  1.1701e-04, -1.9783e-04, -3.9741e-04,\n",
            "         8.4745e-05, -1.4279e-03,  9.2372e-04, -3.1691e-05,  9.0268e-04,\n",
            "         5.5958e-04,  4.4857e-04, -2.3108e-04, -4.1549e-04, -3.1104e-04,\n",
            "        -9.0119e-05,  1.6662e-05,  8.5834e-04,  3.0713e-04,  6.2298e-04,\n",
            "         1.6147e-03, -7.7717e-04, -2.9883e-04, -3.5467e-04, -5.7400e-04,\n",
            "         8.4906e-04,  1.2802e-03, -3.9881e-04, -6.9644e-04, -3.0168e-04,\n",
            "        -2.2791e-04, -3.7632e-04,  1.2950e-03, -1.0761e-04, -5.8011e-04,\n",
            "        -2.3972e-04,  5.0830e-04,  8.8397e-04, -7.9640e-04, -2.8550e-05,\n",
            "        -1.3804e-03, -1.7899e-04, -1.6977e-04, -2.0792e-06,  8.7490e-04,\n",
            "         9.1599e-04,  1.1232e-03,  1.1008e-03, -6.4364e-04,  5.1565e-04,\n",
            "        -3.4733e-04,  4.3472e-04,  4.1072e-04, -1.4807e-04, -7.9381e-04,\n",
            "         1.1562e-03,  1.2422e-03,  2.8973e-04,  4.8233e-04, -4.9399e-04,\n",
            "         5.8624e-04, -1.4832e-03, -1.2510e-03, -2.2528e-04,  5.7814e-04,\n",
            "         6.4199e-05, -7.9688e-05, -7.7707e-04, -7.7532e-04, -6.6288e-04,\n",
            "        -8.1675e-04, -1.4761e-04, -2.3486e-04,  5.1801e-04, -3.7875e-04,\n",
            "        -6.2233e-04, -2.3149e-04, -4.5172e-04,  1.1526e-03,  3.2381e-06,\n",
            "        -1.5669e-04,  6.3069e-04,  1.3857e-03, -6.0603e-05,  3.1987e-04,\n",
            "        -6.4124e-04, -2.0930e-04, -1.3040e-04,  6.9885e-04, -8.1267e-04,\n",
            "        -1.5471e-06,  1.4088e-04,  3.1298e-04, -6.8070e-04, -3.6773e-04,\n",
            "         3.6729e-04, -1.6214e-04,  8.3160e-04, -2.6618e-04,  2.5314e-04,\n",
            "         6.0046e-04,  2.5682e-04,  8.3441e-04,  2.5307e-04, -4.8249e-04,\n",
            "         4.9341e-04, -6.6297e-04,  2.5541e-06,  5.8933e-04, -2.1667e-04,\n",
            "        -4.4134e-04,  2.9613e-04, -1.5524e-04, -5.5318e-04, -7.1295e-04,\n",
            "        -5.5329e-04, -8.6378e-04,  5.5615e-04,  1.4714e-03,  2.3417e-05,\n",
            "         2.7036e-04, -1.0311e-04,  1.5044e-04,  4.5165e-05, -3.7927e-04,\n",
            "         6.1547e-04,  5.0711e-05, -3.2639e-04, -1.7326e-04,  4.7295e-04,\n",
            "         2.5019e-04, -5.9410e-04, -3.6523e-04,  1.7394e-03,  5.2567e-04,\n",
            "        -8.0845e-05, -1.4051e-04,  3.4979e-04,  7.5105e-05,  1.0161e-03,\n",
            "         2.5922e-04, -6.6370e-04, -1.3464e-03, -3.6004e-04, -7.8259e-04,\n",
            "        -2.3771e-04, -9.9490e-05,  3.1111e-04,  1.2598e-04, -1.3282e-04,\n",
            "         8.3813e-05, -5.7149e-04, -3.6925e-05,  8.2160e-04,  3.0068e-04,\n",
            "        -2.8993e-04,  4.3654e-04, -9.0435e-04, -6.9385e-04,  2.8943e-04,\n",
            "         4.8463e-05,  3.9159e-04,  9.6090e-04, -1.1544e-03, -5.9233e-04,\n",
            "        -1.0459e-05,  2.2749e-04,  1.4230e-03,  4.0648e-04,  5.7022e-04,\n",
            "         6.6125e-04,  6.6848e-04,  9.0253e-04,  4.0729e-04,  1.0787e-04,\n",
            "        -2.0326e-04, -1.2239e-03,  1.0218e-03, -9.3447e-04,  6.8725e-04,\n",
            "        -1.3433e-04,  4.4882e-04, -1.1922e-04, -2.4886e-04, -4.8767e-04,\n",
            "        -8.3167e-04, -1.5695e-04,  5.3312e-04, -1.3137e-04, -6.1887e-04,\n",
            "         1.8797e-04, -2.7269e-04, -8.6564e-04,  6.3878e-04, -5.5767e-05,\n",
            "        -1.5731e-04,  4.8226e-04, -2.6352e-04,  3.1242e-04, -1.1734e-03,\n",
            "        -1.0125e-03,  4.0260e-04,  2.0903e-04, -2.0459e-04,  2.4832e-04,\n",
            "        -6.4009e-04,  1.9108e-04,  8.1426e-04, -3.5832e-04,  4.9108e-05,\n",
            "         1.4937e-04, -6.7529e-04,  5.1182e-04,  7.3041e-05,  2.1147e-04,\n",
            "        -2.4561e-04, -7.4452e-04,  6.4135e-04,  5.3830e-04,  9.8061e-04,\n",
            "        -7.3737e-04, -4.2676e-04,  4.1540e-04, -6.8534e-04, -3.5637e-05,\n",
            "         4.2820e-04, -6.4522e-04, -8.1877e-04,  1.2684e-03,  1.3471e-04,\n",
            "         5.8380e-04, -3.7980e-04,  3.9420e-04,  1.5695e-03, -2.2098e-04,\n",
            "        -2.4029e-05, -6.3184e-05, -2.5957e-04, -4.4227e-04, -1.3114e-03,\n",
            "         6.9692e-04, -6.8742e-04, -3.8623e-04, -8.8352e-04, -3.7748e-04,\n",
            "        -1.9220e-04,  6.2428e-04, -4.7826e-04,  6.6927e-04, -4.8306e-04,\n",
            "        -6.4683e-06,  5.2792e-04,  7.8191e-04, -9.7053e-04,  8.0111e-04,\n",
            "         5.3586e-04,  1.0439e-05, -9.0893e-04,  2.9739e-04, -1.6190e-04,\n",
            "         1.3673e-03,  1.0684e-04,  7.4607e-04,  4.9072e-04,  1.6111e-05,\n",
            "         6.3159e-04, -3.6329e-04, -4.0976e-04, -9.9777e-05,  2.2616e-04,\n",
            "         9.6479e-04, -5.1230e-04,  6.0252e-04, -7.8659e-04, -7.1714e-04,\n",
            "        -5.3056e-04, -6.5973e-04, -3.0014e-04,  5.7675e-04,  3.2760e-04,\n",
            "        -1.6109e-04,  5.2789e-04,  7.1301e-05,  3.1466e-04, -8.9116e-04,\n",
            "        -8.8439e-04,  1.2062e-04, -1.9767e-04,  5.5003e-04, -1.6255e-04,\n",
            "         5.1749e-04, -8.1962e-04, -5.1359e-04, -3.9732e-04, -9.8504e-05,\n",
            "         2.2312e-04,  4.1991e-04,  1.1204e-03,  1.0648e-03, -8.9544e-05,\n",
            "         6.2411e-04, -2.4705e-04,  4.0999e-04, -3.9409e-04, -4.0627e-04,\n",
            "        -1.1461e-03,  6.2051e-04, -1.0762e-03,  6.0099e-04,  2.2820e-04,\n",
            "        -6.2260e-04,  3.9992e-04, -7.1582e-04,  9.3946e-04,  3.1280e-04,\n",
            "        -6.6824e-06, -1.2776e-03, -4.7026e-04, -2.0847e-04, -1.1705e-03,\n",
            "         1.5022e-05, -2.1830e-04, -1.7661e-03,  7.2968e-04,  1.3531e-04,\n",
            "        -7.2571e-04, -1.5058e-04,  3.0107e-04,  1.1561e-03,  8.9952e-04,\n",
            "         2.2428e-04, -9.0360e-04, -4.2193e-04,  2.2037e-04, -4.6996e-05,\n",
            "         2.9231e-05,  6.1958e-04, -7.3432e-04, -7.8702e-04,  4.5372e-05,\n",
            "        -4.7786e-04, -2.3503e-04, -4.9072e-05,  8.8925e-04,  1.2393e-03,\n",
            "         1.7068e-04,  2.3822e-04, -7.4419e-04, -9.0644e-05,  2.6610e-04,\n",
            "        -9.0584e-04,  1.2649e-03, -1.6437e-04, -7.1371e-05, -4.3939e-04,\n",
            "        -1.6339e-04,  1.3233e-05,  5.1546e-04,  3.8937e-04,  3.2977e-04,\n",
            "         1.2987e-04, -5.9318e-05, -9.8660e-04, -8.8727e-04, -6.7182e-05,\n",
            "        -1.1750e-04,  7.2611e-04,  7.0575e-04,  4.3976e-04,  2.0033e-04,\n",
            "        -5.6267e-04,  6.5265e-04,  4.2120e-04,  1.2563e-03, -2.1277e-04,\n",
            "         6.9709e-04,  3.1618e-04,  6.4833e-04, -7.6721e-04,  2.8190e-05,\n",
            "         1.2779e-03,  5.6655e-04, -1.1355e-03, -2.3922e-04, -7.0400e-04,\n",
            "        -2.4533e-04, -4.0918e-04, -1.3513e-04, -5.1296e-04,  1.0817e-03,\n",
            "         4.3228e-04,  6.9825e-05,  1.0326e-04,  6.3658e-04, -4.5307e-05,\n",
            "         3.1215e-04,  4.5478e-04,  1.4646e-04, -6.4309e-04,  2.0561e-04,\n",
            "         8.7093e-04, -6.3359e-04,  2.8470e-04,  2.1762e-05, -6.2858e-05,\n",
            "        -2.4520e-04, -5.1190e-04,  1.3308e-03,  4.3453e-04,  5.8468e-04,\n",
            "         1.2581e-03, -5.2936e-04, -1.0742e-03,  2.1180e-04,  3.6697e-04,\n",
            "        -4.1591e-04,  2.5940e-04,  1.8313e-05, -1.4970e-04,  2.2734e-04,\n",
            "        -6.0292e-04,  6.4306e-05, -9.7531e-04,  1.5444e-04,  5.2695e-04,\n",
            "        -3.2275e-04,  6.6947e-04, -1.1419e-04,  1.8990e-04,  1.0186e-03,\n",
            "         3.5054e-04, -5.7400e-05,  1.0851e-03, -5.1466e-04, -5.5861e-04,\n",
            "        -2.8189e-04, -8.0034e-04,  4.8486e-04,  2.3993e-04, -3.2269e-04,\n",
            "        -6.3394e-04,  1.9094e-04,  4.9627e-04, -1.5865e-04,  1.3030e-04,\n",
            "        -1.2671e-04,  2.9706e-06, -7.6073e-04,  8.9229e-04, -4.0859e-04,\n",
            "         2.1890e-04, -6.3502e-04, -4.4362e-04, -3.2978e-05,  3.7090e-04,\n",
            "         1.1878e-03,  5.4208e-04, -2.4519e-04,  5.4083e-05, -5.6377e-05,\n",
            "        -8.2070e-04,  1.7062e-04, -1.8747e-04,  9.4189e-04,  3.3338e-04,\n",
            "        -6.1829e-04,  5.4900e-04,  1.7280e-04,  1.5115e-04,  3.3705e-04,\n",
            "        -3.5783e-04,  9.3607e-04,  3.4024e-04, -3.6797e-04,  2.1362e-04,\n",
            "        -2.5327e-04, -3.4158e-04,  2.0090e-04, -9.4917e-04, -5.0261e-04,\n",
            "        -4.7155e-04, -5.1240e-04,  7.6936e-04,  1.2511e-04, -9.3170e-04,\n",
            "        -1.5595e-04, -6.7172e-04, -4.6985e-04, -7.9386e-04,  5.0506e-04,\n",
            "        -7.1308e-04,  5.8716e-04,  6.7129e-04,  5.8502e-04, -3.5170e-04,\n",
            "         1.6201e-04,  3.3430e-04,  3.6229e-04,  9.7540e-05,  1.3699e-04,\n",
            "         1.0653e-03,  1.0538e-03, -8.9689e-04, -3.3217e-04, -5.3587e-04,\n",
            "        -2.7529e-04,  6.1265e-04,  2.4414e-05,  7.9315e-05,  4.9001e-04,\n",
            "        -6.6217e-04,  1.3232e-04, -3.2444e-04, -2.0227e-04, -6.2330e-04,\n",
            "         5.2913e-06,  1.6159e-04, -4.1899e-04, -4.9077e-05, -1.1351e-03,\n",
            "         6.6086e-04, -1.1095e-03, -5.9502e-04, -9.3403e-05, -7.7978e-04,\n",
            "        -4.7879e-04,  3.6496e-04, -6.5455e-04, -2.4015e-05,  2.7471e-04,\n",
            "        -6.0628e-04,  2.1059e-04,  2.3201e-04, -8.8006e-04, -1.5278e-04,\n",
            "         3.5325e-04, -1.7189e-04, -8.2571e-04,  2.3019e-04, -1.7503e-04,\n",
            "         4.1891e-04, -3.5937e-04,  2.2955e-04,  2.6770e-06, -5.6118e-04,\n",
            "        -1.3088e-04, -1.5387e-03,  1.2058e-04,  2.8601e-04, -8.6361e-04,\n",
            "         1.0688e-04, -3.3028e-04,  1.1020e-03, -1.4120e-04,  2.5790e-04,\n",
            "         4.1761e-04,  4.4546e-04,  5.1866e-04, -1.5199e-04,  1.4469e-03,\n",
            "        -9.9220e-05, -4.7436e-04,  1.6265e-04, -9.8780e-04, -6.5838e-05,\n",
            "        -9.7529e-04, -1.9862e-04, -1.6225e-04, -4.4650e-04,  6.7866e-06,\n",
            "         1.0809e-03,  9.4531e-04, -1.3564e-03, -1.5277e-04, -4.1776e-04,\n",
            "         5.2700e-04,  2.7280e-04,  1.1937e-03,  1.1176e-03,  7.7606e-05,\n",
            "         1.5530e-03,  4.7256e-04, -4.8097e-04,  1.2238e-04,  2.5345e-04,\n",
            "         8.1659e-04,  6.6548e-05, -4.2585e-04,  1.0589e-04, -1.6375e-04,\n",
            "         1.1458e-04, -7.9664e-04, -3.8530e-05, -1.9210e-04,  6.6972e-04,\n",
            "         5.6650e-04,  1.4844e-03,  2.5712e-04, -7.5334e-04, -1.2724e-04,\n",
            "         7.8454e-04, -8.3258e-04,  5.9337e-04, -5.4319e-04, -1.6602e-04,\n",
            "        -9.8547e-04,  3.1242e-04, -7.6890e-04, -1.2701e-03,  4.5829e-04,\n",
            "         8.5628e-04, -5.7609e-04,  2.0486e-04,  9.1100e-05, -9.6868e-04,\n",
            "         1.0673e-03,  6.8338e-04,  4.7293e-04,  1.2632e-04, -8.7768e-04,\n",
            "        -4.3669e-04, -7.0663e-04,  3.5525e-04,  3.7637e-04, -7.6111e-05,\n",
            "        -6.4902e-04,  1.2892e-03, -3.7159e-05,  3.8292e-04,  7.1084e-05,\n",
            "        -7.3721e-04,  1.5111e-04, -8.1632e-04, -1.4729e-03,  5.1448e-04,\n",
            "        -8.7656e-04,  1.5132e-04,  6.5878e-04,  7.7291e-04,  4.1862e-05,\n",
            "         7.6431e-04,  1.1114e-04,  2.8447e-04,  4.7570e-04,  4.4560e-05,\n",
            "        -5.7022e-04, -7.9743e-04,  8.8006e-04, -6.2270e-04,  1.2527e-05,\n",
            "        -2.9731e-04, -4.1361e-04,  9.4706e-04,  3.9174e-04,  3.3206e-04,\n",
            "         9.4276e-05,  1.2249e-03,  1.9220e-04, -6.5618e-04, -9.3326e-05,\n",
            "        -3.1545e-04,  7.3194e-05, -4.8036e-04, -5.3431e-04, -6.3313e-04,\n",
            "         4.7166e-04,  4.8196e-04,  1.4182e-04,  5.4973e-04, -6.1696e-05,\n",
            "        -1.3960e-04, -5.5190e-04,  4.5592e-05,  4.0501e-05, -1.3853e-04,\n",
            "         4.7775e-04,  3.0309e-04,  9.7501e-05,  5.3188e-04, -5.6174e-04,\n",
            "        -1.2406e-04, -1.3692e-04,  1.0039e-03,  1.1298e-04,  6.1444e-04,\n",
            "         1.7222e-05, -4.9022e-04, -5.9042e-04], device='cuda:0')\n",
            "ITEM 11 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['sheep']\n",
            "y_hat_labels_str = ['sheep']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['sheep']\n",
            "y_labels_int_v2 = tensor([124], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4952, 0.6298, 0.7332, 0.6995]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['sheep']\n",
            "y_hat_bboxes_v2 = tensor([[0.5012, 0.6226, 0.7200, 0.6969]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0054, 0.9080, 0.0127, 0.0054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.618165969848633 = 0.06713388115167618 + 5.551032066345215\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-2.7246e-04,  7.0488e-05, -2.5942e-05,  3.0894e-04, -3.5461e-04,\n",
            "         7.5441e-06, -7.1330e-04, -1.9540e-05,  3.0086e-04,  3.6092e-04,\n",
            "         5.6868e-05, -2.4862e-04,  2.0531e-04,  3.3347e-04, -1.7906e-04,\n",
            "         3.8992e-04,  1.1496e-04, -3.9847e-04,  3.8081e-05,  1.0971e-04,\n",
            "        -1.8524e-04,  1.8643e-04, -2.3363e-04,  1.8338e-04,  1.1891e-04,\n",
            "         3.1576e-04, -2.5057e-04,  4.1900e-04, -1.4449e-04,  2.6432e-04,\n",
            "         3.9207e-04, -8.1369e-05,  2.1938e-04, -2.6312e-04,  8.4552e-05,\n",
            "         3.3366e-04,  3.1437e-05,  1.8058e-04,  2.9343e-04, -1.4983e-04,\n",
            "         1.1520e-04, -1.9674e-04,  4.5677e-04,  1.6928e-04, -1.7302e-06,\n",
            "        -1.0826e-04, -2.3306e-04, -1.3311e-04,  3.8502e-04, -3.2775e-04,\n",
            "        -4.3562e-04, -7.1701e-06, -1.5052e-04,  7.0502e-05, -3.2343e-04,\n",
            "        -3.6766e-04, -3.0823e-04, -3.0220e-04,  4.2995e-04, -7.3783e-05,\n",
            "         1.0383e-04,  1.2198e-04,  5.0368e-05, -2.8032e-04, -1.5247e-04,\n",
            "         1.5838e-05,  4.6311e-04,  1.7309e-05, -3.9011e-04, -2.2045e-04,\n",
            "         1.2975e-04,  4.2253e-05,  2.2485e-04, -2.7235e-05, -3.9789e-05,\n",
            "         1.8099e-04,  2.8090e-05, -1.7275e-04, -1.6264e-06, -8.9723e-05,\n",
            "        -4.1221e-04,  3.1614e-04,  3.5715e-04,  1.0072e-04, -2.7767e-05,\n",
            "         3.3927e-05,  1.7238e-04, -6.2685e-05, -4.5678e-04,  4.4833e-04,\n",
            "         1.3561e-04,  1.2881e-05, -3.4034e-05, -2.8730e-05,  2.4316e-04,\n",
            "        -4.4242e-04,  5.2731e-05,  5.7412e-04, -7.5572e-04, -1.3544e-04,\n",
            "        -6.4105e-05,  1.1801e-04,  6.6731e-04, -4.4641e-07,  3.7640e-04,\n",
            "         6.8792e-05,  3.3678e-04, -8.1879e-05,  1.0490e-04, -2.3640e-04,\n",
            "        -3.8159e-05, -2.7289e-04, -7.8247e-05, -2.9793e-04,  7.6945e-04,\n",
            "         1.9305e-04,  4.9853e-04,  8.1393e-05, -3.0648e-04, -3.8914e-04,\n",
            "        -3.6048e-04, -1.0598e-04, -1.1034e-04,  1.5363e-04, -2.0795e-04,\n",
            "         2.8223e-04,  3.7017e-04,  2.2688e-04, -2.0023e-04,  3.5439e-04,\n",
            "         3.4848e-04,  4.4773e-04,  9.3706e-05, -2.6166e-04,  2.3948e-04,\n",
            "         7.3071e-05, -4.9985e-07, -2.7525e-04, -1.0553e-04, -1.5393e-04,\n",
            "         2.6115e-04,  2.6671e-04,  2.4484e-04,  4.0829e-04, -1.3972e-04,\n",
            "        -3.2527e-04, -1.5491e-04,  2.2081e-04,  6.5301e-05,  5.3487e-05,\n",
            "        -5.3010e-04, -2.7136e-04,  3.7465e-04,  2.0935e-04, -7.2506e-05,\n",
            "         3.1103e-04, -2.8972e-04,  1.3346e-04, -2.5428e-04,  7.0354e-05,\n",
            "         2.1952e-04,  6.6496e-04,  2.5491e-04,  3.0911e-04, -1.3161e-04,\n",
            "        -2.1840e-04,  2.4772e-04, -2.5785e-04, -1.1770e-04, -6.3707e-05,\n",
            "        -2.3424e-05, -4.1589e-04, -3.8848e-06,  4.0783e-04, -1.9953e-04,\n",
            "        -1.1471e-04, -3.3975e-05,  2.1875e-04, -1.7743e-04,  1.4236e-04,\n",
            "         2.8218e-04, -2.0020e-04, -1.1183e-04,  5.4690e-04, -1.4384e-04,\n",
            "         2.9480e-04, -7.9798e-06, -1.0840e-04,  1.4093e-04, -9.7009e-06,\n",
            "        -1.2088e-04,  6.5937e-05, -9.5273e-05, -4.4181e-05,  1.5312e-04,\n",
            "         9.7030e-05,  1.4024e-04,  3.3485e-05,  9.3294e-05, -1.0520e-04,\n",
            "         3.7356e-04, -3.4125e-04,  3.2660e-04,  1.6050e-04,  2.8879e-04,\n",
            "        -2.7884e-04,  3.0504e-04,  3.4960e-04,  8.2401e-06, -9.4839e-05,\n",
            "         7.8956e-05,  2.6747e-04, -2.4759e-04, -2.5285e-04, -5.0356e-04,\n",
            "         2.7829e-04,  1.9425e-04,  4.9306e-04, -2.9583e-04,  4.4137e-04,\n",
            "        -4.2418e-05,  2.5344e-04,  4.4878e-05, -4.2027e-05, -5.3981e-04,\n",
            "         1.8941e-04, -1.8684e-04, -4.6252e-04, -2.0473e-04,  3.1510e-04,\n",
            "         1.3671e-04, -2.1612e-04, -3.7977e-04, -3.3713e-04, -5.3961e-05,\n",
            "         2.7634e-04,  3.6684e-04,  9.4921e-05, -1.1499e-04,  7.7411e-05,\n",
            "         2.5464e-04, -6.2167e-04,  1.4491e-04, -6.7143e-05,  1.4646e-04,\n",
            "         8.7516e-05,  3.0536e-04, -1.0979e-05,  1.5259e-04,  9.2455e-06,\n",
            "        -1.5584e-04, -2.3377e-04, -7.2249e-05,  5.3992e-04, -1.2432e-04,\n",
            "         3.7062e-04, -2.2617e-04, -3.5823e-04,  1.4347e-04,  2.3441e-04,\n",
            "        -4.7164e-04,  3.6649e-05,  1.4309e-04,  3.0072e-04, -2.3337e-04,\n",
            "        -3.8322e-04, -3.6417e-04,  9.6700e-05,  3.9928e-05,  2.5388e-04,\n",
            "        -4.7237e-04, -1.8614e-05, -1.2238e-04, -5.7718e-05,  2.2520e-04,\n",
            "        -1.2616e-04,  4.2800e-04,  1.7294e-05,  3.1222e-04, -2.0022e-04,\n",
            "         2.2578e-05,  1.5593e-04, -1.9110e-04,  1.9957e-04, -4.1455e-04,\n",
            "        -8.9010e-06, -2.4443e-04,  1.4476e-04,  3.9015e-04, -7.9672e-05,\n",
            "        -1.1890e-04,  8.2769e-06,  1.4534e-04, -5.8594e-04,  1.9077e-05,\n",
            "        -3.5935e-04, -8.2499e-05, -1.0689e-05, -2.0319e-05,  1.8027e-04,\n",
            "        -4.2001e-04,  2.6085e-04,  2.6229e-04, -2.5996e-05,  7.1099e-05,\n",
            "        -3.7533e-04, -8.1016e-05, -3.1483e-04,  4.1863e-04,  2.5498e-04,\n",
            "        -3.5654e-06,  1.0423e-04,  1.0315e-05, -4.0157e-04,  3.3419e-04,\n",
            "         1.2031e-04, -3.7288e-04,  1.3693e-04, -1.8741e-04,  3.7517e-04,\n",
            "        -4.0117e-04,  3.6963e-04,  9.0601e-05,  5.5844e-05, -4.9869e-04,\n",
            "        -4.2317e-05, -1.4510e-04, -1.2087e-04, -2.6881e-05, -1.5921e-04,\n",
            "        -1.4263e-04,  4.3622e-06, -3.6881e-04, -2.0659e-04, -4.0633e-04,\n",
            "        -6.3792e-05, -8.4526e-05,  1.1947e-04,  8.6431e-06, -3.3082e-04,\n",
            "         2.5701e-04, -4.3829e-04,  7.3031e-05, -2.9236e-05,  6.4343e-04,\n",
            "         2.1537e-04, -8.8823e-05,  1.5813e-04,  9.3227e-05,  1.5573e-04,\n",
            "        -8.1241e-06, -6.4641e-05,  4.8437e-05,  1.1748e-04,  3.5766e-04,\n",
            "         9.6545e-05,  2.5632e-04,  6.9987e-05, -4.5641e-04,  1.4139e-04,\n",
            "         2.3952e-04, -8.7321e-05, -4.5907e-04, -2.0739e-04,  7.3147e-05,\n",
            "         1.5794e-04,  2.7624e-04, -1.6336e-04, -3.5406e-04, -2.7563e-04,\n",
            "        -9.4767e-05,  3.5618e-05, -2.3744e-04, -3.5911e-04, -2.3023e-04,\n",
            "         1.7066e-04, -1.2923e-04, -1.5759e-04, -9.3973e-05, -4.4291e-05,\n",
            "        -1.5367e-04,  2.2155e-04,  2.2716e-04,  1.2417e-04,  2.7545e-05,\n",
            "         2.1333e-04, -6.8493e-05,  1.1776e-04,  1.1524e-04, -2.2788e-04,\n",
            "        -2.1131e-04, -3.8993e-04, -3.2663e-04, -1.0938e-04, -7.9760e-05,\n",
            "         1.1529e-04, -1.1491e-04, -5.2952e-04,  1.1018e-04, -7.4545e-05,\n",
            "         2.8571e-04, -8.2870e-05, -6.2638e-05, -2.3053e-04, -1.5274e-04,\n",
            "         3.4367e-04, -3.8686e-05, -1.4881e-05, -1.9629e-06,  9.4935e-05,\n",
            "        -1.2884e-04,  4.1966e-04, -4.6302e-04, -3.2624e-04, -6.2215e-05,\n",
            "        -2.0873e-04,  4.9336e-04, -1.2385e-04, -3.5778e-04,  1.8035e-04,\n",
            "        -4.5169e-05, -4.1188e-04, -2.4551e-04, -2.2855e-05,  7.3614e-04,\n",
            "         2.0022e-04,  1.9912e-04, -1.6289e-04, -1.8831e-04,  4.6793e-04,\n",
            "        -1.3437e-04,  1.0029e-04, -1.5607e-04, -2.1148e-05, -4.5020e-04,\n",
            "         3.7119e-04,  3.8715e-05,  8.2954e-05, -2.9502e-04, -2.1064e-04,\n",
            "         8.3871e-05,  2.0551e-04,  7.6666e-04,  2.3623e-04, -1.9935e-04,\n",
            "         6.7133e-04,  4.7202e-04,  4.7820e-05, -1.4188e-06,  2.4849e-04,\n",
            "         1.8442e-04,  1.5612e-04, -3.9083e-04,  1.2308e-04, -3.4579e-04,\n",
            "        -5.0441e-04,  1.1589e-04,  4.9120e-05, -4.4850e-04, -1.6245e-04,\n",
            "         3.2290e-04, -6.2708e-04, -2.3855e-04, -1.2333e-04, -6.8369e-05,\n",
            "        -2.6652e-04,  2.1430e-05,  2.4945e-04, -4.4512e-04, -2.2842e-04,\n",
            "         2.6137e-04, -1.6555e-04,  1.0335e-04, -1.9738e-04,  4.6914e-04,\n",
            "         2.8271e-04,  3.7807e-04, -3.0398e-06,  3.0261e-04, -1.6527e-04,\n",
            "         7.7550e-05,  8.3004e-05,  2.1209e-04,  4.6351e-05, -4.4410e-04,\n",
            "         1.2227e-04, -1.5242e-04, -4.4648e-04, -1.8643e-05, -4.7519e-04,\n",
            "        -1.7436e-04, -5.0100e-04, -2.0713e-04,  2.1534e-04,  7.1335e-05,\n",
            "         1.1168e-04, -1.1527e-05, -7.5507e-05, -2.0131e-04, -8.3029e-05,\n",
            "        -1.6715e-04, -4.8052e-04, -4.2157e-04, -2.3795e-04,  2.5012e-04,\n",
            "         2.7210e-04, -8.2545e-05, -2.2608e-04, -6.5602e-05,  4.3380e-06,\n",
            "        -4.9033e-04, -1.9555e-04,  1.5610e-06, -9.9494e-05,  2.0485e-04,\n",
            "        -1.6159e-05,  1.0255e-04,  4.1127e-05,  3.4943e-04,  2.5383e-04,\n",
            "         1.5601e-05, -1.0318e-04,  4.1427e-04, -3.1531e-04, -1.8162e-04,\n",
            "        -6.7293e-05,  1.3916e-04, -2.1549e-05,  4.8156e-05, -1.1677e-04,\n",
            "        -6.8633e-05,  5.1654e-04, -2.5262e-04,  1.1541e-04,  2.9506e-04,\n",
            "        -4.2790e-05,  1.0085e-04, -5.8439e-04,  7.8472e-05,  5.3652e-05,\n",
            "         3.2369e-04,  9.2129e-05, -1.3516e-04, -7.7064e-05,  4.9934e-05,\n",
            "         2.2520e-04, -6.2243e-04, -3.7005e-04, -3.0086e-05, -5.2335e-05,\n",
            "        -1.9407e-04, -4.8071e-05, -2.7483e-04, -3.3612e-04,  1.5746e-04,\n",
            "        -2.2882e-05,  5.4285e-04, -2.7530e-04,  2.0584e-04,  2.1319e-04,\n",
            "        -9.4983e-05,  1.7295e-04, -3.8955e-04, -5.7838e-05,  3.3526e-04,\n",
            "        -3.4608e-04,  2.4888e-04,  4.6125e-06, -2.9118e-04, -3.1542e-04,\n",
            "         3.7307e-04,  6.6850e-04, -1.6820e-04, -5.0674e-04, -3.5114e-04,\n",
            "         1.1779e-04, -4.4939e-06,  4.2148e-04, -3.0135e-04,  3.3976e-04,\n",
            "         1.2984e-04,  2.4357e-04, -5.1785e-04,  1.4670e-04, -2.8977e-04,\n",
            "        -3.0507e-04,  1.4319e-04, -6.3731e-05, -1.5141e-04, -8.8044e-05,\n",
            "        -4.5721e-04,  2.1735e-04,  2.2474e-04,  4.8173e-05, -2.1213e-04,\n",
            "         2.0673e-04, -2.5404e-05, -1.0533e-04, -7.4591e-06, -4.5182e-04,\n",
            "         4.1966e-04,  9.3678e-05,  1.3297e-04,  3.5601e-05,  3.6826e-04,\n",
            "        -9.0839e-05, -7.4525e-05, -2.4432e-04, -9.4587e-05,  1.7496e-04,\n",
            "        -3.5919e-04,  4.1865e-05, -3.5563e-04,  1.0058e-04,  4.8504e-04,\n",
            "        -3.0845e-04,  2.0958e-04,  2.6964e-04,  1.3948e-04,  1.4687e-05,\n",
            "        -5.8631e-06, -2.6395e-05, -1.5635e-05,  4.1136e-05, -4.1465e-04,\n",
            "        -1.0301e-04, -5.2723e-04,  3.8152e-04,  5.4188e-04, -6.4822e-04,\n",
            "         2.0865e-04, -1.1626e-04,  1.8983e-04, -3.0444e-04, -2.7931e-05,\n",
            "        -4.0980e-06,  2.4837e-04,  2.1990e-04, -4.0590e-04, -1.9480e-05,\n",
            "         6.2255e-05, -1.5243e-04, -4.5755e-05, -2.6177e-04, -1.2603e-04,\n",
            "        -2.3482e-05, -8.6891e-05, -1.0322e-04,  6.1567e-04, -4.1404e-05,\n",
            "         4.7932e-05, -2.3421e-04, -4.2097e-04, -4.2899e-04, -8.3431e-05,\n",
            "         3.3457e-04,  1.7439e-04, -3.7472e-04,  1.7422e-05, -2.4456e-04,\n",
            "         7.9443e-05,  2.1919e-04,  1.0670e-04, -8.0913e-05, -1.8996e-04,\n",
            "        -3.2802e-04,  7.2680e-05, -1.7108e-04,  1.0310e-04,  2.9215e-04,\n",
            "        -1.7680e-04,  1.0157e-04,  2.5192e-04, -1.6782e-04, -5.4571e-06,\n",
            "        -4.0582e-04,  4.1990e-04, -5.2296e-04,  9.6547e-06, -3.8867e-04,\n",
            "        -5.8068e-06, -2.2316e-04, -1.0129e-04,  2.6879e-04,  2.3066e-04,\n",
            "        -2.5940e-04,  1.0040e-04,  5.5865e-05,  3.3665e-04,  7.6331e-05,\n",
            "         3.7790e-05,  4.3852e-04,  1.7663e-04,  3.6937e-04,  4.9081e-05,\n",
            "         7.0367e-05,  1.6922e-04, -1.6843e-04,  2.7801e-05,  3.0244e-04,\n",
            "         2.8880e-04,  2.0048e-04, -2.7745e-04,  1.6096e-04,  3.2215e-04,\n",
            "         3.0246e-04, -1.4859e-04,  8.3712e-05, -2.0051e-04, -2.1435e-04,\n",
            "        -2.6093e-04, -6.8227e-04,  1.0985e-04, -2.8495e-04, -3.6145e-04,\n",
            "         2.3191e-04, -4.6046e-05, -2.4108e-04,  5.5919e-05, -3.4258e-04,\n",
            "        -2.6781e-04,  9.5000e-05, -5.6446e-06,  8.8678e-05, -2.4052e-04,\n",
            "         2.1577e-04,  4.7195e-04, -4.5732e-04,  2.1809e-04, -1.1519e-04,\n",
            "         3.0532e-04,  2.1798e-04,  1.3460e-04, -2.6061e-04,  3.9612e-05,\n",
            "        -1.7756e-04, -4.3296e-06, -3.0303e-05, -1.1385e-04, -7.3317e-05,\n",
            "        -2.2422e-04,  4.9520e-04,  3.5653e-04,  3.5040e-05, -1.3734e-04,\n",
            "         2.0115e-04,  1.8076e-04, -2.4320e-05,  3.6470e-04, -1.0099e-04,\n",
            "        -4.4320e-04,  3.7397e-04, -7.7302e-05, -4.5409e-05,  2.6440e-04,\n",
            "        -4.7114e-04,  2.8337e-04,  2.1818e-04,  9.0141e-06, -2.8857e-04,\n",
            "        -3.2432e-04,  4.4416e-04,  1.6598e-04,  1.0390e-04, -3.2590e-04,\n",
            "        -8.2300e-05,  3.7347e-04,  2.3189e-05], device='cuda:0')\n",
            "ITEM 12 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['female', 'male', 'hat', 'window']\n",
            "y_hat_labels_str = ['hat', 'female', 'male', 'window']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['female', 'male', 'hat', 'window']\n",
            "y_labels_int_v2 = tensor([ 55,  89,  70, 160], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4567, 0.5000, 0.2716, 0.5216],\n",
            "        [0.2067, 0.4567, 0.3678, 0.5865],\n",
            "        [0.2404, 0.2091, 0.1346, 0.0817],\n",
            "        [0.3750, 0.2608, 0.7284, 0.2404]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['female', 'male', 'hat', 'window']\n",
            "y_hat_bboxes_v2 = tensor([[0.4571, 0.4981, 0.2735, 0.5230],\n",
            "        [0.2037, 0.4538, 0.3612, 0.5696],\n",
            "        [0.2437, 0.2065, 0.1358, 0.0729],\n",
            "        [0.5359, 0.2681, 0.3778, 0.2298]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0037, 0.0013, 0.0029,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0068, 0.0013, 0.0036,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0060, 0.7914, 0.0058,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0037, 0.0391, 0.0032,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0', grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 14.886006355285645 = 9.337050437927246 + 5.548955917358398\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 4.3093e-04,  1.1909e-03,  2.3976e-04, -1.8680e-04, -1.4254e-03,\n",
            "         1.4301e-03,  8.9433e-04,  3.0588e-04, -1.1128e-03,  5.0959e-04,\n",
            "         1.2720e-04,  4.2288e-04, -7.3934e-04, -3.4838e-04,  2.0194e-04,\n",
            "         8.1887e-04,  2.1729e-03,  2.2259e-03,  1.6177e-03,  2.1426e-04,\n",
            "         5.8819e-04, -5.6112e-04, -2.7573e-03,  3.4590e-04,  1.3214e-05,\n",
            "        -1.5902e-03,  1.3778e-03,  5.6062e-04,  1.6773e-03,  1.4784e-03,\n",
            "        -1.8980e-03,  1.8936e-04, -5.4487e-04,  1.9639e-03, -1.3308e-05,\n",
            "         1.0055e-03, -5.4078e-04, -2.1822e-03, -3.0529e-05, -4.0961e-04,\n",
            "         1.1601e-04,  2.8604e-03, -1.0649e-03, -3.2582e-04,  1.1679e-04,\n",
            "        -1.3315e-03,  9.1264e-05, -1.5908e-04,  7.3696e-05,  8.5213e-04,\n",
            "         8.3989e-04, -5.0597e-04, -1.1707e-03, -2.1493e-03, -1.0549e-03,\n",
            "        -8.5878e-04,  1.3339e-03,  8.3322e-04,  9.0699e-04, -6.2854e-04,\n",
            "         8.3324e-04,  2.6404e-04,  1.8412e-03, -9.3924e-04, -9.8292e-04,\n",
            "         1.1760e-03, -1.5232e-03,  1.4678e-03,  2.2349e-03,  6.9015e-04,\n",
            "        -2.3402e-03, -3.0438e-04,  1.0209e-03, -1.1748e-03, -1.2414e-04,\n",
            "         9.6823e-04,  1.2095e-03, -2.8380e-04, -1.6002e-04, -1.3462e-03,\n",
            "        -7.7992e-04, -1.1984e-03,  1.5097e-03,  1.7674e-03,  3.2857e-04,\n",
            "         3.6788e-04,  6.0304e-04,  3.9872e-04,  1.2304e-03,  3.6441e-04,\n",
            "        -8.4140e-04, -2.7608e-04,  9.2570e-04,  5.8007e-04, -3.9464e-04,\n",
            "         5.7526e-04,  1.4009e-04,  2.9466e-04,  1.7710e-03,  5.3495e-04,\n",
            "        -6.0604e-04, -7.2145e-04, -2.2909e-03,  1.9789e-03, -8.8563e-04,\n",
            "        -1.4739e-04, -6.3512e-04,  7.0050e-04, -2.5279e-03,  8.2415e-04,\n",
            "         1.4330e-03, -8.7593e-04, -2.9720e-03, -1.6739e-03, -2.8362e-03,\n",
            "         1.0308e-03, -8.2047e-04,  1.2777e-03, -1.6358e-03, -1.1540e-05,\n",
            "         2.2860e-03, -1.7241e-03,  2.3059e-03, -4.4478e-04,  1.0052e-03,\n",
            "         7.2438e-04, -3.7526e-05,  3.9509e-04, -1.7287e-04,  9.9565e-04,\n",
            "        -1.0920e-03, -8.8849e-04,  1.3678e-03,  8.3668e-05,  8.2459e-04,\n",
            "         1.0267e-04,  1.6838e-04, -1.0119e-04, -1.7718e-03, -1.9823e-03,\n",
            "         3.7525e-04, -1.3246e-03,  6.2926e-04, -5.5094e-04,  7.5927e-04,\n",
            "         9.6698e-04, -9.7558e-04, -8.4806e-07, -2.7788e-05,  1.8494e-04,\n",
            "         1.1244e-03,  5.3832e-04,  1.4418e-04, -7.4456e-04, -1.4322e-03,\n",
            "         4.6757e-06, -7.8124e-04, -2.1102e-03,  1.3771e-03,  1.1870e-03,\n",
            "         1.2638e-03, -2.5254e-03, -4.3611e-04, -1.1931e-03,  1.3450e-03,\n",
            "         2.2504e-04, -2.8493e-04, -3.6334e-04,  4.0835e-04, -1.7946e-03,\n",
            "         4.0236e-04,  4.6720e-04, -2.3269e-04,  9.4709e-04,  6.7412e-04,\n",
            "        -2.1908e-04,  1.2047e-03, -3.7182e-04, -8.5063e-04, -1.2093e-04,\n",
            "        -1.0905e-03, -1.0877e-03, -1.3992e-03, -1.4709e-03, -2.1345e-04,\n",
            "        -5.4879e-04, -8.9854e-04, -3.1817e-04,  1.8456e-03,  8.3200e-05,\n",
            "         1.6966e-03, -6.2957e-04,  7.2326e-04,  9.8423e-04,  8.3365e-04,\n",
            "        -7.4033e-04, -1.4653e-03, -2.2676e-03,  6.9110e-04, -1.5790e-04,\n",
            "         6.3471e-05,  1.4828e-03,  1.3292e-03, -3.5750e-05,  1.8196e-04,\n",
            "         1.5245e-03, -7.8974e-04, -3.3163e-04, -6.2103e-04,  5.1105e-04,\n",
            "        -1.7760e-03, -1.4359e-03, -1.6620e-04,  1.8073e-03, -1.7080e-03,\n",
            "        -6.8053e-05,  7.3766e-04, -1.6394e-04,  1.0105e-03,  4.8507e-04,\n",
            "         4.6498e-04, -1.0942e-03,  2.9569e-04, -1.7708e-04,  2.1720e-03,\n",
            "         3.8536e-04,  4.9001e-04,  1.7124e-04, -9.3050e-04, -2.3442e-03,\n",
            "         8.8986e-04,  1.7781e-03, -2.8130e-04,  1.4463e-03,  1.1613e-03,\n",
            "        -1.0941e-03,  8.3460e-04, -2.2223e-03,  8.8516e-04, -4.9960e-04,\n",
            "        -1.1530e-03, -1.5043e-03,  1.0573e-03,  9.7729e-04,  7.3946e-04,\n",
            "         1.2581e-03,  4.1797e-04, -1.5926e-03, -1.5121e-03, -2.3237e-03,\n",
            "        -2.9490e-03,  2.4091e-04,  1.3035e-03, -3.6424e-04, -2.1227e-04,\n",
            "        -9.2509e-05,  1.0091e-03, -3.9111e-04, -2.4596e-04, -1.4161e-05,\n",
            "         1.2152e-03,  5.7400e-04, -9.4039e-04,  2.8384e-04,  6.1450e-04,\n",
            "         6.7094e-04, -6.9506e-04,  3.9821e-04, -1.2882e-03, -1.3516e-03,\n",
            "        -9.3650e-04,  1.5055e-03, -1.3282e-03, -5.8151e-05, -6.3783e-04,\n",
            "         1.3272e-03,  1.4125e-04,  4.1390e-04,  1.1413e-03,  1.0543e-03,\n",
            "         9.6370e-04,  1.1789e-03,  1.1471e-05,  5.2665e-04,  3.9462e-04,\n",
            "        -7.0937e-04,  1.2170e-03, -1.9632e-03,  1.1359e-04, -1.0836e-03,\n",
            "        -4.0844e-06,  3.1299e-04, -1.9984e-03, -2.9929e-04,  5.9808e-06,\n",
            "         9.5841e-04, -1.4097e-03,  1.2153e-03,  1.4545e-04,  1.8310e-03,\n",
            "         6.3655e-04,  1.3146e-03, -1.7535e-03, -7.7640e-04, -8.6998e-05,\n",
            "        -1.6373e-03,  6.2124e-04,  1.7712e-03, -1.4604e-03, -1.6485e-03,\n",
            "        -2.3885e-04, -3.4715e-04,  8.5649e-04, -4.8178e-04, -1.2627e-03,\n",
            "         7.3883e-04, -9.6828e-04, -6.8226e-04,  1.5975e-03, -9.3323e-04,\n",
            "         1.1589e-03, -1.2709e-03,  1.1139e-03, -7.2308e-04,  1.9312e-03,\n",
            "        -2.6723e-04, -2.2915e-03,  1.0963e-03,  2.9945e-04,  5.0838e-04,\n",
            "         5.8897e-05, -5.6417e-04,  9.0666e-04, -2.4990e-04,  1.5381e-03,\n",
            "         3.2087e-04, -4.0332e-05,  1.8156e-04,  9.1195e-04, -6.2307e-04,\n",
            "         7.2782e-04,  1.9351e-03, -7.1802e-04, -1.5785e-03,  5.2483e-04,\n",
            "         1.0019e-03, -3.4393e-04, -1.4096e-03,  9.7038e-04, -6.8747e-04,\n",
            "        -3.4397e-03, -1.6681e-03, -9.7658e-04,  1.9946e-04, -2.0134e-03,\n",
            "        -6.0816e-05, -4.9948e-04, -1.6686e-03,  2.0852e-03,  7.8257e-04,\n",
            "        -9.1590e-04,  3.4209e-04, -6.6414e-04,  1.8974e-03,  9.8617e-04,\n",
            "        -1.9749e-03, -2.3295e-03, -5.6929e-04, -9.2097e-04,  1.5168e-03,\n",
            "         1.4805e-03,  1.5501e-03, -4.7520e-04,  5.0500e-04, -9.6551e-04,\n",
            "        -5.6728e-04,  1.0068e-04,  1.6172e-03,  6.5307e-04,  2.2369e-03,\n",
            "         3.4574e-04, -2.0495e-04,  6.6024e-04, -1.6281e-03, -3.3899e-04,\n",
            "         6.1997e-04,  8.5928e-04,  1.9817e-04, -2.3174e-03, -1.2300e-03,\n",
            "         1.4317e-03,  1.5388e-03,  5.3876e-05,  3.2983e-03, -1.9930e-03,\n",
            "         1.2919e-03, -2.8366e-04,  1.6008e-03,  6.9343e-04, -3.6829e-04,\n",
            "         7.4546e-04,  1.2657e-03,  4.3845e-04, -6.3528e-05, -1.1463e-03,\n",
            "        -1.0564e-03, -5.8965e-04, -1.1460e-04,  5.4277e-04,  8.6874e-04,\n",
            "         3.0767e-04, -1.2839e-03, -1.4669e-03,  7.4491e-05,  1.9820e-03,\n",
            "         1.7784e-04, -8.0053e-04, -6.6577e-04, -3.2610e-04, -1.1142e-03,\n",
            "        -6.0449e-04,  1.6171e-03,  1.4633e-03,  2.6420e-04,  9.4944e-04,\n",
            "         3.8710e-04,  2.8165e-04,  2.1387e-04,  1.6971e-03, -5.0341e-04,\n",
            "        -2.5957e-04,  6.6841e-05,  6.7066e-04,  5.2943e-04, -1.0750e-03,\n",
            "        -3.8425e-04, -2.7261e-05, -2.5818e-04, -1.0110e-03, -4.3167e-04,\n",
            "         5.9659e-04, -1.2395e-03,  9.0197e-04, -3.2899e-04, -8.4341e-04,\n",
            "        -1.0826e-03, -1.6603e-03, -2.3499e-03, -1.1874e-03,  1.0849e-03,\n",
            "         2.1997e-03, -8.9285e-04,  1.0245e-03,  5.5800e-05,  1.0489e-03,\n",
            "        -1.8522e-03,  1.2152e-03, -1.3014e-03,  8.4871e-04,  5.3393e-04,\n",
            "         2.7640e-03, -1.8024e-04, -1.6210e-03, -3.6733e-05,  5.0400e-04,\n",
            "         8.3004e-05,  2.1621e-03, -1.7394e-03,  1.4769e-03,  3.0044e-03,\n",
            "        -4.5461e-04, -5.4198e-04, -1.4154e-03,  5.4159e-04, -3.7738e-04,\n",
            "         6.1355e-04,  1.2868e-04, -1.2389e-03,  4.9380e-05,  8.7368e-04,\n",
            "        -7.8344e-04, -6.8862e-04, -1.0393e-04,  5.0228e-05, -2.2481e-04,\n",
            "         1.3540e-03,  3.4882e-04,  4.5287e-05, -2.7453e-03, -7.0821e-05,\n",
            "         1.2754e-03,  2.2791e-03,  9.7764e-04,  9.5270e-04, -1.5537e-03,\n",
            "        -5.8427e-04, -8.5409e-04, -3.4480e-04, -1.2355e-03, -8.6556e-04,\n",
            "         1.0927e-03, -9.3118e-04, -2.4987e-04,  4.9927e-04, -2.0500e-03,\n",
            "        -9.4454e-04, -2.8449e-03, -1.0793e-03,  2.3450e-04,  2.5249e-03,\n",
            "        -1.1146e-03, -4.7820e-04,  1.0501e-03,  2.7216e-05,  7.2374e-04,\n",
            "         2.6121e-03,  9.3629e-04,  1.4779e-04,  1.4796e-04,  9.1696e-04,\n",
            "        -1.0744e-03,  1.2862e-03, -2.0074e-03,  9.1182e-04, -6.9008e-04,\n",
            "         3.6914e-04, -8.8382e-04,  1.4017e-03,  1.2373e-04, -1.2635e-04,\n",
            "        -1.0251e-03,  6.0472e-05,  2.8335e-03,  3.9343e-03, -1.2723e-03,\n",
            "         2.4644e-03, -1.0664e-03,  3.0396e-04, -1.2471e-03,  3.3708e-03,\n",
            "        -1.3638e-03,  2.9581e-04,  5.1492e-04, -7.0292e-05,  4.7399e-04,\n",
            "         3.0256e-04,  2.6668e-04,  4.3335e-04, -1.5908e-04,  3.3592e-04,\n",
            "         7.1652e-04,  1.4912e-03,  1.8097e-03,  1.6829e-03,  1.0190e-03,\n",
            "         8.5099e-04, -1.5684e-03, -1.2244e-03, -5.9296e-04, -1.4608e-03,\n",
            "         6.3195e-04, -5.6860e-04,  2.6538e-03,  9.6103e-04, -3.2867e-03,\n",
            "        -3.4820e-04, -2.7435e-04,  1.4015e-03, -5.7224e-04, -1.8918e-03,\n",
            "        -9.7528e-04,  2.6802e-03,  5.5363e-04,  7.0195e-04, -2.4463e-03,\n",
            "        -9.0280e-04, -1.6686e-03,  5.1800e-04,  1.7778e-03,  6.6179e-05,\n",
            "        -2.6929e-03,  2.9331e-04,  1.9576e-03, -1.1405e-03, -5.8958e-04,\n",
            "        -3.3803e-04, -3.0593e-04,  4.9639e-04,  2.1926e-03,  6.0950e-04,\n",
            "         2.0293e-03, -9.3254e-04,  3.3390e-03, -2.9382e-04, -5.3612e-04,\n",
            "         2.9668e-04,  1.5645e-03, -1.9643e-03, -4.0336e-04, -1.0446e-03,\n",
            "        -5.2785e-04,  1.6369e-03,  2.4707e-05,  2.1365e-03, -5.2313e-04,\n",
            "        -1.6570e-03, -3.2917e-04,  6.2658e-04, -1.8549e-03,  2.0458e-03,\n",
            "         1.5437e-03, -1.8725e-04, -6.6298e-04, -2.0156e-04, -2.2014e-03,\n",
            "        -1.5394e-03, -1.9494e-03, -1.2198e-03, -7.7194e-04, -6.3668e-05,\n",
            "        -8.2209e-04, -3.3554e-04,  9.8992e-06,  1.3595e-03,  9.0215e-04,\n",
            "         2.0272e-03,  3.0865e-04, -1.9658e-04, -3.5576e-04, -7.1054e-04,\n",
            "         1.0447e-03,  5.8154e-05, -1.0905e-04,  1.1641e-03,  1.3963e-03,\n",
            "        -1.4415e-03, -1.8849e-03,  1.2550e-03, -1.9925e-04, -1.1691e-04,\n",
            "         3.4576e-04, -2.9626e-04,  1.3173e-03,  3.2562e-04,  1.3600e-03,\n",
            "         5.0679e-04,  9.7747e-04, -2.9491e-04, -1.3382e-03,  1.5213e-05,\n",
            "         6.6743e-04, -3.2546e-03, -2.2656e-03,  3.4492e-04, -8.9672e-04,\n",
            "        -7.7846e-04, -1.7526e-03,  2.1237e-03,  7.9897e-04, -4.1163e-04,\n",
            "        -6.0698e-04, -1.4599e-04,  5.9854e-04, -1.0416e-03, -1.9315e-03,\n",
            "         1.2777e-03,  5.9228e-04,  9.2507e-04,  9.8688e-04, -1.7854e-03,\n",
            "         1.5514e-05, -9.6350e-04, -1.4805e-03,  1.1796e-03, -1.0257e-03,\n",
            "         4.5241e-04, -1.4157e-05,  6.2168e-04,  4.2559e-04,  5.8151e-04,\n",
            "        -1.3416e-03,  9.5866e-04, -1.5920e-04, -4.6666e-04,  1.0785e-03,\n",
            "         1.0345e-03, -6.8190e-04,  3.6627e-04, -3.2983e-03, -6.0577e-04,\n",
            "        -5.1436e-05, -6.5893e-04,  7.9020e-04, -1.1638e-03,  3.9791e-04,\n",
            "        -1.2333e-03, -1.5879e-03, -4.1088e-04,  1.7420e-03, -1.6299e-03,\n",
            "        -6.9790e-04,  2.4282e-04, -4.2239e-04,  6.3904e-04, -1.6175e-03,\n",
            "         6.8409e-04,  2.5799e-03,  9.1339e-04, -1.9046e-03,  1.9695e-03,\n",
            "         7.8148e-04,  1.7660e-03, -3.0470e-05,  3.8406e-04,  8.9378e-04,\n",
            "        -2.8666e-03, -1.6190e-03,  5.6777e-04,  1.4666e-05, -2.7526e-04,\n",
            "         1.7419e-04, -1.5470e-03,  1.8687e-03, -2.6192e-04, -7.3629e-04,\n",
            "         1.0468e-03, -2.0267e-04,  1.2900e-03, -1.2934e-03, -8.2326e-04,\n",
            "        -6.1007e-04,  1.0175e-03, -2.1209e-03, -1.5668e-03,  5.6511e-04,\n",
            "        -1.3031e-03, -6.9661e-04, -9.8996e-05,  6.6743e-04, -1.8271e-03,\n",
            "         8.1902e-04, -1.7930e-03, -1.0060e-03,  2.7009e-03,  2.0191e-04,\n",
            "        -9.4920e-04, -2.1727e-04,  1.7670e-03,  8.4391e-04, -1.5654e-03,\n",
            "         6.0468e-04, -9.5866e-04,  2.6533e-04,  1.6392e-03, -6.6580e-04,\n",
            "         7.9551e-04,  3.5899e-05,  4.1170e-04, -1.6510e-04,  7.3356e-04,\n",
            "        -4.9152e-04, -2.7265e-03, -4.1028e-04, -1.1298e-03, -4.7456e-04,\n",
            "         6.8234e-04, -9.1756e-04, -1.0480e-04], device='cuda:0')\n",
            "ITEM 13 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['female', 'male', 'male', 'female', 'hat', 'hat', 'hat', 'hat', 'tree']\n",
            "y_hat_labels_str = ['hat', 'hat', 'female', 'male', 'hat', 'female', 'hat', 'male']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['female', 'male', 'male', 'female', 'hat', 'hat', 'hat', 'hat']\n",
            "y_labels_int_v2 = tensor([55, 89, 89, 55, 70, 70, 70, 70], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.6611, 0.5697, 0.2332, 0.6082],\n",
            "        [0.4832, 0.6514, 0.1130, 0.3101],\n",
            "        [0.2861, 0.5649, 0.2212, 0.4808],\n",
            "        [0.6947, 0.7151, 0.1274, 0.3918],\n",
            "        [0.3413, 0.3546, 0.1082, 0.0601],\n",
            "        [0.5000, 0.5252, 0.0865, 0.0625],\n",
            "        [0.6526, 0.3041, 0.1298, 0.0769],\n",
            "        [0.7079, 0.5541, 0.1106, 0.0721]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'female', 'male', 'female', 'hat', 'hat', 'hat', 'hat']\n",
            "y_hat_bboxes_v2 = tensor([[0.6400, 0.5664, 0.2037, 0.6163],\n",
            "        [0.4864, 0.6516, 0.1111, 0.3124],\n",
            "        [0.2874, 0.5668, 0.2068, 0.4790],\n",
            "        [0.7058, 0.7157, 0.1568, 0.3820],\n",
            "        [0.3405, 0.3552, 0.1017, 0.0538],\n",
            "        [0.4996, 0.5241, 0.0847, 0.0560],\n",
            "        [0.6532, 0.2988, 0.1328, 0.0823],\n",
            "        [0.7125, 0.5554, 0.1003, 0.0612]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0035, 0.0058, 0.0031,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0022, 0.0033, 0.0013,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0039, 0.0058, 0.0028,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0041, 0.5413, 0.0056,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0048, 0.6189, 0.0061,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0040, 0.4668, 0.0050,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0', grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.646946907043457 = 0.09836610406637192 + 5.548580646514893\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-5.4629e-06,  8.4158e-05,  4.8533e-05, -5.4617e-05, -2.8590e-05,\n",
            "         6.5763e-05, -2.4278e-05, -7.2061e-06, -4.4816e-05,  8.4920e-05,\n",
            "         1.2232e-05,  3.1266e-05,  9.2219e-05, -1.9069e-05, -2.6975e-05,\n",
            "        -7.1210e-05, -5.4668e-06, -5.8565e-05, -4.1408e-05, -5.6456e-05,\n",
            "        -6.2229e-05, -1.9744e-05,  1.9586e-04,  3.0274e-05, -5.9780e-05,\n",
            "         7.0334e-05, -5.7721e-05,  8.6774e-05, -1.3408e-04, -3.8640e-05,\n",
            "        -7.6760e-05,  1.1084e-04, -3.0433e-06, -4.5909e-05, -1.8873e-05,\n",
            "        -4.0951e-05,  5.0777e-07,  1.0478e-05, -3.4400e-05,  5.3921e-05,\n",
            "        -1.2300e-04, -1.4645e-04, -4.3189e-05, -9.6906e-05,  4.4144e-05,\n",
            "        -8.7162e-05, -3.7090e-05,  3.2518e-05,  4.7891e-05,  5.7409e-05,\n",
            "         1.9459e-05,  2.0608e-04, -9.1425e-05,  1.4391e-04, -7.7412e-05,\n",
            "         3.9529e-05, -3.9360e-05, -4.7740e-05,  9.4900e-05,  4.9204e-05,\n",
            "        -7.8796e-05,  1.1547e-05,  8.1556e-06,  1.0467e-04,  6.6263e-05,\n",
            "        -1.1152e-04,  8.9098e-05,  6.6355e-05, -8.0043e-05,  2.4175e-05,\n",
            "         3.0688e-05, -2.1254e-05, -4.1217e-05,  5.5931e-05,  2.0716e-05,\n",
            "         2.0746e-05,  6.0460e-05, -1.5587e-04,  1.3328e-04,  4.9416e-05,\n",
            "        -1.2172e-04, -2.5897e-05, -2.4940e-05, -2.6841e-05,  1.0796e-05,\n",
            "        -2.7988e-06,  8.1618e-05,  1.3326e-04, -1.2034e-04, -1.3667e-06,\n",
            "         9.2488e-05, -9.0336e-06,  7.6082e-05, -8.6114e-05,  6.4369e-05,\n",
            "         4.7623e-05, -1.2785e-05,  5.4277e-05, -1.0138e-04,  3.2822e-05,\n",
            "         6.6815e-05,  4.0358e-05,  1.1523e-04, -5.4923e-05,  4.7354e-05,\n",
            "         2.3204e-05, -1.5088e-05, -3.4602e-05,  2.5109e-05,  2.8307e-06,\n",
            "        -2.4712e-05,  3.3616e-05, -2.2328e-05, -1.0046e-04,  1.0757e-04,\n",
            "        -2.9041e-05,  1.2000e-04,  6.8667e-05, -7.2260e-06, -4.4387e-06,\n",
            "        -4.1108e-05,  9.1285e-05, -3.0082e-05,  1.1534e-04,  7.7388e-07,\n",
            "        -8.2115e-05,  6.5084e-05,  6.9415e-05, -8.5125e-05, -6.1934e-05,\n",
            "         5.4366e-05, -2.2420e-05,  5.0479e-05, -1.1259e-04, -1.5734e-06,\n",
            "        -7.0035e-05, -1.0030e-04, -1.3919e-05,  1.3770e-04,  3.1887e-05,\n",
            "        -2.6352e-05,  1.0414e-04,  1.1331e-04,  5.1245e-06, -5.4290e-06,\n",
            "         5.2261e-05, -1.1694e-04, -5.0158e-05,  9.2912e-05,  2.1237e-05,\n",
            "        -5.7337e-05, -8.7590e-05,  3.5067e-05, -6.5862e-05, -2.0035e-05,\n",
            "         7.9280e-05,  3.8947e-07, -3.1948e-05, -4.7396e-06, -7.8238e-05,\n",
            "         7.1018e-05, -3.8682e-05,  5.1417e-05,  5.5444e-05,  2.5497e-05,\n",
            "         1.2549e-04, -4.9321e-05,  3.6595e-05,  4.3423e-05,  5.5446e-05,\n",
            "        -8.5536e-06,  1.0575e-05, -1.2131e-04,  7.8072e-05, -5.9863e-06,\n",
            "         8.5628e-05, -8.3724e-05, -3.5559e-05,  3.3385e-06,  8.0566e-05,\n",
            "         4.9096e-07,  5.2079e-05, -4.1720e-05, -1.1117e-04, -1.5077e-05,\n",
            "         1.0189e-04,  3.3568e-05,  1.1656e-05, -5.5579e-05, -3.8902e-05,\n",
            "        -1.0102e-04,  8.8164e-05,  2.6210e-06,  1.1853e-05,  8.6047e-05,\n",
            "         4.2793e-05, -5.8282e-05,  7.7371e-05, -4.8274e-05,  1.3736e-05,\n",
            "        -3.1347e-05, -5.5370e-05,  1.1517e-04, -7.3998e-06, -2.4042e-05,\n",
            "        -1.7400e-05, -5.7354e-05, -3.3791e-05,  3.0719e-05,  7.0126e-05,\n",
            "         3.6395e-05, -2.3693e-05, -1.6026e-05, -7.9020e-05, -1.6104e-04,\n",
            "        -1.1387e-04, -3.0102e-05, -2.3551e-05,  7.9748e-05,  1.8775e-05,\n",
            "         1.1577e-04,  1.9307e-04, -7.1686e-05, -8.5637e-05,  3.4551e-05,\n",
            "         4.9747e-05,  3.0558e-06,  3.1647e-05, -1.0201e-06,  1.5767e-04,\n",
            "        -9.9736e-05, -1.1605e-04,  4.6580e-05, -1.3340e-04, -7.3514e-05,\n",
            "         1.2426e-06,  1.1663e-05,  4.9886e-05,  7.5393e-05,  3.6232e-05,\n",
            "        -8.3089e-05,  5.0713e-05, -2.0229e-05, -1.6543e-05, -2.1798e-05,\n",
            "         9.9236e-05, -2.0540e-06, -1.2401e-04,  1.1054e-04, -1.0821e-05,\n",
            "         1.2742e-04, -1.3080e-04,  8.0570e-05,  2.2684e-05,  2.0276e-05,\n",
            "         2.1855e-06, -6.0516e-05, -1.1784e-05,  4.6481e-05,  1.1780e-04,\n",
            "        -9.2935e-05, -2.8880e-05,  5.1318e-05,  7.9336e-05, -3.4169e-05,\n",
            "        -6.8930e-05, -1.2656e-04, -1.2777e-05,  2.2593e-05,  6.9393e-05,\n",
            "        -7.4211e-05, -9.6610e-05, -9.4089e-06, -3.3499e-05, -9.2450e-05,\n",
            "        -1.0023e-04,  1.1997e-04,  2.5760e-06, -3.4522e-05,  2.1772e-05,\n",
            "        -2.5511e-06,  4.7750e-05,  5.7800e-05,  7.0328e-05, -1.8301e-04,\n",
            "         2.6494e-06, -7.0241e-05,  4.3234e-05,  6.1931e-05,  1.4806e-04,\n",
            "         2.3246e-07, -4.7569e-05,  7.9481e-05,  9.3141e-05,  2.0552e-05,\n",
            "        -5.8107e-05,  1.4896e-04, -1.4944e-06, -1.5962e-04,  6.5262e-05,\n",
            "         4.6430e-05,  1.0194e-04, -7.9500e-05,  5.8282e-05,  2.5545e-05,\n",
            "        -1.4069e-04, -7.8160e-05,  9.6086e-06, -2.3256e-05,  7.0640e-05,\n",
            "        -7.0132e-05, -2.4191e-06,  1.5717e-04, -2.1076e-05, -6.9466e-05,\n",
            "        -5.0515e-05,  1.9731e-05,  2.8059e-06, -5.1242e-05,  7.5509e-05,\n",
            "        -1.1129e-04,  1.2101e-04, -4.8462e-05,  1.8033e-05, -6.2739e-05,\n",
            "        -1.1644e-05,  7.5059e-05,  6.8858e-05,  7.4192e-05, -1.6725e-04,\n",
            "        -3.1590e-05, -1.6792e-04, -2.1500e-05,  1.7135e-04, -5.3447e-05,\n",
            "         1.7770e-05,  1.0868e-04,  7.5684e-05,  3.9974e-05, -5.1105e-05,\n",
            "        -4.4833e-05, -2.6934e-05,  1.4021e-04, -3.2416e-05,  9.9577e-05,\n",
            "        -8.5707e-05,  6.3467e-05,  5.5038e-05,  4.3581e-05,  5.6715e-05,\n",
            "        -2.3749e-05, -1.1777e-04,  6.5182e-05, -1.2367e-04,  7.2874e-05,\n",
            "         4.2722e-05,  1.3114e-04,  4.6301e-05, -9.3940e-05, -2.2930e-05,\n",
            "         8.5566e-05,  6.1357e-05,  1.3397e-04,  7.7356e-05,  8.8808e-05,\n",
            "        -1.5154e-04,  3.4311e-05, -1.7148e-06, -5.5582e-05, -2.3148e-05,\n",
            "         1.5691e-05,  1.0440e-04, -5.1918e-05, -2.6306e-05, -4.4287e-05,\n",
            "         7.6408e-05, -8.4271e-05, -2.7072e-05,  1.0796e-05,  4.1074e-05,\n",
            "        -7.5222e-05, -4.9724e-05, -1.3690e-04, -4.8663e-05, -1.3148e-04,\n",
            "         5.8703e-05,  1.8011e-05,  4.9484e-05, -3.6505e-05, -8.0031e-05,\n",
            "        -1.0341e-05, -1.1315e-04,  9.6851e-06, -8.0055e-06, -2.6694e-05,\n",
            "         2.7251e-05, -1.3093e-04, -3.8960e-05,  4.2037e-05, -6.2826e-05,\n",
            "        -1.1609e-04, -6.2874e-05,  6.0257e-05,  2.2656e-05, -1.9110e-05,\n",
            "         2.3721e-05,  1.4789e-04,  2.7652e-05,  1.3913e-05, -2.8853e-05,\n",
            "         2.0624e-05,  1.1165e-04,  7.2681e-06,  1.0872e-04,  8.2428e-05,\n",
            "        -4.9237e-05, -3.4491e-05, -9.5469e-06, -6.2116e-06, -2.5877e-05,\n",
            "        -2.0992e-06, -1.2666e-04, -3.0731e-05, -8.7854e-05, -2.7569e-06,\n",
            "        -7.9209e-06, -5.4112e-05,  1.1976e-06,  4.8811e-05,  5.2002e-05,\n",
            "        -1.8584e-06, -1.4943e-04, -4.2366e-05,  7.4874e-05, -1.4571e-06,\n",
            "        -1.8830e-06,  1.8141e-05,  1.0160e-04, -1.0181e-04, -4.0780e-05,\n",
            "        -5.9325e-05,  5.2056e-05,  5.1230e-05, -3.6066e-05, -9.1110e-07,\n",
            "        -1.4927e-05,  6.8539e-05,  6.1968e-05, -9.6248e-06,  1.2384e-04,\n",
            "        -1.4517e-06, -7.0828e-05, -5.8989e-05, -1.4203e-04, -8.7379e-05,\n",
            "        -4.8314e-05,  4.5988e-05, -1.4277e-05, -2.9716e-05,  2.5473e-05,\n",
            "        -1.1418e-04,  4.0207e-05,  4.8649e-05, -2.7116e-06, -3.4877e-06,\n",
            "        -3.2900e-05,  9.6696e-05,  8.1330e-05,  8.3826e-05, -2.9326e-05,\n",
            "         6.0677e-06,  2.6811e-05,  4.1001e-06, -1.8163e-05, -6.5075e-05,\n",
            "         1.0907e-04,  1.5387e-05, -6.8024e-05,  6.2170e-05,  1.0409e-06,\n",
            "         7.3240e-06,  5.3151e-05, -1.0248e-05,  4.1644e-06, -1.2880e-04,\n",
            "        -1.3713e-05, -1.1749e-04, -7.0344e-05, -3.2578e-05,  4.1022e-06,\n",
            "         9.6043e-05, -1.2369e-04, -7.5554e-06, -7.4894e-05,  7.6514e-05,\n",
            "         5.7636e-05,  1.1805e-04,  3.8553e-05,  5.1157e-05,  4.3788e-05,\n",
            "         9.4123e-05, -8.3364e-05,  5.8759e-05,  6.0847e-05, -8.2178e-05,\n",
            "         4.7083e-06, -7.8002e-05,  1.0307e-04,  3.3251e-05, -1.7892e-05,\n",
            "         9.3412e-05, -6.1773e-05, -7.2987e-05,  5.0836e-05, -1.0538e-04,\n",
            "        -9.2032e-05,  6.5626e-05,  4.3356e-05, -1.5203e-05, -2.5605e-05,\n",
            "        -6.8386e-05, -7.9832e-05,  1.7447e-05,  4.7358e-05,  9.3193e-05,\n",
            "        -9.1423e-05, -2.7976e-05, -1.0467e-04, -5.4607e-05, -2.0057e-05,\n",
            "         8.4515e-05, -3.9572e-05, -7.6618e-05, -3.4706e-05,  4.3449e-05,\n",
            "        -1.2277e-04,  2.8082e-05, -7.9833e-05,  8.3642e-05, -6.0325e-05,\n",
            "         4.1558e-05,  3.8479e-05, -9.7858e-06, -8.7616e-05,  9.2893e-05,\n",
            "        -3.2493e-05, -7.2151e-05, -7.0394e-05, -5.3272e-05,  4.3310e-05,\n",
            "        -4.2485e-06,  3.0990e-05, -1.2349e-04,  1.7878e-06, -2.0254e-05,\n",
            "        -8.3988e-05,  3.0565e-05,  1.1839e-05, -6.4635e-05,  5.8932e-06,\n",
            "         5.0792e-05, -2.5385e-05, -5.1381e-05, -3.1473e-05, -4.0019e-05,\n",
            "        -7.4285e-05,  2.7313e-05, -4.1443e-05,  1.8373e-05, -6.3852e-05,\n",
            "        -8.6577e-05, -1.0748e-05, -7.3701e-05, -7.0958e-05,  1.4882e-05,\n",
            "         1.3840e-05,  1.8260e-04, -2.1530e-05, -8.8279e-05,  5.8802e-05,\n",
            "         1.0176e-04, -4.8528e-05, -9.1357e-07, -1.5219e-04, -5.0902e-05,\n",
            "        -6.3230e-05,  9.0254e-05,  3.7525e-05, -1.8309e-05, -1.3722e-05,\n",
            "        -3.6263e-05,  6.0128e-05,  1.0473e-04, -1.3573e-04,  9.8112e-05,\n",
            "        -4.8418e-05,  7.5094e-05, -7.9109e-05,  1.0394e-05,  3.8288e-05,\n",
            "         5.9737e-05, -5.5549e-06,  1.8023e-05,  7.1536e-05,  7.7534e-05,\n",
            "        -2.1452e-05, -1.0305e-04, -5.8318e-05, -1.4024e-04,  8.6077e-05,\n",
            "         9.6901e-06,  4.5681e-05, -2.2753e-05,  6.6856e-05,  9.7309e-05,\n",
            "        -3.5687e-05,  1.2935e-04,  1.2599e-04, -5.0153e-05,  8.5507e-06,\n",
            "        -1.9961e-05,  2.4739e-05, -6.8321e-05, -8.6673e-06, -4.0068e-05,\n",
            "         2.2096e-05, -7.3864e-05, -5.5326e-05,  1.8033e-04,  2.1726e-05,\n",
            "        -2.1451e-05,  2.3444e-06,  3.0420e-05, -3.5284e-05, -8.9280e-05,\n",
            "         5.1888e-05, -5.1373e-05, -3.5528e-05,  8.5483e-06, -6.9548e-05,\n",
            "         1.2169e-04, -6.9928e-06,  9.0683e-05, -1.1696e-04,  4.0690e-05,\n",
            "        -9.7128e-05,  8.4059e-05,  2.8290e-05,  1.1783e-04, -2.3307e-05,\n",
            "        -3.9123e-05,  1.1941e-05,  9.2573e-05,  3.6034e-05, -2.9360e-05,\n",
            "        -4.5287e-05,  1.0094e-04, -1.3112e-04, -2.1292e-05, -3.8601e-06,\n",
            "        -1.8211e-05, -9.2089e-05,  2.5795e-05,  6.4349e-05,  5.2080e-05,\n",
            "         1.2145e-04,  1.3192e-05,  2.0723e-05,  4.0843e-05,  6.2928e-05,\n",
            "        -4.9665e-05,  5.6469e-05, -6.1044e-05, -3.6926e-05, -6.1502e-05,\n",
            "        -2.1402e-05, -5.1169e-05, -1.3781e-04,  1.8767e-05, -8.6221e-05,\n",
            "         1.6492e-05, -1.6229e-05,  1.0281e-05,  1.1671e-05,  1.0896e-04,\n",
            "         4.4768e-05,  7.3400e-05,  9.8089e-06,  2.1806e-05, -1.2914e-04,\n",
            "         6.6269e-05,  1.1894e-04,  5.7021e-06,  3.5419e-05, -3.6461e-05,\n",
            "         2.1707e-05, -4.8071e-05, -4.3653e-06,  1.7859e-05,  8.1208e-05,\n",
            "         4.2108e-05,  4.3445e-05, -7.1667e-05, -4.8563e-05,  4.7030e-06,\n",
            "         1.0905e-05, -5.6780e-05,  1.1921e-04,  3.8635e-06, -4.4783e-05,\n",
            "        -1.0847e-05,  4.9489e-06, -3.0800e-05,  7.4318e-05, -3.5597e-05,\n",
            "         1.1182e-04, -2.3167e-05, -6.1231e-05,  1.4954e-05,  1.8894e-05,\n",
            "         1.5869e-05,  3.4364e-05, -1.7538e-06, -2.5437e-05, -2.0446e-04,\n",
            "         1.8168e-05, -6.3060e-05, -1.2202e-04,  4.4157e-05, -1.2209e-04,\n",
            "        -4.1776e-05, -1.9578e-05,  1.6156e-04,  9.7149e-05, -3.4047e-06,\n",
            "         6.9018e-05,  1.2131e-04, -4.3116e-05,  7.9359e-06, -2.7688e-05,\n",
            "         5.4729e-05,  5.0440e-05,  9.0534e-05,  7.5756e-05, -3.5388e-05,\n",
            "         4.2989e-05, -5.3711e-05, -1.0184e-04,  2.1556e-05,  6.0616e-06,\n",
            "        -8.5935e-05, -4.5712e-05,  2.0912e-04, -6.4748e-05,  6.9313e-05,\n",
            "         1.0260e-04,  1.5905e-05,  1.5848e-05, -5.4736e-05, -3.7059e-05,\n",
            "        -8.3026e-06,  1.2927e-04,  1.1549e-05,  6.7429e-05, -1.2042e-04,\n",
            "        -8.8310e-05, -9.4727e-06, -7.9554e-05], device='cuda:0')\n",
            "ITEM 14 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['horse', 'female', 'horse', 'male', 'male', 'male', 'male', 'male', 'tree']\n",
            "y_hat_labels_str = ['horse', 'female', 'male', 'female', 'horse', 'male']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['horse', 'female', 'horse', 'male', 'male', 'male', 'male', 'male']\n",
            "y_labels_int_v2 = tensor([73, 55, 73, 89, 89, 89, 89, 89], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.3389, 0.3053, 0.4231, 0.2909],\n",
            "        [0.3413, 0.8425, 0.1250, 0.2284],\n",
            "        [0.2091, 0.7524, 0.0938, 0.1971],\n",
            "        [0.1466, 0.8654, 0.1154, 0.2404],\n",
            "        [0.4038, 0.7837, 0.0889, 0.2885],\n",
            "        [0.2596, 0.8053, 0.1875, 0.3293],\n",
            "        [0.3486, 0.2043, 0.2067, 0.3221],\n",
            "        [0.6382, 0.2404, 0.2452, 0.1899]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['horse', 'female', 'female', 'female', 'female', 'female', 'male', 'horse']\n",
            "y_hat_bboxes_v2 = tensor([[0.3368, 0.3160, 0.4130, 0.2719],\n",
            "        [0.3413, 0.8427, 0.1348, 0.2256],\n",
            "        [0.1507, 0.8728, 0.1000, 0.2284],\n",
            "        [0.1507, 0.8728, 0.1000, 0.2284],\n",
            "        [0.3413, 0.8427, 0.1348, 0.2256],\n",
            "        [0.3413, 0.8427, 0.1348, 0.2256],\n",
            "        [0.3498, 0.2092, 0.1969, 0.3089],\n",
            "        [0.6260, 0.3528, 0.1923, 0.1770]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0034, 0.0157, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0022, 0.0613, 0.0028,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0027, 0.1380, 0.0033,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0022, 0.0613, 0.0028,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0045, 0.4066, 0.0072,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0023, 0.0236, 0.0020,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0', grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 7.772409439086914 = 2.2244865894317627 + 5.5479230880737305\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 8.8426e-04, -4.5996e-04, -1.0934e-04,  8.1474e-05, -6.6103e-04,\n",
            "         2.5261e-04, -1.6237e-04,  5.6042e-04,  1.8006e-04,  5.2362e-04,\n",
            "        -6.9436e-04, -4.8840e-04, -7.9579e-04,  8.4071e-04, -3.3932e-04,\n",
            "         5.0470e-04,  3.4795e-04, -4.1321e-04, -3.2378e-04,  4.0355e-04,\n",
            "         4.0858e-04, -9.3641e-04,  4.6679e-04,  5.7910e-05,  9.5069e-05,\n",
            "         4.6179e-04,  9.3614e-04, -7.1571e-05,  6.6125e-04,  1.6940e-04,\n",
            "        -2.1053e-04, -4.1708e-04,  2.9262e-05,  3.6654e-04,  3.8144e-04,\n",
            "         9.7545e-04,  2.3684e-04, -4.0834e-05,  2.6042e-04, -9.7827e-05,\n",
            "        -3.4596e-06, -1.3890e-04,  6.4073e-04, -2.5163e-05,  3.1837e-04,\n",
            "        -7.2400e-04, -7.0485e-04, -9.4729e-04, -4.9870e-04, -5.3661e-04,\n",
            "        -4.3905e-04,  2.9219e-04, -5.4725e-04, -1.5450e-04, -3.0252e-04,\n",
            "        -5.8317e-04, -1.1623e-03, -1.1980e-04, -2.9414e-04,  1.0582e-04,\n",
            "         1.2067e-04, -1.3261e-04, -6.0372e-04,  2.5328e-04,  2.6634e-04,\n",
            "         6.6566e-04, -1.7228e-04,  9.1915e-04,  6.0353e-04,  9.8633e-04,\n",
            "         1.1294e-04, -3.9265e-04, -1.3979e-04, -6.5839e-04, -3.8895e-04,\n",
            "         4.9910e-04, -1.0658e-04,  3.9521e-04,  2.6211e-04, -5.7425e-04,\n",
            "         3.0723e-04,  1.4164e-04, -5.4833e-04,  1.1615e-04,  2.6652e-04,\n",
            "        -5.5359e-06,  6.0171e-04, -6.4955e-04,  1.6025e-04,  5.1764e-04,\n",
            "         7.2965e-04, -3.8851e-04,  4.4056e-04,  2.1287e-04, -1.9457e-05,\n",
            "         5.3769e-04,  2.4398e-04,  4.2829e-04, -3.3298e-04, -3.5544e-05,\n",
            "         4.6827e-04,  2.5074e-04, -1.6177e-05, -8.9577e-05, -6.2119e-05,\n",
            "         1.1956e-04, -4.3856e-05,  4.4769e-04,  6.0053e-05,  1.6137e-04,\n",
            "         1.7454e-04, -1.1638e-04, -9.7959e-05, -2.9427e-04,  3.1230e-04,\n",
            "        -2.2225e-05,  5.4106e-05,  2.2964e-04, -1.8336e-06, -1.3278e-04,\n",
            "        -2.1491e-04, -1.0063e-03,  5.9231e-04,  8.0052e-05,  6.1052e-04,\n",
            "         7.2288e-04,  1.7524e-04,  1.1551e-03, -1.2401e-04,  3.5430e-04,\n",
            "         3.4587e-04, -2.9212e-04,  1.5895e-04,  2.8103e-04, -5.9695e-06,\n",
            "         4.1563e-05,  3.6316e-04, -6.6270e-04,  1.4033e-05, -1.4469e-03,\n",
            "         2.2647e-04, -2.0311e-04, -1.4155e-04, -7.8221e-04, -6.3260e-04,\n",
            "        -1.8844e-05, -6.8313e-04, -6.1280e-04,  2.1817e-04, -2.5607e-04,\n",
            "         3.5455e-04,  7.4339e-05,  4.2429e-04,  2.0279e-04, -2.4466e-04,\n",
            "         2.1686e-04, -3.7749e-04,  8.5039e-05,  8.5313e-04, -1.9474e-04,\n",
            "         8.1282e-04, -6.2915e-04, -2.1616e-04,  2.1637e-04, -5.6771e-04,\n",
            "        -5.0725e-05,  2.2773e-04,  1.3082e-04,  1.0847e-04,  1.6630e-04,\n",
            "         1.3394e-04, -5.8895e-04,  3.1579e-04,  1.0938e-03,  3.2133e-04,\n",
            "         1.1098e-04,  4.4242e-04, -6.2200e-05,  5.3327e-04,  1.0634e-03,\n",
            "         1.2712e-04, -7.3316e-04,  6.7606e-04,  1.9567e-04,  7.3257e-04,\n",
            "        -3.1977e-04,  4.9642e-04, -4.1320e-04,  4.8330e-04,  9.0398e-05,\n",
            "         3.9868e-05,  5.2371e-04,  3.7114e-04, -3.0861e-04, -2.3858e-04,\n",
            "         1.4459e-04,  6.0538e-05,  4.8359e-05, -4.0713e-04, -1.2835e-04,\n",
            "         3.5834e-04, -6.6205e-04,  3.7232e-06,  2.3265e-04, -6.1664e-04,\n",
            "         8.6508e-04,  2.2979e-06, -6.2704e-04,  2.4593e-04,  3.5724e-04,\n",
            "        -1.5620e-04,  9.1550e-04, -6.2701e-04, -3.9988e-04, -6.4699e-04,\n",
            "         8.5125e-06,  3.2239e-05, -2.5265e-04,  7.8283e-04,  6.6343e-04,\n",
            "        -3.9268e-04,  5.7226e-05, -6.1782e-04,  3.1622e-04, -5.6877e-05,\n",
            "         4.4722e-04, -6.9219e-05, -5.4992e-04,  1.4264e-05,  2.0063e-04,\n",
            "        -1.8175e-04,  3.5980e-04, -6.9854e-04, -1.7646e-04, -2.5093e-04,\n",
            "         1.9091e-04,  1.7010e-04,  3.5508e-04,  6.7902e-05,  4.2685e-04,\n",
            "         2.5062e-04, -6.2521e-04,  5.1569e-04,  6.8319e-04, -3.4445e-04,\n",
            "        -1.8845e-04, -6.9342e-05, -9.9071e-04, -6.8805e-05,  3.8248e-04,\n",
            "        -2.1787e-04, -7.3665e-04,  4.5617e-04,  7.6319e-04, -3.7240e-04,\n",
            "         8.7470e-05,  3.8420e-04,  1.7988e-04, -5.5512e-04, -1.1418e-04,\n",
            "        -6.7768e-04,  2.1133e-04, -3.1649e-04, -6.7572e-04, -4.2425e-04,\n",
            "        -9.7610e-05,  5.3369e-04,  1.0433e-04,  9.9872e-05, -5.8744e-04,\n",
            "         9.0205e-06,  1.3432e-04, -2.6430e-04, -6.0253e-06, -5.7882e-05,\n",
            "        -1.5397e-04,  4.0270e-04,  2.8122e-04,  5.1219e-05,  3.5841e-04,\n",
            "        -2.3263e-04, -4.5318e-04,  3.6683e-04,  1.1760e-04,  6.6068e-05,\n",
            "        -3.5545e-04, -5.5792e-04,  8.4900e-04,  4.0002e-04, -5.6900e-04,\n",
            "         6.3130e-04,  1.8645e-04, -3.3994e-04, -5.4009e-04, -4.1815e-04,\n",
            "        -5.1894e-04,  4.9326e-04, -2.1822e-04, -2.4028e-04,  1.1313e-03,\n",
            "         1.0743e-05,  4.5844e-04,  1.7191e-04, -4.3449e-04, -3.0255e-04,\n",
            "         6.0292e-04, -3.2576e-04, -8.9055e-04, -1.2045e-03,  3.4145e-04,\n",
            "         1.9868e-04, -7.5813e-04, -1.3070e-04,  1.2513e-04, -3.6162e-04,\n",
            "         3.1735e-04,  1.4035e-04,  5.7450e-04,  2.9126e-04, -3.0846e-04,\n",
            "        -3.0943e-04, -7.3573e-04,  1.2697e-03, -4.0224e-04,  2.0644e-05,\n",
            "        -2.4658e-04, -9.8630e-05, -6.5573e-04,  1.8844e-04, -3.0152e-04,\n",
            "         2.6370e-04,  6.6814e-04, -1.0982e-04, -9.5983e-04,  8.1106e-04,\n",
            "         2.4394e-04, -1.9805e-04, -4.3526e-04,  4.2653e-04,  3.2552e-04,\n",
            "         7.5366e-05, -1.3052e-03,  5.9438e-04, -3.3972e-04,  9.6583e-04,\n",
            "        -2.4998e-04,  6.1860e-04,  4.6336e-04,  7.5170e-05,  6.6579e-04,\n",
            "         3.8939e-04,  1.4073e-04,  2.0362e-04,  5.9997e-04, -2.0424e-04,\n",
            "         5.5234e-04,  3.7658e-04,  8.6801e-05,  8.4427e-04,  2.8402e-04,\n",
            "        -3.5118e-04,  3.2325e-04, -7.0213e-04,  5.0390e-04, -1.1626e-04,\n",
            "         1.6338e-04, -5.0487e-04,  7.4770e-04,  4.7081e-04, -1.2146e-04,\n",
            "        -3.3445e-04,  7.3158e-05, -6.8488e-04,  5.0597e-04, -1.1596e-03,\n",
            "         3.8301e-04,  1.1252e-04,  9.4624e-04,  3.5540e-04,  4.9920e-04,\n",
            "         1.5746e-04, -2.2246e-04,  1.6459e-04, -5.7018e-05,  3.4355e-04,\n",
            "         1.7862e-04,  1.1448e-03, -4.4325e-04, -3.4509e-04,  1.7703e-04,\n",
            "        -1.0003e-03, -2.7403e-04, -5.5436e-04, -6.6099e-04, -3.1388e-05,\n",
            "         2.6572e-04, -4.5401e-04, -2.4439e-04,  2.8031e-04, -1.7021e-04,\n",
            "         4.3889e-04,  4.8723e-04,  1.5325e-04,  2.5536e-04, -5.9762e-04,\n",
            "        -4.1671e-04,  6.3708e-04, -4.6189e-04, -3.5429e-04,  5.9524e-05,\n",
            "        -1.3996e-04,  4.5309e-04, -6.4950e-04,  8.7931e-05,  1.2119e-04,\n",
            "        -1.3743e-03,  4.5157e-04, -4.1725e-04, -8.1432e-04, -2.2676e-04,\n",
            "         2.4696e-04, -6.9886e-04, -5.0442e-04,  5.8195e-04,  3.6322e-04,\n",
            "        -5.4067e-05,  2.4206e-04,  5.0524e-04,  2.7536e-04, -2.0226e-04,\n",
            "        -5.9422e-04,  3.8775e-04,  4.0394e-04, -2.2368e-04, -3.7714e-04,\n",
            "         1.1218e-04, -2.3970e-04,  9.5412e-04,  1.3334e-04,  3.0049e-04,\n",
            "        -5.9492e-06,  4.9358e-04, -5.2912e-04,  1.6150e-04, -5.5858e-04,\n",
            "        -1.2462e-04,  9.3742e-04,  1.3230e-04,  2.2850e-04, -2.0338e-04,\n",
            "        -3.1076e-04,  8.3887e-04, -1.0473e-04,  1.9406e-04, -5.0233e-04,\n",
            "        -4.1408e-05,  1.0316e-03,  6.9351e-04,  4.3372e-04, -7.3210e-04,\n",
            "        -3.5870e-04, -1.9961e-04,  2.6559e-04,  4.4417e-04,  4.9651e-06,\n",
            "        -9.6258e-05, -3.4541e-04,  4.1249e-04, -3.9338e-04,  4.0162e-04,\n",
            "        -7.8087e-05, -5.9653e-04, -3.9734e-04,  1.1224e-04,  8.1055e-04,\n",
            "         7.6079e-05, -5.4415e-04, -4.8706e-06, -5.6425e-04,  4.0948e-04,\n",
            "         2.6257e-04, -3.2329e-04,  1.5732e-04,  3.2440e-04, -4.8964e-05,\n",
            "        -1.8501e-04, -1.0988e-03,  3.6184e-06, -5.1514e-04, -6.6514e-04,\n",
            "         9.1325e-05,  1.3382e-04, -1.3224e-04, -5.4680e-04, -5.9986e-04,\n",
            "        -2.6928e-04, -3.4422e-04,  9.2436e-04, -1.0096e-04, -6.8963e-05,\n",
            "        -1.9019e-04, -2.8940e-05, -6.2271e-04, -1.0070e-03,  6.0618e-04,\n",
            "        -3.8473e-04, -3.6696e-04, -1.5585e-05, -9.3759e-05,  3.2177e-04,\n",
            "         1.3207e-04,  2.3640e-04, -3.3360e-04,  2.7743e-04, -6.1331e-04,\n",
            "        -1.4751e-04, -2.5834e-04,  4.8439e-04, -1.5575e-04,  4.1277e-04,\n",
            "        -5.7543e-04,  1.3154e-03,  2.4314e-04, -8.2432e-04, -2.6196e-04,\n",
            "         2.5194e-04, -2.9184e-04,  4.8577e-04,  5.2888e-04, -3.6000e-04,\n",
            "         8.5671e-04,  5.8034e-04,  9.1717e-04, -1.8227e-04, -5.4709e-04,\n",
            "         3.6176e-04, -6.2918e-04, -1.8267e-04, -1.2612e-04,  6.6914e-04,\n",
            "        -1.6555e-04, -2.2485e-04, -1.0663e-04,  1.4318e-03, -3.0091e-05,\n",
            "        -5.8471e-04, -1.2973e-04,  2.3615e-04,  1.0421e-03, -7.3463e-05,\n",
            "        -3.0775e-04,  2.0985e-04,  6.6654e-04,  1.2598e-04, -2.9014e-04,\n",
            "        -5.4357e-04,  2.0376e-04, -2.9945e-04,  9.3714e-04,  4.0065e-04,\n",
            "        -4.2670e-04, -1.8061e-04,  9.2767e-05,  7.6308e-04,  6.3945e-05,\n",
            "        -7.9684e-04,  2.6775e-04, -1.1318e-03, -1.4821e-04,  3.7262e-04,\n",
            "        -5.7358e-04,  1.6641e-05,  3.3901e-04,  1.2595e-04, -8.3012e-05,\n",
            "        -1.4248e-05,  3.5497e-04, -1.5414e-04,  9.0743e-05,  3.0015e-04,\n",
            "        -8.8445e-04,  3.3742e-04, -1.9065e-04,  6.3832e-05, -1.5131e-04,\n",
            "         1.9476e-04,  6.8467e-04, -4.4536e-04,  2.5361e-04, -1.1949e-05,\n",
            "        -1.1345e-03, -2.1369e-04, -4.6069e-04, -4.2104e-04, -8.1449e-04,\n",
            "        -3.5498e-05,  1.9641e-04, -1.7513e-04,  1.2595e-03, -3.7850e-04,\n",
            "        -6.3854e-04,  9.4450e-05,  6.6985e-04, -2.9235e-04, -1.8893e-04,\n",
            "         2.0157e-04, -2.9841e-06, -4.3415e-04, -1.0682e-03,  5.4572e-04,\n",
            "         4.7144e-04,  4.3866e-04, -1.3591e-03,  6.6831e-04,  3.4544e-04,\n",
            "        -1.0700e-04,  8.2332e-04,  1.2567e-03, -3.9220e-05,  1.0092e-03,\n",
            "         4.6212e-04, -1.2438e-03, -6.1381e-04, -3.3237e-04, -6.0610e-04,\n",
            "        -4.2674e-04,  3.2941e-05, -2.7100e-04,  6.6299e-04, -3.8209e-04,\n",
            "         1.8260e-04, -5.8047e-04, -1.7232e-04,  2.0178e-04, -3.0068e-04,\n",
            "         7.5405e-05,  4.1433e-04,  8.5384e-04, -1.6894e-04, -5.8503e-04,\n",
            "         1.7920e-04, -1.0118e-03,  2.3458e-05, -3.3560e-05,  5.5323e-04,\n",
            "         3.4191e-04, -7.4824e-04,  3.8715e-05,  5.9857e-04,  4.3401e-04,\n",
            "        -1.0908e-04, -2.8028e-04, -7.4774e-04,  2.6435e-04,  4.6033e-04,\n",
            "         5.7187e-04,  6.8361e-04, -8.7736e-05,  5.8392e-04,  1.8968e-04,\n",
            "         1.6576e-04, -1.5293e-05, -3.2665e-04,  5.8554e-04,  7.5004e-05,\n",
            "        -4.3496e-04, -3.8144e-06, -4.1123e-05,  1.6869e-04, -6.2772e-04,\n",
            "         2.1257e-04,  6.1087e-04, -3.2987e-04,  5.7862e-04,  1.0524e-04,\n",
            "        -1.0454e-04, -2.9564e-04, -3.4998e-04,  4.3482e-06, -6.7681e-05,\n",
            "         4.3880e-04, -1.4859e-04, -4.1878e-04,  7.3507e-05, -1.1876e-03,\n",
            "         2.3725e-04,  6.2754e-05, -1.5389e-04,  6.3828e-05, -4.5233e-04,\n",
            "        -1.9953e-04,  2.4545e-04,  7.7466e-04, -9.9764e-04, -8.0699e-04,\n",
            "        -6.4041e-04, -8.6652e-04, -1.3968e-04, -7.2911e-04,  2.1492e-04,\n",
            "         2.1795e-05,  1.1120e-04, -5.1749e-04, -4.3796e-04,  1.3042e-03,\n",
            "        -2.3355e-04,  9.0626e-05, -2.0546e-04, -1.0210e-03, -8.3168e-04,\n",
            "         1.1153e-03, -5.1224e-04,  7.9030e-04,  2.1149e-04, -3.7212e-04,\n",
            "         2.5750e-04, -2.1894e-04, -9.9442e-04, -1.5975e-04,  5.8756e-04,\n",
            "         4.8495e-05, -3.7637e-04, -2.8351e-04, -1.7679e-04, -9.6799e-05,\n",
            "         4.4099e-04,  3.1015e-04,  2.2134e-04,  8.5202e-04,  7.8865e-04,\n",
            "        -2.4061e-04, -3.0237e-04,  2.1538e-04, -7.7629e-05, -9.5232e-05,\n",
            "         2.0027e-04, -2.8071e-04,  2.6405e-04,  3.4764e-05,  5.9576e-04,\n",
            "        -4.0750e-04, -3.0353e-04,  3.1936e-04,  2.1731e-04, -9.3533e-04,\n",
            "        -4.1721e-04,  2.3818e-04, -8.9007e-04,  3.4876e-04, -1.3312e-03,\n",
            "        -1.5528e-04,  5.0343e-04,  3.2672e-04, -8.6328e-05, -2.5866e-05,\n",
            "         9.1675e-04,  5.7257e-04,  3.6287e-04, -6.7907e-04, -4.3642e-05,\n",
            "        -5.7345e-04, -3.5335e-04, -3.7395e-04,  3.8388e-05, -2.5506e-04,\n",
            "        -1.6132e-04, -3.0909e-04,  1.9549e-04], device='cuda:0')\n",
            "ITEM 15 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male', 'male', 'hat', 'hat']\n",
            "y_hat_labels_str = ['hat', 'male', 'male']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male', 'male', 'hat', 'hat']\n",
            "y_labels_int_v2 = tensor([89, 89, 70, 70], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.5769, 0.4375, 0.5962, 0.5481],\n",
            "        [0.7163, 0.5817, 0.2404, 0.5048],\n",
            "        [0.7115, 0.2139, 0.1562, 0.0913],\n",
            "        [0.7308, 0.3726, 0.1106, 0.0865]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'male', 'hat', 'hat']\n",
            "y_hat_bboxes_v2 = tensor([[0.5807, 0.5049, 0.5899, 0.6696],\n",
            "        [0.7165, 0.5852, 0.2548, 0.5134],\n",
            "        [0.7120, 0.2140, 0.1490, 0.0854],\n",
            "        [0.7120, 0.2140, 0.1490, 0.0854]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0041, 0.0209, 0.0037,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0037, 0.0271, 0.0033,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0071, 0.8002, 0.0102,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0071, 0.8002, 0.0102,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0', grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 8.47037410736084 = 2.9214694499969482 + 5.5489044189453125\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([-2.3895e-04, -2.4521e-04, -1.8916e-05,  1.3068e-04, -1.1028e-04,\n",
            "         1.3226e-04,  2.2171e-04,  3.8935e-05,  8.7138e-05,  1.7695e-04,\n",
            "         9.6223e-05,  1.6896e-04,  6.0050e-05,  8.0816e-05, -1.1359e-05,\n",
            "        -1.4745e-04, -6.2211e-05, -1.6375e-04,  1.5781e-04,  1.0288e-04,\n",
            "        -3.3411e-05,  3.4602e-04, -3.1990e-04, -3.6051e-04,  9.0367e-05,\n",
            "        -1.2416e-04, -2.7547e-04, -4.3031e-04, -1.5184e-05,  3.0356e-04,\n",
            "        -2.5907e-04,  2.4397e-04,  4.1365e-04,  1.1685e-04,  2.4079e-04,\n",
            "         3.2887e-04, -8.9508e-05, -3.0979e-04, -1.1383e-04, -2.2725e-04,\n",
            "        -1.5913e-04, -1.8336e-04,  9.5502e-05, -4.8580e-04,  1.7021e-05,\n",
            "        -3.1136e-04,  1.6071e-04, -3.6145e-04, -4.7495e-05, -8.0866e-06,\n",
            "        -8.7187e-05, -2.0619e-04, -3.6302e-04, -9.3625e-05, -3.3073e-04,\n",
            "         1.0885e-04, -4.1713e-05,  2.7959e-04,  3.5589e-04, -3.0179e-04,\n",
            "        -3.5631e-05, -2.2207e-04,  7.1336e-04, -3.7068e-04,  9.0106e-05,\n",
            "         2.1094e-04, -9.9787e-05, -8.6967e-05,  1.1089e-04,  2.2890e-05,\n",
            "         6.0826e-05, -6.4942e-05,  4.3516e-04,  2.7329e-04, -4.4567e-05,\n",
            "        -4.1591e-04,  3.4864e-04,  2.0346e-05,  1.2017e-04, -1.1714e-04,\n",
            "        -1.1057e-06, -8.7325e-05,  5.8524e-04,  1.9294e-04, -1.6982e-04,\n",
            "         1.1890e-04, -1.1795e-04, -2.2281e-04,  1.2619e-04,  3.0616e-04,\n",
            "         5.8331e-04,  8.5985e-05, -2.4596e-04,  1.9549e-04,  2.4856e-04,\n",
            "        -2.8079e-04, -1.4749e-04,  5.0807e-04,  4.4881e-04, -1.2985e-04,\n",
            "        -3.0852e-04,  1.6532e-04, -1.3960e-04,  1.7250e-04,  4.0130e-04,\n",
            "         8.1636e-05,  2.5839e-05, -3.4195e-04, -1.2616e-04, -1.4823e-04,\n",
            "         9.1497e-05,  1.9270e-04, -7.8286e-05, -5.1265e-04, -8.6248e-05,\n",
            "         2.9371e-05, -3.8878e-04,  3.3965e-04,  1.9105e-04, -2.2826e-04,\n",
            "         2.6601e-04, -1.8593e-04, -1.6382e-04, -4.4433e-04,  3.0357e-04,\n",
            "        -2.5400e-04, -4.2877e-04, -5.5732e-05,  4.3287e-04, -1.0417e-04,\n",
            "         4.6106e-05,  2.9578e-04,  1.0763e-04, -2.6470e-04,  1.0755e-03,\n",
            "         6.5174e-04, -2.8168e-04,  1.1330e-04,  6.9114e-05,  1.4151e-04,\n",
            "         3.4813e-05, -2.4550e-04,  1.1482e-04,  1.6150e-04,  1.2706e-04,\n",
            "         1.8684e-04,  4.0904e-04, -2.0006e-04, -2.1922e-04, -3.6766e-04,\n",
            "        -3.5168e-04,  1.1378e-04,  1.6775e-05, -4.4253e-06, -6.8735e-05,\n",
            "         2.4122e-04,  4.3367e-05, -4.7971e-04,  3.2251e-04, -2.5620e-04,\n",
            "         8.4518e-06, -1.9496e-04, -5.4583e-05, -1.8629e-04,  1.5323e-05,\n",
            "         1.1063e-04, -1.8225e-04,  1.5567e-04, -3.2511e-04, -1.8217e-04,\n",
            "        -9.1604e-05,  6.4202e-05, -2.2211e-04,  3.4347e-04, -1.8878e-04,\n",
            "         2.4676e-04, -7.0533e-05, -4.5084e-04, -1.4119e-04,  6.2973e-05,\n",
            "         3.0783e-05, -3.4941e-06,  3.8348e-05, -8.3947e-05, -2.2687e-05,\n",
            "        -3.2923e-06, -5.4464e-05, -1.0812e-04,  1.1023e-04, -2.5075e-04,\n",
            "         4.3272e-05, -3.3282e-04,  4.0440e-04, -8.7143e-05, -3.1808e-04,\n",
            "        -2.9253e-04, -2.4571e-04, -1.8874e-05,  2.1617e-04,  4.0339e-04,\n",
            "         1.9022e-04,  8.5908e-05, -3.0033e-05, -8.4860e-05,  1.1947e-04,\n",
            "         2.2156e-04, -1.3131e-04,  1.8124e-04, -1.2955e-04, -5.5494e-05,\n",
            "        -1.4567e-04, -2.1480e-05, -1.8683e-04,  1.2939e-04, -3.2738e-04,\n",
            "         3.2195e-04, -7.5721e-05, -3.0075e-04, -2.1227e-05,  6.8746e-05,\n",
            "        -2.0628e-05, -1.5867e-05, -5.0877e-05,  3.0058e-04,  3.9880e-04,\n",
            "        -1.9534e-04,  5.8060e-04, -1.8644e-04,  2.5479e-05,  9.5567e-05,\n",
            "         1.7274e-04, -1.2636e-04, -3.9195e-05,  1.8031e-04,  2.4927e-04,\n",
            "        -9.3388e-05,  6.9239e-05, -3.1498e-04, -6.2948e-05,  5.3486e-05,\n",
            "        -6.4079e-06, -7.6797e-05, -1.2350e-04, -8.1884e-05,  1.1735e-04,\n",
            "         6.1386e-05,  1.4259e-04, -9.3762e-05,  3.2533e-04,  5.3196e-05,\n",
            "         7.0406e-04, -5.0779e-04,  3.8364e-04,  7.4323e-05, -5.7065e-04,\n",
            "         2.3047e-04,  1.3027e-04, -2.9399e-04,  1.6511e-04,  4.0489e-04,\n",
            "         3.2887e-04, -3.5282e-05,  1.5003e-04, -5.0288e-05,  2.0618e-04,\n",
            "        -1.6900e-04, -5.9728e-04,  1.4867e-04, -1.8614e-04,  1.0991e-05,\n",
            "         1.1962e-04,  5.5343e-04, -1.1448e-04,  7.0511e-05,  4.7332e-05,\n",
            "         1.2477e-04, -2.2322e-04,  1.6873e-04,  9.1720e-05,  7.1956e-05,\n",
            "         4.4842e-04,  1.4889e-04,  6.1148e-05, -5.6045e-05, -1.0129e-05,\n",
            "         1.6691e-04,  3.0595e-04,  2.0748e-04, -4.3818e-04,  5.6330e-04,\n",
            "        -1.0583e-04, -2.2630e-04, -2.3127e-04,  1.9276e-05, -4.0613e-04,\n",
            "         2.1722e-04, -2.8598e-04,  5.1794e-04,  2.4625e-04,  1.3591e-04,\n",
            "        -7.5984e-05,  1.4083e-04, -2.3987e-04, -3.4676e-04, -1.5787e-04,\n",
            "        -2.8228e-04,  1.6596e-04, -5.3869e-04,  1.0283e-04,  5.8515e-05,\n",
            "        -8.0419e-05, -1.8049e-04,  1.0536e-04, -3.4656e-05,  3.0775e-04,\n",
            "        -2.2397e-05,  4.2106e-05, -2.9899e-04, -2.1712e-04, -2.5241e-04,\n",
            "        -7.9391e-05,  1.6492e-04, -3.2720e-04, -2.3502e-04,  6.4716e-05,\n",
            "         1.6630e-04,  8.7891e-05,  9.1372e-05,  1.5379e-04, -3.1046e-04,\n",
            "         6.8203e-05,  4.1024e-05, -2.2454e-04, -1.0704e-04,  2.8302e-04,\n",
            "         1.1445e-04, -3.0135e-04,  3.1844e-04, -4.1826e-04,  3.5709e-06,\n",
            "        -1.5745e-04, -1.2500e-04, -3.1382e-04, -1.1553e-04,  7.5312e-05,\n",
            "        -9.5615e-05,  1.1801e-04, -1.6104e-04,  1.7643e-04, -5.4554e-05,\n",
            "        -1.2456e-04, -3.5364e-04,  1.8666e-04, -1.9127e-04,  3.8446e-04,\n",
            "        -1.1629e-04, -8.7638e-05,  1.9410e-04, -1.8562e-04,  3.0733e-04,\n",
            "        -3.2294e-04, -2.5594e-04,  2.7319e-05, -2.9508e-04, -1.7024e-04,\n",
            "         1.7535e-04,  1.7973e-04, -3.4906e-04,  3.7034e-04,  1.2845e-04,\n",
            "         2.0045e-04, -9.3185e-06,  3.5340e-05,  8.9926e-05,  1.5895e-05,\n",
            "        -3.1036e-04,  2.8399e-04,  3.5954e-05, -9.7543e-05, -2.5286e-04,\n",
            "         1.2171e-04, -1.1206e-04, -6.2252e-05, -6.5455e-05,  2.3538e-04,\n",
            "         1.9476e-04, -1.9898e-05, -6.5142e-05,  1.1502e-04,  4.3531e-04,\n",
            "        -3.5264e-05,  3.6824e-05,  1.7481e-04,  3.2081e-04, -7.7546e-05,\n",
            "        -5.0761e-04, -6.3586e-05,  2.4699e-04,  1.1526e-04, -5.4916e-06,\n",
            "         1.1485e-04, -1.2669e-04, -2.1395e-04,  1.0261e-04, -6.5326e-05,\n",
            "        -1.6215e-04, -1.7098e-04,  2.4391e-04,  3.0649e-04,  5.6157e-05,\n",
            "         2.1834e-04,  1.9839e-04, -4.8277e-04,  1.4962e-04, -1.0746e-04,\n",
            "        -2.5794e-05, -2.1698e-04, -7.0403e-05,  4.4379e-04,  2.9920e-04,\n",
            "         6.5528e-05, -4.1807e-05,  9.2760e-05, -2.1033e-05,  1.8838e-05,\n",
            "        -1.4871e-04, -3.3698e-06, -2.4601e-04, -2.7100e-04,  1.7305e-05,\n",
            "        -1.0756e-04, -4.5420e-05,  1.3473e-04,  3.2615e-04, -3.6997e-05,\n",
            "        -6.7117e-05,  6.8194e-04, -3.8308e-05, -2.3098e-04, -1.6807e-04,\n",
            "         4.2987e-04,  3.1058e-04,  7.9907e-05,  1.6480e-05, -2.0688e-04,\n",
            "        -1.4036e-04, -1.8922e-04, -1.6305e-04,  4.2359e-06, -1.1270e-04,\n",
            "        -8.7730e-05, -6.8334e-06, -4.8139e-05, -2.1446e-04,  2.4961e-04,\n",
            "        -1.6435e-04, -5.7586e-05, -9.7445e-05, -2.3425e-04,  8.6520e-05,\n",
            "         3.1667e-04, -2.9434e-04, -2.8889e-04, -3.5687e-04,  4.7241e-05,\n",
            "         9.9701e-05,  1.8845e-04,  2.5271e-04, -2.8143e-04,  3.0693e-04,\n",
            "        -7.3484e-05,  1.5162e-04,  3.4074e-04, -5.1949e-04, -2.0700e-04,\n",
            "         1.2007e-04,  4.3052e-04, -1.1826e-04, -3.3674e-05,  1.6086e-04,\n",
            "        -9.4339e-05, -1.2694e-04, -4.3412e-04,  2.0884e-04,  1.2012e-04,\n",
            "         3.5210e-04, -3.7001e-04, -7.4177e-05,  7.3459e-05,  8.3307e-05,\n",
            "         6.7770e-04, -1.9041e-05,  1.2680e-04, -6.8021e-05,  2.9568e-05,\n",
            "         3.0090e-04, -3.0675e-04,  1.2582e-04, -2.3030e-04, -1.6873e-04,\n",
            "         1.2463e-04, -4.9883e-04,  1.6323e-04, -4.4913e-05,  3.5584e-05,\n",
            "         7.1645e-05, -1.7832e-04,  2.3280e-04,  8.5065e-05, -1.5658e-04,\n",
            "        -1.1494e-04,  1.5757e-04, -2.2813e-04, -2.7305e-04, -3.7484e-04,\n",
            "         2.2275e-04, -2.0748e-04,  1.9907e-04,  1.2694e-04, -2.7376e-04,\n",
            "         2.9210e-04, -3.8567e-04, -2.4663e-05, -5.0181e-04, -1.5375e-04,\n",
            "         2.0602e-04,  3.2643e-04, -3.9895e-06,  1.0996e-04, -1.0153e-04,\n",
            "         5.0839e-05,  6.9896e-05,  2.5128e-04,  4.7022e-04,  1.4376e-04,\n",
            "         1.8853e-04, -1.8436e-04,  7.0403e-05, -5.4427e-05,  2.4918e-04,\n",
            "        -2.2378e-04,  9.1052e-05,  3.2720e-04,  3.7727e-05,  2.3843e-05,\n",
            "        -4.1376e-05, -8.4764e-05, -1.7363e-04, -1.0853e-04, -2.5648e-04,\n",
            "        -3.4444e-04, -1.4609e-04,  2.5119e-04,  2.6145e-04, -1.1894e-04,\n",
            "        -2.7345e-04, -1.7577e-04, -5.7130e-06,  3.2767e-04,  3.2563e-05,\n",
            "         1.2213e-04, -6.1889e-05,  3.5068e-06, -1.2813e-04, -1.9933e-05,\n",
            "         1.9478e-05,  2.9172e-04,  4.5967e-06,  8.5771e-05, -6.7109e-05,\n",
            "        -2.1763e-04,  3.6416e-04, -9.6699e-05, -1.3006e-05, -2.7715e-04,\n",
            "         3.1311e-04,  9.1620e-05,  3.4804e-04,  4.1316e-05,  3.4777e-04,\n",
            "         1.5579e-04,  2.5831e-05,  1.2357e-04,  1.6180e-04,  1.1123e-04,\n",
            "        -9.2546e-05, -4.3139e-04,  2.3486e-04,  3.7500e-04, -8.4394e-05,\n",
            "        -1.9684e-04, -6.1412e-04, -3.4066e-05,  1.7291e-04, -6.9985e-07,\n",
            "        -1.6947e-04, -2.9106e-04, -1.4796e-04,  1.4064e-04, -3.8917e-04,\n",
            "        -2.1279e-04, -3.6905e-04, -3.0588e-04,  3.6078e-04, -3.5841e-04,\n",
            "         1.1913e-04,  3.8911e-04,  1.0692e-05, -4.4611e-04,  4.6135e-05,\n",
            "         2.0466e-05, -4.6927e-04,  2.4353e-04, -9.9083e-05,  1.8293e-05,\n",
            "        -2.7142e-04, -3.6850e-04, -3.3124e-04, -2.4644e-04, -1.2212e-05,\n",
            "        -1.3610e-04,  2.1588e-04,  2.7124e-04,  3.9384e-05,  1.6671e-05,\n",
            "        -1.7791e-04, -2.5219e-04,  2.8572e-04,  5.6336e-05,  2.4917e-04,\n",
            "         2.5447e-04,  3.0110e-04, -6.3614e-05, -1.3098e-05,  3.2017e-04,\n",
            "        -2.5368e-04, -1.4214e-04, -1.3520e-04,  1.4749e-04, -3.0263e-04,\n",
            "        -5.1140e-05, -1.4723e-04,  2.2225e-04,  2.9747e-05,  2.6164e-04,\n",
            "        -8.1444e-05, -3.0484e-05,  5.5976e-04,  4.0707e-04,  3.2538e-04,\n",
            "        -8.8774e-05,  1.6924e-04,  2.2114e-05, -1.0230e-04, -1.4802e-04,\n",
            "        -3.4208e-04,  4.8704e-05,  5.6268e-04, -1.8799e-04,  2.7675e-04,\n",
            "        -2.8488e-04, -2.9528e-04,  2.3686e-05, -4.8576e-05, -4.1104e-04,\n",
            "         7.9443e-05,  1.3866e-04, -3.0446e-04,  1.7870e-04, -1.5975e-04,\n",
            "        -6.5496e-05,  2.9381e-04,  4.7190e-05, -4.6815e-05,  1.9961e-04,\n",
            "         3.6929e-05, -5.0404e-05, -1.4945e-05,  8.8788e-05,  4.9696e-04,\n",
            "         3.3114e-05, -8.9425e-05, -4.7359e-05, -2.7219e-05,  1.4369e-04,\n",
            "        -1.5148e-04, -2.1783e-04,  3.4126e-04, -3.0104e-04,  7.3197e-04,\n",
            "        -2.1305e-04, -4.2134e-04,  1.8546e-04,  3.6745e-04,  1.5945e-04,\n",
            "         1.0432e-04,  7.3882e-05, -1.3215e-04,  2.4440e-04, -5.3119e-04,\n",
            "         1.3806e-04, -1.8943e-04,  1.4628e-04,  1.4370e-05,  1.8713e-05,\n",
            "         2.1688e-04, -4.6862e-04,  2.4940e-05,  3.0837e-05,  2.3859e-04,\n",
            "        -6.6444e-04, -2.2904e-04,  6.4100e-05, -2.0011e-04, -8.5155e-05,\n",
            "        -2.8854e-04, -1.5481e-04,  2.6587e-04, -8.0332e-05, -2.9956e-04,\n",
            "        -5.4366e-05, -4.6712e-04,  3.9641e-04,  3.3920e-05, -3.3590e-04,\n",
            "        -2.7168e-04, -1.5620e-05,  4.8563e-05, -1.9737e-04, -4.2794e-04,\n",
            "         2.3522e-05,  2.9659e-04, -4.8780e-04, -2.1529e-04,  2.1869e-04,\n",
            "         1.8005e-05, -6.7177e-04,  4.4324e-04,  1.6879e-04, -2.5202e-04,\n",
            "         5.5328e-05, -1.4602e-04, -3.0095e-04, -1.1045e-04, -2.5212e-04,\n",
            "        -2.7787e-04,  5.0706e-04,  5.9701e-04, -1.0262e-04,  4.4132e-04,\n",
            "         7.9437e-05, -2.2038e-04,  3.0346e-04, -4.7775e-06, -5.7541e-05,\n",
            "         1.2059e-04,  2.4102e-04,  3.1242e-04, -1.4015e-04,  2.0364e-04,\n",
            "         1.2230e-04, -1.7597e-04, -3.3847e-05, -4.4926e-05, -1.1541e-04,\n",
            "         2.9450e-04,  1.5324e-05, -5.0943e-05], device='cuda:0')\n",
            "ITEM 16 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male']\n",
            "y_hat_labels_str = ['male', 'male']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male']\n",
            "y_labels_int_v2 = tensor([89], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.7067, 0.4423, 0.3510, 0.8774]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male']\n",
            "y_hat_bboxes_v2 = tensor([[0.7048, 0.4696, 0.3838, 0.9393]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0071, 0.6247, 0.0118, 0.0072, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 6.963777542114258 = 1.4151134490966797 + 5.548664093017578\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 8.8349e-03, -2.0901e-03,  4.0562e-03,  2.6356e-03, -8.6386e-03,\n",
            "         2.1796e-03, -5.2886e-03,  3.9704e-04, -3.2580e-03, -5.1778e-03,\n",
            "        -1.6134e-03, -1.0208e-03, -2.9902e-03,  4.0335e-03,  4.2195e-03,\n",
            "        -7.0467e-03,  2.0948e-03,  5.6285e-04, -3.8633e-03, -7.9044e-04,\n",
            "         1.0306e-03,  2.3718e-03,  4.5882e-03, -2.0229e-03,  6.8500e-04,\n",
            "         6.0934e-04,  2.9886e-03, -1.2157e-03, -5.0837e-05, -4.4580e-03,\n",
            "        -2.8802e-03,  1.7829e-03,  2.3265e-03, -8.1848e-03,  3.7988e-03,\n",
            "        -4.9967e-04, -1.8709e-03, -5.5752e-03,  5.4352e-03, -6.5809e-04,\n",
            "        -1.3670e-03, -3.7364e-03,  2.0594e-03,  1.3752e-03,  9.8792e-04,\n",
            "         5.7079e-03, -4.4013e-03,  3.4477e-03,  3.0373e-03, -9.3982e-04,\n",
            "        -5.0541e-03,  2.1462e-03, -1.0735e-03,  3.9916e-03,  1.6320e-04,\n",
            "         1.9013e-03, -1.0502e-03, -3.7273e-03,  2.3804e-03, -4.4051e-03,\n",
            "        -3.4476e-03, -1.9329e-03, -5.3184e-03, -1.6875e-03, -3.4182e-03,\n",
            "        -5.4283e-03, -4.8429e-03,  1.9170e-03,  1.1319e-03,  1.7424e-03,\n",
            "        -2.8382e-04, -3.8799e-03,  8.3578e-03,  1.8583e-03,  3.1999e-03,\n",
            "        -3.3744e-03, -3.8083e-03,  4.3093e-03,  7.2607e-03,  4.2111e-03,\n",
            "        -3.8743e-03,  3.2298e-03, -6.4677e-03,  3.6996e-04,  6.6565e-03,\n",
            "        -3.8205e-03, -5.3224e-04, -2.1140e-03,  5.6382e-03,  5.0320e-03,\n",
            "        -6.4723e-03,  7.5306e-03,  1.1483e-03, -4.1502e-03,  6.1925e-03,\n",
            "         3.3092e-03, -1.7172e-03, -8.4622e-04,  2.3406e-03, -6.2643e-03,\n",
            "        -3.8499e-03,  2.1389e-03, -2.8235e-03, -5.0635e-03, -3.9031e-03,\n",
            "        -3.1631e-03, -3.9927e-03, -5.4550e-03,  1.8555e-03, -1.4744e-03,\n",
            "        -6.2475e-04, -1.4729e-03, -4.4711e-04, -3.0821e-03, -1.8965e-04,\n",
            "        -4.0137e-03,  3.1007e-03,  5.2339e-03,  9.3565e-04,  1.5294e-03,\n",
            "        -5.5945e-03,  1.5107e-03, -1.3463e-03,  6.2769e-04, -5.3981e-03,\n",
            "         2.0633e-03,  3.0702e-03,  3.1337e-03,  2.5978e-03, -4.2252e-03,\n",
            "         2.9565e-03, -2.4538e-03, -3.8785e-03,  3.2236e-03, -5.9159e-04,\n",
            "         3.5255e-03,  1.8465e-03, -2.1115e-03,  2.8965e-03,  3.3672e-03,\n",
            "        -8.6947e-05,  3.2960e-03, -2.4815e-03, -3.3939e-04, -6.5368e-03,\n",
            "         2.6765e-03,  8.8503e-04, -3.8434e-03,  3.3846e-03,  4.9829e-03,\n",
            "         1.0212e-03, -3.3367e-03, -8.1526e-04,  1.9501e-03, -3.4173e-03,\n",
            "         2.4163e-04,  2.3987e-04,  6.5926e-03,  2.0099e-03,  1.8267e-03,\n",
            "        -1.5629e-04, -3.6738e-04,  2.3506e-03,  1.1519e-03,  1.5617e-03,\n",
            "        -1.8329e-03,  2.1595e-03,  9.6116e-04,  2.9482e-03, -3.0760e-03,\n",
            "         1.0476e-03,  1.3526e-03,  4.4727e-03, -6.9939e-03, -4.1215e-03,\n",
            "         5.1893e-04,  4.8635e-03, -1.4611e-03,  1.6143e-03,  2.8088e-03,\n",
            "         2.6899e-03,  1.1119e-03, -7.5226e-04,  2.1344e-03,  3.2412e-03,\n",
            "        -2.1971e-03, -2.6847e-03, -2.0897e-03, -1.2988e-03,  3.4823e-03,\n",
            "        -4.3203e-04,  2.0368e-03,  5.4920e-03,  2.0494e-03, -6.6197e-03,\n",
            "         1.9379e-03,  1.7316e-03,  2.6191e-03,  3.5183e-03, -1.0083e-03,\n",
            "         4.6524e-03, -3.2209e-03,  3.0377e-04, -1.7676e-03, -5.0163e-03,\n",
            "        -2.3498e-03, -6.1633e-03, -2.7506e-03,  2.6300e-04, -1.3876e-03,\n",
            "        -3.4941e-05, -1.5022e-03, -1.0481e-03,  7.4133e-03, -3.5751e-03,\n",
            "        -2.6046e-03, -1.4056e-03, -1.0346e-03,  3.3884e-03,  2.9077e-03,\n",
            "        -2.4609e-05,  3.8831e-03, -1.3810e-03,  1.9199e-04,  5.6866e-03,\n",
            "         4.5435e-03,  6.0303e-03, -2.3891e-03, -1.8952e-05,  5.5863e-03,\n",
            "        -2.7233e-03,  2.2575e-03, -2.1235e-03,  4.0820e-03,  1.0374e-03,\n",
            "         3.5405e-04, -1.4303e-03,  4.8499e-03,  3.8967e-03,  6.5839e-04,\n",
            "         4.0351e-03,  2.7385e-03, -2.7656e-03, -4.3408e-03, -5.2573e-05,\n",
            "        -1.7980e-03, -2.8487e-03, -4.5191e-04,  6.2363e-04,  4.2189e-03,\n",
            "         5.0667e-03,  5.8055e-03,  7.2521e-04, -6.2687e-04,  6.4147e-03,\n",
            "        -4.0246e-03, -7.1241e-04,  1.6223e-03,  2.1979e-03, -1.5896e-03,\n",
            "         2.3754e-03,  7.0500e-04, -1.6320e-03, -2.2848e-03,  3.4451e-03,\n",
            "        -5.2261e-03, -1.2097e-03,  2.8428e-03,  5.2906e-03,  4.2083e-03,\n",
            "        -4.9806e-03, -1.0474e-03,  4.0152e-03, -2.9523e-04,  7.1133e-04,\n",
            "         9.3739e-04,  4.0721e-03, -1.7796e-04,  8.0047e-04,  7.5109e-04,\n",
            "         5.9999e-07,  8.6864e-03,  1.2801e-03, -1.5129e-03,  1.1981e-03,\n",
            "         1.3523e-04, -2.9834e-03, -1.6059e-03,  1.7836e-03,  3.8662e-03,\n",
            "        -2.1924e-03, -2.3743e-03, -4.7505e-04, -6.0163e-03,  3.7943e-04,\n",
            "        -3.7287e-03,  3.9479e-04, -1.1498e-03,  7.1136e-04, -1.8514e-03,\n",
            "        -3.6104e-03, -4.9913e-03,  2.3135e-03,  6.5942e-03,  2.1937e-03,\n",
            "        -3.1082e-03, -3.9372e-03, -1.5839e-03,  5.3386e-04, -1.9041e-03,\n",
            "         4.8380e-03,  5.2024e-03, -3.4986e-03,  1.5163e-03, -8.1927e-03,\n",
            "        -5.6294e-04, -9.5212e-03, -2.5604e-03, -4.3912e-03, -4.2107e-04,\n",
            "         5.6135e-03,  5.9430e-04,  2.5264e-03,  1.3727e-03,  2.0100e-03,\n",
            "        -2.8111e-03,  6.4536e-03, -6.9068e-03, -2.1407e-03, -5.7689e-03,\n",
            "        -3.0282e-03, -6.2626e-03,  1.3380e-03, -1.1409e-02,  3.1692e-03,\n",
            "         3.8607e-03,  2.3522e-03,  9.9656e-04, -3.7849e-04, -3.3449e-03,\n",
            "        -4.2364e-03, -6.0665e-03, -1.0761e-03,  2.7315e-03, -6.7265e-03,\n",
            "         2.7827e-04, -3.0761e-03,  7.3375e-03, -3.0072e-03,  1.1093e-03,\n",
            "        -2.0211e-03, -5.1146e-03,  3.7217e-03,  4.8582e-04, -2.9382e-03,\n",
            "         5.4682e-03,  2.2811e-03,  7.5676e-03,  3.4303e-03,  5.0353e-03,\n",
            "         7.7585e-03,  3.1861e-03,  3.3385e-03,  2.4149e-03, -4.0137e-03,\n",
            "         3.1578e-03,  4.0513e-04, -1.9131e-03,  6.4041e-04,  6.6480e-04,\n",
            "        -5.3871e-03,  2.8714e-03, -2.7432e-03, -1.2778e-03,  5.7835e-04,\n",
            "        -4.0962e-03,  4.5903e-03,  1.1215e-03,  3.8146e-03,  2.2461e-03,\n",
            "         1.5628e-03,  2.0232e-03,  1.6199e-03,  1.0883e-03, -1.3176e-03,\n",
            "        -4.8540e-03, -4.7730e-03, -3.1263e-03, -2.6074e-04,  5.1193e-03,\n",
            "        -3.8320e-03,  5.8852e-03,  1.1783e-03,  6.2220e-03, -7.1489e-04,\n",
            "         2.3864e-03, -1.2923e-03,  1.6305e-03,  2.3307e-03, -5.1169e-03,\n",
            "         1.2654e-03, -2.1855e-03, -8.6455e-04,  2.8793e-03, -1.6421e-03,\n",
            "         1.4052e-03, -1.7414e-03, -5.4385e-03,  2.1895e-03, -5.8589e-04,\n",
            "         9.1992e-03,  8.8490e-04, -4.6770e-04,  6.5249e-03, -4.4723e-03,\n",
            "         4.3010e-04,  1.0470e-03, -5.8668e-03,  4.9685e-03, -5.6075e-03,\n",
            "         1.6957e-03, -3.1648e-04,  6.8436e-03, -5.5191e-03, -2.8880e-04,\n",
            "         4.5437e-04,  4.1691e-03,  6.1580e-03,  4.7003e-03, -2.3830e-03,\n",
            "        -3.2269e-03, -9.1108e-04, -6.1874e-03, -2.6810e-03,  2.6593e-03,\n",
            "         1.5942e-04, -3.1562e-03, -2.6688e-03,  1.5019e-03, -2.4241e-03,\n",
            "        -8.0061e-03, -2.7281e-05,  3.2663e-03, -2.1793e-03, -2.8553e-03,\n",
            "         5.9997e-03, -4.4579e-03,  1.0586e-05,  1.8737e-03, -2.1415e-03,\n",
            "        -2.5540e-03, -2.3615e-03, -3.3700e-03, -8.6481e-04,  6.2474e-04,\n",
            "        -8.4462e-03,  2.9294e-03,  5.6500e-03, -2.6692e-03,  3.5744e-03,\n",
            "         1.9103e-03, -1.8198e-03,  1.2935e-03, -1.1234e-04, -3.0550e-03,\n",
            "         1.9025e-03, -2.9200e-03,  2.1999e-03, -2.6404e-03, -5.4844e-03,\n",
            "         8.3259e-04,  1.2756e-04, -9.1496e-04,  1.1383e-05, -2.1621e-03,\n",
            "        -4.6752e-03, -2.0933e-03, -3.9357e-03, -3.5652e-03,  5.1725e-04,\n",
            "         9.8833e-03,  2.5283e-03,  1.5083e-03, -2.7738e-03, -3.6365e-03,\n",
            "        -2.7542e-03,  2.8764e-04, -1.3917e-03,  3.7636e-03,  8.2849e-04,\n",
            "         1.8550e-03, -6.1972e-05, -3.4176e-03, -2.8382e-03,  1.5651e-03,\n",
            "         1.2138e-03,  8.7562e-03,  1.1340e-03,  3.1625e-03, -1.4013e-03,\n",
            "         6.2746e-04,  3.5923e-03, -5.0804e-03,  2.3319e-03,  6.2831e-03,\n",
            "        -1.6256e-03, -1.4087e-04,  4.0963e-04,  1.5859e-03,  2.8267e-04,\n",
            "         2.8020e-03,  2.6632e-03, -2.3392e-03,  7.5410e-04,  6.1297e-03,\n",
            "        -3.2645e-03,  5.1183e-04, -9.1756e-04, -2.1937e-03, -2.0052e-03,\n",
            "         9.4303e-04, -2.6585e-03,  3.0539e-03,  6.6574e-03,  8.2275e-03,\n",
            "        -4.7706e-03,  9.1203e-04, -9.0073e-05,  5.2235e-05, -2.7867e-03,\n",
            "         9.8638e-04, -4.7573e-03, -4.1507e-03,  4.2215e-03, -8.9175e-04,\n",
            "        -2.6318e-03,  1.5135e-03,  3.2520e-04, -3.0419e-03, -1.6347e-03,\n",
            "         6.2872e-03,  5.4503e-04, -3.1354e-04, -4.3546e-04, -2.1865e-03,\n",
            "         8.4456e-04,  1.2808e-03,  3.2369e-03,  5.0026e-03, -8.4445e-03,\n",
            "        -1.4402e-03, -7.1744e-03, -3.8543e-03, -8.4058e-03, -1.4724e-03,\n",
            "         5.3067e-04,  1.5080e-03,  3.2341e-03,  1.8686e-03,  2.6070e-03,\n",
            "         3.1324e-03, -4.8359e-03,  6.1621e-03,  5.8083e-03,  3.5076e-03,\n",
            "        -3.6222e-03, -1.7271e-03, -3.8951e-03, -2.8545e-03, -4.6252e-03,\n",
            "         8.4514e-04,  7.3210e-04,  1.5422e-03, -1.1201e-04,  1.3810e-03,\n",
            "        -1.5729e-03, -1.1123e-03,  2.9929e-03,  5.3235e-04,  3.8102e-03,\n",
            "         2.1694e-03,  1.3016e-03, -1.2663e-03, -1.8423e-03,  1.3301e-03,\n",
            "         3.7143e-03, -1.1033e-03,  4.5165e-04, -4.1180e-03, -1.1534e-03,\n",
            "         2.4001e-04, -2.0061e-03, -2.9907e-03,  2.9681e-04, -7.9598e-03,\n",
            "         1.9323e-03,  2.0735e-03, -3.4920e-03, -3.2760e-03,  6.0662e-03,\n",
            "         5.2457e-03, -4.0271e-05, -5.6274e-03, -3.5550e-03, -1.3110e-03,\n",
            "        -3.3456e-03,  1.1563e-03,  1.9865e-03, -2.6374e-03,  6.2901e-03,\n",
            "         4.7461e-03, -2.5437e-03, -1.1621e-03, -1.6275e-03, -2.9293e-03,\n",
            "         1.9021e-03,  9.2313e-03, -8.5756e-04,  2.1240e-03, -8.4453e-04,\n",
            "        -5.5093e-04,  1.9497e-03,  5.6510e-04, -1.8322e-03, -1.4210e-03,\n",
            "         2.1576e-03,  2.6384e-03,  2.5517e-03,  3.6641e-03, -2.5051e-03,\n",
            "        -9.4212e-04, -1.1513e-02,  5.2787e-03, -6.3298e-04,  2.7574e-03,\n",
            "        -4.4524e-04,  4.4431e-03,  1.5395e-03,  2.1524e-03, -6.0706e-04,\n",
            "         4.4220e-03, -1.6147e-03, -8.5251e-04,  7.9789e-04,  4.7898e-03,\n",
            "         1.1397e-04, -1.0144e-03, -4.2689e-04,  5.4522e-03, -3.9101e-03,\n",
            "         1.8638e-03, -7.1566e-04, -2.0437e-03,  1.5433e-03,  7.8680e-03,\n",
            "         3.3280e-03, -1.1591e-03,  1.4088e-03,  2.3433e-03, -3.2874e-03,\n",
            "        -5.5341e-04, -1.5903e-03, -5.8980e-04, -2.6896e-03, -3.5616e-03,\n",
            "         3.9524e-04,  1.0703e-04, -2.4725e-03,  2.4135e-03, -1.8179e-03,\n",
            "        -5.5285e-03,  3.2834e-03, -1.3597e-03, -3.0264e-03, -3.3953e-03,\n",
            "         3.5616e-03,  3.6847e-03, -4.0250e-03, -2.4179e-03, -2.6138e-03,\n",
            "         8.4155e-03, -8.5545e-04, -5.8355e-03,  2.3459e-03,  2.0161e-03,\n",
            "        -2.5599e-03,  3.8502e-04, -6.3337e-03,  2.9069e-03,  1.1073e-03,\n",
            "         2.6151e-05,  1.6051e-03, -1.0533e-04,  1.3160e-03,  1.6539e-03,\n",
            "         2.0626e-03, -3.6894e-04, -2.0107e-03, -5.8277e-03,  2.4661e-04,\n",
            "         1.3208e-03,  4.5116e-03,  7.3664e-04, -4.2282e-03, -5.0581e-04,\n",
            "        -9.1167e-04, -2.8343e-03,  5.4143e-03, -8.3112e-04,  8.2110e-04,\n",
            "         2.0628e-03,  5.0169e-04, -6.0022e-03, -2.3106e-04, -7.0645e-03,\n",
            "         5.5114e-03,  3.9834e-03,  9.5137e-04, -1.3707e-03,  1.0643e-03,\n",
            "         5.0620e-03, -1.9237e-03, -3.5846e-03,  1.4142e-03, -3.1566e-03,\n",
            "        -6.5730e-04, -5.4898e-03, -8.7262e-05, -1.5403e-03, -1.6939e-03,\n",
            "         9.9622e-04,  5.5661e-03,  6.4712e-03,  1.7165e-03, -1.5636e-03,\n",
            "        -2.2237e-03,  6.7793e-03, -1.2469e-03, -3.3971e-03, -9.9952e-04,\n",
            "        -4.8721e-03,  4.8799e-03, -2.2103e-03,  5.3352e-03, -2.1949e-03,\n",
            "         7.0751e-03, -5.6277e-03, -2.0904e-04,  3.9820e-03,  2.2989e-03,\n",
            "         1.6953e-03,  2.4764e-04, -6.0888e-04, -3.1896e-04, -1.8606e-04,\n",
            "         6.9095e-03,  8.5051e-04,  1.2853e-03,  4.3299e-03,  1.3341e-03,\n",
            "         2.3249e-04,  3.9185e-04, -1.8006e-03, -3.9694e-03, -2.6864e-03,\n",
            "         2.2223e-03,  2.8061e-03, -9.6583e-04], device='cuda:0')\n",
            "ITEM 17 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male', 'boat', 'barrel', 'hat', 'tie', 'box']\n",
            "y_hat_labels_str = ['male', 'barrel', 'hat', 'boat']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male', 'boat', 'barrel', 'hat']\n",
            "y_labels_int_v2 = tensor([89, 15,  5, 70], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4700, 0.6046, 0.4183, 0.6418],\n",
            "        [0.1514, 0.5457, 0.2500, 0.2452],\n",
            "        [0.7897, 0.8053, 0.2380, 0.1803],\n",
            "        [0.5589, 0.3474, 0.1755, 0.1274]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'boat', 'barrel', 'hat']\n",
            "y_hat_bboxes_v2 = tensor([[0.4834, 0.6040, 0.4389, 0.6437],\n",
            "        [0.1502, 0.5377, 0.2521, 0.2391],\n",
            "        [0.7876, 0.8061, 0.2377, 0.1807],\n",
            "        [0.5602, 0.3450, 0.1655, 0.1235]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0044, 0.0167, 0.0025,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0040, 0.0041, 0.0024,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0027, 0.0016, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0046, 0.0232, 0.0026,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0', grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.430166244506836 = 0.05274074897170067 + 5.377425670623779\n",
            "MODEL PARAMETER GRADIENT CHECK: tensor([ 7.4214e-04, -3.4226e-05,  4.5352e-04,  1.2827e-04, -2.7501e-04,\n",
            "        -6.5779e-04, -3.8814e-04, -1.4208e-04,  1.9172e-04, -9.2151e-05,\n",
            "         2.5862e-04,  2.6101e-04,  1.4447e-04, -9.0013e-05,  2.6530e-04,\n",
            "         1.6468e-04, -2.3439e-04, -4.8434e-04, -4.8243e-05, -6.7378e-04,\n",
            "         2.0503e-04, -3.3657e-04,  4.1596e-04,  1.8673e-04, -3.1762e-04,\n",
            "         2.9925e-04,  7.3340e-05,  8.5812e-04, -3.6324e-04,  2.2428e-04,\n",
            "         5.2817e-05,  8.7972e-05, -5.4023e-04, -7.4248e-05, -2.3848e-05,\n",
            "         2.2369e-04,  3.0545e-04,  3.1426e-04,  3.7008e-04,  3.0520e-04,\n",
            "         2.2652e-04,  3.4412e-04, -1.8892e-04, -2.0526e-04, -6.0815e-04,\n",
            "        -2.7263e-04, -3.0652e-04,  4.6657e-04, -5.5414e-04, -1.7835e-04,\n",
            "         4.6340e-05, -1.6080e-04, -3.0196e-04, -4.6872e-04, -3.9718e-04,\n",
            "        -8.1284e-05, -2.3482e-04,  1.4536e-04, -2.1949e-04,  6.7755e-04,\n",
            "        -8.1514e-05,  5.2495e-04, -1.0093e-03,  7.8332e-05, -2.4180e-04,\n",
            "        -5.9587e-04,  2.3652e-04, -4.0843e-04,  3.7146e-04, -6.2206e-04,\n",
            "        -6.7120e-04, -1.7440e-04, -3.0465e-04, -4.4469e-04,  1.1464e-04,\n",
            "         1.5495e-04, -3.5871e-05, -2.0631e-04, -7.7413e-04, -4.7408e-05,\n",
            "        -4.8233e-04,  4.4537e-04,  1.7193e-04, -2.5567e-04, -1.9236e-04,\n",
            "         8.2682e-06, -1.8461e-04,  8.3180e-04,  1.1760e-04, -1.5984e-04,\n",
            "        -7.0302e-04,  5.1980e-04, -7.0595e-04,  3.1292e-04, -4.5966e-04,\n",
            "        -5.3787e-04,  2.3695e-04, -3.8533e-05, -2.1391e-04,  4.9580e-05,\n",
            "         5.4170e-04, -2.2349e-04,  4.1539e-04,  7.1709e-04, -9.5300e-04,\n",
            "        -7.2226e-04,  4.7605e-04,  4.1345e-05, -6.3193e-04, -3.6256e-05,\n",
            "         2.9046e-04,  3.3314e-04,  1.4294e-04, -2.3322e-04, -9.4016e-05,\n",
            "        -1.6643e-04, -3.0826e-04,  2.3338e-04, -5.8013e-04, -5.2360e-04,\n",
            "        -1.6681e-04,  4.3668e-04,  2.6051e-05,  5.8235e-04, -3.5139e-04,\n",
            "        -2.6043e-04,  2.3904e-04,  3.0091e-04,  5.1179e-05, -7.4924e-04,\n",
            "        -9.0892e-05, -2.2248e-04,  8.1376e-05,  6.5872e-04, -4.2133e-04,\n",
            "         1.7067e-04, -5.3736e-05,  3.7487e-04, -1.7093e-04, -3.5745e-04,\n",
            "         2.0625e-04, -1.7071e-04, -1.8724e-04,  1.0386e-04,  9.5705e-06,\n",
            "         3.9483e-04, -2.6758e-05, -1.6968e-04,  2.4546e-04, -1.2800e-04,\n",
            "        -2.9609e-05, -8.2280e-07, -2.2212e-05, -8.9190e-07, -3.2074e-04,\n",
            "        -8.2384e-05, -2.6059e-04, -7.3226e-05, -7.1597e-05, -3.8182e-04,\n",
            "         2.8914e-04,  2.4187e-04, -5.2768e-04, -7.7860e-05,  5.3843e-04,\n",
            "        -1.4753e-04,  2.2978e-05, -3.4985e-04,  4.8829e-04,  4.6023e-04,\n",
            "         4.3058e-05, -5.4095e-04, -3.7662e-04,  4.5033e-04, -2.9620e-04,\n",
            "        -4.9754e-04, -8.7652e-04,  3.3551e-04, -1.4233e-04, -3.2480e-04,\n",
            "        -2.0390e-04, -2.2756e-04, -9.9840e-04, -3.5791e-04, -3.8437e-05,\n",
            "         2.0161e-04, -4.9305e-04,  1.2459e-04, -2.6230e-04, -2.5461e-04,\n",
            "         3.5378e-04,  1.4451e-04, -4.0497e-04,  6.5878e-04,  5.3496e-04,\n",
            "        -2.7739e-04, -2.4047e-04, -4.5809e-05, -4.3163e-04,  4.7631e-04,\n",
            "         2.6565e-04,  8.2370e-05,  4.4703e-06, -2.1925e-04,  6.2961e-04,\n",
            "         6.0583e-04, -4.0337e-04, -2.4634e-04, -6.3556e-04, -3.0014e-04,\n",
            "         5.3623e-04, -2.7717e-05,  2.3140e-04, -4.9921e-04, -3.6495e-04,\n",
            "         1.7173e-04, -2.6955e-04,  3.3235e-04,  1.0371e-04, -2.7331e-04,\n",
            "         4.5579e-04,  9.0812e-04, -3.9045e-04, -3.3792e-04,  3.5744e-04,\n",
            "         7.2952e-05, -1.1966e-04, -7.8554e-07, -7.6070e-04, -3.8312e-04,\n",
            "        -3.0555e-04, -3.3216e-04,  6.1570e-04,  2.7930e-04, -8.4195e-05,\n",
            "        -1.0869e-04, -2.2671e-04, -1.6843e-04,  3.2150e-04, -6.3748e-04,\n",
            "        -9.2124e-05,  2.1508e-04, -5.2535e-04, -3.2627e-04, -1.6443e-04,\n",
            "        -4.1705e-04,  8.8055e-04,  1.2349e-04,  1.3506e-04, -2.7546e-04,\n",
            "         5.4388e-04, -7.7646e-05, -3.4424e-04,  7.9029e-05,  8.4930e-04,\n",
            "         1.2414e-04,  1.8804e-04,  3.6377e-04,  3.4803e-04, -5.1970e-04,\n",
            "         1.8387e-04, -4.3117e-04,  2.8235e-04, -6.1150e-05,  4.9174e-04,\n",
            "        -4.1435e-04,  4.0473e-04, -8.4427e-04, -8.0554e-05, -3.0419e-04,\n",
            "         2.2480e-05, -5.7754e-04, -2.3398e-04,  2.0675e-04,  5.9073e-04,\n",
            "        -3.5834e-04,  7.3512e-04, -3.4008e-04,  6.4561e-04,  3.8688e-04,\n",
            "         4.8153e-05, -3.6008e-04, -2.9083e-04,  1.4671e-04, -6.8057e-04,\n",
            "         3.2698e-04, -3.0907e-04,  9.2788e-05,  6.8093e-05, -7.7667e-05,\n",
            "         2.7861e-04, -1.1247e-04, -2.1410e-04, -3.7990e-05,  6.1390e-05,\n",
            "        -8.1877e-04,  8.1763e-05, -2.5354e-05,  8.5574e-05, -2.6697e-05,\n",
            "        -3.1454e-04, -9.5738e-05, -2.5798e-04, -2.8361e-04,  6.7948e-05,\n",
            "        -2.9603e-04,  4.4903e-04,  1.8013e-04,  2.6896e-04, -4.6700e-05,\n",
            "         1.0023e-04,  5.9112e-04,  2.8692e-04, -4.7759e-04, -1.9243e-04,\n",
            "        -2.4882e-05,  2.5479e-05,  2.8162e-04,  3.2895e-04, -4.5477e-04,\n",
            "        -9.1472e-05,  7.7647e-04,  6.6797e-04,  5.6582e-05,  2.1886e-04,\n",
            "        -2.7619e-04, -7.2532e-05, -2.6937e-04, -1.1383e-04, -4.0988e-04,\n",
            "        -1.7032e-04, -1.3944e-05,  8.5911e-05,  1.7642e-05,  3.5288e-04,\n",
            "         1.8054e-04,  8.3904e-06,  2.8528e-05, -6.3791e-04, -5.4672e-04,\n",
            "         2.6871e-04,  3.0441e-04,  1.6350e-04, -1.4192e-04,  6.0921e-05,\n",
            "         4.4732e-05, -3.9443e-04, -2.1289e-04,  2.0343e-04, -3.5956e-04,\n",
            "         3.5930e-04, -1.5525e-04, -3.0770e-04, -8.5100e-05, -1.1178e-04,\n",
            "        -4.7878e-04, -7.2977e-05, -4.1194e-04, -3.1923e-04, -1.8948e-04,\n",
            "         1.6231e-04,  1.3195e-05,  5.2953e-04, -3.2107e-04,  3.2621e-04,\n",
            "        -1.0090e-03,  3.9288e-04, -8.2438e-05,  4.9568e-05,  1.1494e-04,\n",
            "         2.3702e-04,  5.2554e-04,  5.9765e-04, -4.9619e-04, -1.7038e-04,\n",
            "        -6.1322e-05, -3.2121e-05,  4.5169e-04,  2.2507e-04, -6.5431e-04,\n",
            "        -2.4404e-04, -3.2725e-04, -7.9830e-05, -4.1713e-04, -3.7757e-04,\n",
            "         4.5272e-04,  3.6712e-05, -3.2156e-04,  2.7565e-04,  1.2173e-05,\n",
            "        -2.2164e-04, -3.1745e-04,  3.1934e-04,  6.2586e-04, -3.9492e-05,\n",
            "         4.3575e-04,  8.2866e-05, -6.8429e-04,  3.8655e-04, -3.0909e-04,\n",
            "         4.1816e-04, -1.7236e-04, -3.2760e-04, -5.8571e-05,  1.9990e-04,\n",
            "         2.8304e-04,  8.7301e-06, -2.8360e-04,  8.8997e-04, -1.7667e-05,\n",
            "         3.0079e-04, -7.6891e-04,  1.4342e-04, -5.9021e-04,  5.4398e-04,\n",
            "         1.9507e-04,  9.1359e-04, -2.7389e-04,  3.5438e-04, -2.3686e-04,\n",
            "         5.0560e-04,  2.3663e-04, -4.8239e-04, -2.9683e-04,  8.1018e-04,\n",
            "        -2.6772e-04, -1.8466e-04, -1.6584e-04,  9.1454e-04, -1.0384e-04,\n",
            "         2.0209e-04,  2.2029e-04, -5.4628e-04,  3.4041e-04, -4.8492e-04,\n",
            "         4.6226e-04, -2.7059e-05, -2.2970e-05,  6.7984e-04, -5.0993e-04,\n",
            "        -1.2887e-04, -1.7457e-04, -1.5903e-04, -1.4609e-04, -2.0770e-04,\n",
            "         1.6827e-04, -2.8856e-04, -6.3162e-04,  2.8080e-04,  6.9055e-04,\n",
            "        -5.5276e-04, -1.1553e-04, -1.5500e-04,  7.7356e-05, -6.8764e-04,\n",
            "         4.4746e-04,  6.8268e-04, -4.4941e-04, -1.0773e-05,  1.9299e-04,\n",
            "         6.5008e-04, -2.1777e-04, -5.1649e-04, -2.8950e-04, -1.0134e-04,\n",
            "        -2.5853e-04, -3.5466e-04,  2.2291e-04, -1.5634e-04, -5.9892e-04,\n",
            "        -3.8783e-05, -5.4269e-04,  5.1947e-04,  6.0012e-04,  3.9538e-04,\n",
            "         7.7560e-05,  5.4492e-04,  2.4478e-04,  3.3047e-04,  9.1901e-05,\n",
            "         3.4897e-05,  2.1305e-04,  3.0369e-04, -2.3305e-04, -2.3425e-04,\n",
            "        -5.9647e-05,  4.3180e-04,  1.3308e-04, -7.3539e-05, -1.6396e-04,\n",
            "         5.0875e-04, -3.0871e-04,  1.2256e-04,  1.5313e-04, -4.2709e-04,\n",
            "         3.0218e-04,  2.5222e-04, -4.4435e-05,  6.9331e-05,  3.9625e-05,\n",
            "         5.4319e-05,  2.8447e-04,  5.7512e-04,  1.6218e-04,  3.4263e-04,\n",
            "        -5.1742e-04, -6.3396e-05, -4.2493e-04, -3.6587e-04, -3.2988e-04,\n",
            "        -4.7619e-04,  4.3427e-04,  7.0971e-05, -1.4722e-04, -4.4649e-04,\n",
            "        -4.6713e-04, -1.9402e-04,  4.4672e-04, -2.9846e-05, -1.1097e-04,\n",
            "         1.1543e-04, -9.1978e-04,  2.8486e-04,  2.6301e-04,  1.8245e-04,\n",
            "        -1.5142e-04, -2.2143e-04,  1.3586e-04,  2.1708e-04, -2.9832e-04,\n",
            "        -1.1396e-05,  1.1223e-04, -4.5987e-04, -6.4010e-04,  7.5883e-04,\n",
            "        -1.9613e-04, -1.8133e-04,  5.4276e-04,  1.3838e-04, -5.2643e-04,\n",
            "         1.0551e-04,  1.5291e-04, -3.4179e-04, -6.0052e-04,  6.6520e-04,\n",
            "        -3.6448e-04,  9.6241e-05,  7.9966e-04, -4.3311e-05, -2.4488e-04,\n",
            "         5.3550e-04,  3.8325e-04,  1.6942e-04,  1.8652e-05,  3.7543e-04,\n",
            "        -2.9242e-04, -2.2927e-04,  9.3663e-05, -4.0776e-04, -5.7591e-05,\n",
            "        -1.8907e-04, -3.5975e-05,  4.9650e-04,  3.5499e-04,  1.7701e-04,\n",
            "         3.3896e-04,  1.8233e-04,  4.0782e-05, -3.2050e-04,  1.8851e-04,\n",
            "        -2.1017e-04,  4.1516e-04,  1.9838e-04,  4.0074e-04, -3.8969e-04,\n",
            "        -4.8192e-04, -1.7965e-04, -5.6195e-05, -6.2565e-04,  1.1743e-04,\n",
            "         6.3885e-04, -6.3310e-05,  3.6290e-04,  5.9821e-05,  3.6023e-04,\n",
            "        -1.5061e-04,  1.4826e-04,  4.9693e-05,  5.3173e-05,  9.3740e-05,\n",
            "         5.7934e-05,  4.9819e-04, -9.9907e-05, -8.3935e-05,  5.2263e-04,\n",
            "         3.6444e-04,  6.3050e-04, -3.7525e-04, -1.4749e-04, -6.0777e-05,\n",
            "        -2.7413e-04,  5.7320e-04, -8.3272e-05,  5.4066e-04,  3.2751e-05,\n",
            "         3.3252e-04, -1.1440e-04,  1.7731e-04,  5.2663e-04,  5.6917e-05,\n",
            "         8.0847e-05, -4.7101e-05, -1.3725e-04, -7.7600e-05,  1.0541e-04,\n",
            "         8.5316e-04,  4.6576e-04,  7.8022e-04,  3.2988e-04, -1.9974e-04,\n",
            "         3.4415e-04, -1.3017e-04, -6.8376e-04, -3.2129e-04, -2.1535e-04,\n",
            "        -3.5797e-06, -8.6800e-05, -4.8079e-04, -2.8275e-04, -9.6588e-05,\n",
            "         5.9427e-04, -1.0833e-05, -5.6687e-04,  3.6770e-04,  4.4269e-04,\n",
            "        -8.2224e-05,  1.2895e-04,  3.4108e-04, -2.2977e-04,  2.0799e-04,\n",
            "         2.7659e-04,  5.2499e-04, -1.9203e-04, -1.3417e-04, -2.7074e-04,\n",
            "        -2.5709e-04,  4.6325e-04, -1.1713e-04, -5.3281e-05,  4.9424e-04,\n",
            "         2.8907e-04, -5.9130e-04,  5.8799e-04,  6.4134e-04, -1.2914e-05,\n",
            "         1.3243e-04,  1.1415e-04, -1.7793e-04, -3.7488e-04,  3.1745e-04,\n",
            "        -8.4218e-06,  4.7193e-04,  3.9045e-04,  1.9572e-04,  3.8865e-04,\n",
            "        -1.2764e-05, -4.0377e-04,  3.3294e-05,  6.8843e-05, -4.3259e-04,\n",
            "         1.0829e-05,  2.9673e-04,  1.1563e-04,  4.4996e-04, -4.8907e-05,\n",
            "        -1.7897e-04, -6.7189e-04,  7.2133e-04, -3.0683e-04, -5.7661e-04,\n",
            "         3.0344e-04, -2.1993e-04, -5.6632e-05,  2.3764e-04, -1.7076e-04,\n",
            "         2.7190e-04, -6.7816e-04, -1.9165e-04,  2.7670e-04,  6.6657e-04,\n",
            "         1.7699e-04,  1.7122e-04,  2.1935e-04,  2.7404e-05, -1.4138e-04,\n",
            "         5.1831e-04,  6.7149e-05, -6.8806e-04,  4.6532e-04, -1.0989e-04,\n",
            "        -2.5778e-04, -1.5440e-05, -3.2255e-05,  2.8539e-04,  1.0339e-04,\n",
            "        -4.3664e-04, -5.4403e-06,  1.9754e-04,  1.3343e-04, -1.1337e-05,\n",
            "        -1.4787e-04,  2.5671e-04, -1.3558e-04,  1.3253e-04,  1.5074e-04,\n",
            "        -3.1683e-04, -4.3805e-04, -5.7965e-04,  5.1652e-04,  3.6608e-04,\n",
            "         7.9571e-04, -2.1590e-04, -1.6858e-04, -9.1138e-05, -2.4652e-04,\n",
            "         4.3028e-04,  2.0137e-04,  3.7605e-04,  6.3503e-04,  2.2595e-05,\n",
            "        -1.9846e-04,  3.2576e-04,  1.0525e-03, -6.9023e-04, -1.6958e-04,\n",
            "        -1.3463e-04,  1.9912e-04, -3.9049e-04, -1.5790e-04,  6.4992e-04,\n",
            "        -3.8804e-04, -6.3543e-05,  1.6317e-04,  5.9943e-04,  4.9482e-05,\n",
            "        -4.9976e-05, -7.4697e-04,  1.3939e-04, -4.4621e-04, -3.8464e-04,\n",
            "         1.1369e-04,  1.5073e-04, -7.1061e-05,  2.0740e-04,  4.6709e-05,\n",
            "         1.9670e-04,  2.1336e-04, -2.4041e-04,  1.0365e-03,  3.4969e-04,\n",
            "        -4.3577e-05,  2.6708e-04, -3.7837e-04, -3.7741e-04,  5.8429e-04,\n",
            "         1.8836e-04,  3.3827e-05, -3.5042e-04], device='cuda:0')\n",
            "ITEM 18 IN LOADER     ----------------------------------------------------------------------\n",
            "y_labels_str = ['male', 'female']\n",
            "y_hat_labels_str = ['male female', 'male female']\n",
            "[Values V2]\n",
            "y_labels_str_v2 = ['male', 'boat', 'barrel', 'hat']\n",
            "y_labels_int_v2 = tensor([89, 15,  5, 70], device='cuda:0')\n",
            "y_bboxes_v2 = tensor([[0.4700, 0.6046, 0.4183, 0.6418],\n",
            "        [0.1514, 0.5457, 0.2500, 0.2452],\n",
            "        [0.7897, 0.8053, 0.2380, 0.1803],\n",
            "        [0.5589, 0.3474, 0.1755, 0.1274]], device='cuda:0')\n",
            "y_hat_labels_str_v2 = ['male', 'boat', 'barrel', 'hat']\n",
            "y_hat_bboxes_v2 = tensor([[0.4834, 0.6040, 0.4389, 0.6437],\n",
            "        [0.1502, 0.5377, 0.2521, 0.2391],\n",
            "        [0.7876, 0.8061, 0.2377, 0.1807],\n",
            "        [0.5602, 0.3450, 0.1655, 0.1235]], device='cuda:0',\n",
            "       grad_fn=<IndexSelectBackward0>)\n",
            "y_hat_logits_raw_v2 = tensor([[0.0044, 0.0167, 0.0025,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0040, 0.0041, 0.0024,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0027, 0.0016, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0046, 0.0232, 0.0026,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0', grad_fn=<IndexSelectBackward0>)\n",
            "loss = loss_box*1000.0 + loss_cls = 5.430166244506836 = 0.05274074897170067 + 5.377425670623779\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-87488626c463>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-345dd4243c09>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, epochs, lr)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# train_loss = train(data['train'][1:], model, optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-5d41edfea849>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, net, optimizer, IoU_threshold, beta)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MODEL PARAMETER GRADIENT CHECK: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_parameters = model.state_dict()\n",
        "\n",
        "parameters_updated = False\n",
        "for key in initial_parameters.keys():\n",
        "    if not torch.equal(initial_parameters[key], current_parameters[key]):\n",
        "        parameters_updated = True\n",
        "        break\n",
        "\n",
        "print('Parameters updated: {}'.format(parameters_updated))"
      ],
      "metadata": {
        "id": "ubqptCJoQW06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extras**"
      ],
      "metadata": {
        "id": "7BODprsBELBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual runs"
      ],
      "metadata": {
        "id": "8JMfrI3UD8q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GroundingDINOV2()\n",
        "# model = model.to(device)\n",
        "\n",
        "# image = data['train'][2][1]\n",
        "# image = image.to(device)\n",
        "\n",
        "# true_classes = [classes[int(i[0])] for i in data['train'][2][2]]\n",
        "# caption = \". \".join(true_classes)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     print(model(image, caption))"
      ],
      "metadata": {
        "id": "YpSqEqvJVr3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n = 1\n",
        "\n",
        "# image = data['train'][n][1]\n",
        "# image = image.to(device)\n",
        "\n",
        "# true_classes = [classes[int(i[0])] for i in data['train'][n][2]]\n",
        "# caption = \". \".join(true_classes)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     print(model(image, caption))"
      ],
      "metadata": {
        "id": "pGiSzAeJ2Pl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# # Suppose we have ground truth labels and predicted logits for three samples and three classes\n",
        "# ground_truth_labels = torch.tensor([2, 0, 1])  # Actual class labels (0: Class A, 1: Class B, 2: Class C)\n",
        "# predicted_logits = torch.tensor([[1.0, 2.0, -1.0], [-1.0, 0.5, 2.0], [0.0, 1.0, -2.0]])\n",
        "\n",
        "# # Calculate cross-entropy loss using PyTorch's F.cross_entropy\n",
        "# loss = F.cross_entropy(predicted_logits, ground_truth_labels)\n",
        "\n",
        "# print(\"Cross-Entropy Loss:\", loss.item())"
      ],
      "metadata": {
        "id": "PcS_qCY06PjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Old Version"
      ],
      "metadata": {
        "id": "QEbLVBxRVoD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujXfKu9xc8rF"
      },
      "outputs": [],
      "source": [
        "# class GroundingDINOV2(nn.Module):\n",
        "#     def __init__(self, box_threshold=0.35, text_threshold=0.25):\n",
        "#         super(GroundingDINOV2, self).__init__()\n",
        "\n",
        "#         self.box_threshold = box_threshold\n",
        "#         self.text_threshold = text_threshold\n",
        "\n",
        "#         self.DINO = Model(model_config_path=CONFIG_PATH, model_checkpoint_path=WEIGHTS_PATH)\n",
        "\n",
        "#     def forward(self, image, image_classes):\n",
        "#         image = image.reshape(416,416,3)*255\n",
        "#         image = image.astype(np.uint8)\n",
        "#         x = self.DINO.predict_with_classes(\n",
        "#             image=image,\n",
        "#             classes=image_classes,\n",
        "#             box_threshold=self.box_threshold,\n",
        "#             text_threshold=self.text_threshold\n",
        "#         )\n",
        "\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFwMeUVXiluR"
      },
      "outputs": [],
      "source": [
        "# # directory_images = '/content/drive/MyDrive/Delft/capstone data/1.0_Children_Books/'+'train'+'/images'\n",
        "# # IMAGE_PATH = directory_images+'/'+data['train'][2][0]+'.jpg'\n",
        "\n",
        "# model = GroundingDINOV2()\n",
        "# model(data['train'][2][1], [classes[int(i[0])] for i in data['train'][2][2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_MtrxMsr8Tc"
      },
      "outputs": [],
      "source": [
        "# directory_images = '/content/drive/MyDrive/Delft/capstone data/1.0_Children_Books/'+'train'+'/images'\n",
        "\n",
        "# IMAGE_PATH = directory_images+'/'+data['train'][0][0]+'.jpg'\n",
        "# # IMAGE_PATH = os.path.join(HOME, \"data\", IMAGE_NAME)\n",
        "\n",
        "# TEXT_PROMPT = \"chair\"\n",
        "# BOX_TRESHOLD = 0.35\n",
        "# TEXT_TRESHOLD = 0.25\n",
        "\n",
        "# image_source, image = load_image(IMAGE_PATH)\n",
        "# image\n",
        "\n",
        "# im = Image.fromarray((x * 255).astype(np.uint8))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grounding DINO Manual Pass"
      ],
      "metadata": {
        "id": "3QygqQ8jlWRS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcknTdB2SUPZ"
      },
      "outputs": [],
      "source": [
        "# manual_pass_model = load_model(CONFIG_PATH, WEIGHTS_PATH)\n",
        "\n",
        "# directory_images = '/content/drive/MyDrive/Delft/capstone data/1.0_Children_Books/'+'train'+'/images'\n",
        "\n",
        "# IMAGE_PATH = directory_images+'/'+data['train'][2][0]+'.jpg'\n",
        "# # IMAGE_PATH = os.path.join(HOME, \"data\", IMAGE_NAME)\n",
        "\n",
        "# TEXT_PROMPT = \"painting. male. female.\"\n",
        "# BOX_TRESHOLD = 0.35\n",
        "# TEXT_TRESHOLD = 0.25\n",
        "\n",
        "# image_source, image = load_image(IMAGE_PATH)\n",
        "\n",
        "# print('Size loaded image by Grounding DINO: {}'.format(image.shape))\n",
        "\n",
        "# boxes, logits, phrases = predict(\n",
        "#     model=manual_pass_model,\n",
        "#     image=image,\n",
        "#     caption=TEXT_PROMPT,\n",
        "#     box_threshold=BOX_TRESHOLD,\n",
        "#     text_threshold=TEXT_TRESHOLD\n",
        "# )\n",
        "\n",
        "# annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "\n",
        "# %matplotlib inline\n",
        "# sv.plot_image(annotated_frame, (16, 16))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6-onp0zmeW2R",
        "MT1ZWFrXRuWt",
        "-kJt4Uk1SEVU",
        "VcpdWG-CVzXs",
        "cu7vtqgMe5KB",
        "Ur0gjcGb7JWd",
        "rx-Z2DZZ7Lr0",
        "7BODprsBELBx",
        "8JMfrI3UD8q6",
        "QEbLVBxRVoD2",
        "3QygqQ8jlWRS"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "737a48fa72d846d1816c3c7426c2eae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d87446db91e4f6dafc2901719893140",
              "IPY_MODEL_5e9ea20a5f294d5bb19f0faaab2bc268",
              "IPY_MODEL_f2cfc1b0d5fe43d89273f26a375de8f4"
            ],
            "layout": "IPY_MODEL_1f88739868b240d2b3bab0611412a881"
          }
        },
        "8d87446db91e4f6dafc2901719893140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de24fa72109541179c57f6b5c66cc795",
            "placeholder": "​",
            "style": "IPY_MODEL_3150d3a576f147f5b0546f5e76579fed",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5e9ea20a5f294d5bb19f0faaab2bc268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf5fed0371b49c78973e89a90da447b",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b436b86abddd467cab22f6eae204c183",
            "value": 28
          }
        },
        "f2cfc1b0d5fe43d89273f26a375de8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26cea3edf5eb4f078a2b9f1676a1e46b",
            "placeholder": "​",
            "style": "IPY_MODEL_cd45ac1e1f27460498d614b4e2b36f6b",
            "value": " 28.0/28.0 [00:00&lt;00:00, 772B/s]"
          }
        },
        "1f88739868b240d2b3bab0611412a881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de24fa72109541179c57f6b5c66cc795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3150d3a576f147f5b0546f5e76579fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbf5fed0371b49c78973e89a90da447b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b436b86abddd467cab22f6eae204c183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26cea3edf5eb4f078a2b9f1676a1e46b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd45ac1e1f27460498d614b4e2b36f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fba7ed9965154a949665b47de71873c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2ff0eba58b542d29cbe3bec34dc9b21",
              "IPY_MODEL_73c6d7b70cbd41ffbd8e8c143895ae96",
              "IPY_MODEL_98733a4aab1e46f5a246f6d329e03008"
            ],
            "layout": "IPY_MODEL_16f4a3e0e8764568999848536e08c792"
          }
        },
        "f2ff0eba58b542d29cbe3bec34dc9b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b89ac451a854cfcadc120c727f33df3",
            "placeholder": "​",
            "style": "IPY_MODEL_49a819311bf04dc6b76c5b033ca5b6b5",
            "value": "config.json: 100%"
          }
        },
        "73c6d7b70cbd41ffbd8e8c143895ae96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b45196818f47c88fb3839c58746867",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_695558a2f8d24fb2948b0a2b25f2e79b",
            "value": 570
          }
        },
        "98733a4aab1e46f5a246f6d329e03008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b364725392466582f371ac3c0d89a2",
            "placeholder": "​",
            "style": "IPY_MODEL_c26057d9f6da4297adba2bca594a93d6",
            "value": " 570/570 [00:00&lt;00:00, 21.7kB/s]"
          }
        },
        "16f4a3e0e8764568999848536e08c792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b89ac451a854cfcadc120c727f33df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a819311bf04dc6b76c5b033ca5b6b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b45196818f47c88fb3839c58746867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "695558a2f8d24fb2948b0a2b25f2e79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55b364725392466582f371ac3c0d89a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26057d9f6da4297adba2bca594a93d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2576b37624fa46e6a70d439311e83000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7209b18fa864498a00681939cd44578",
              "IPY_MODEL_6f4a8698671f4c5dbd3c3d707c533c4a",
              "IPY_MODEL_c3a969a596a54d9d8acef303173d22b5"
            ],
            "layout": "IPY_MODEL_9f5d041ced52415687d499ffb320c097"
          }
        },
        "c7209b18fa864498a00681939cd44578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1afc2ac48b4a939abff56af701013a",
            "placeholder": "​",
            "style": "IPY_MODEL_bc8ff3ee72544e6783b66082646f5248",
            "value": "vocab.txt: 100%"
          }
        },
        "6f4a8698671f4c5dbd3c3d707c533c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57cdcaa1473c408aa0427ffae4012741",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68bd8129a3f540b2aca477df3003fdf7",
            "value": 231508
          }
        },
        "c3a969a596a54d9d8acef303173d22b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c5ddbae1cac478ebc4dc74b227a7d65",
            "placeholder": "​",
            "style": "IPY_MODEL_831eda6ff3294b05a76ebbad70f4bcee",
            "value": " 232k/232k [00:00&lt;00:00, 3.82MB/s]"
          }
        },
        "9f5d041ced52415687d499ffb320c097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1afc2ac48b4a939abff56af701013a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8ff3ee72544e6783b66082646f5248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57cdcaa1473c408aa0427ffae4012741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68bd8129a3f540b2aca477df3003fdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c5ddbae1cac478ebc4dc74b227a7d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831eda6ff3294b05a76ebbad70f4bcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb828d23df24d9492d4d14dadfc3ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f1cbbdccf7c434aa8548fe70705fba7",
              "IPY_MODEL_fc6574bbb55b4bc0afa750bbd4048803",
              "IPY_MODEL_d6aa17eadd0a4cc3bf47733637234a3f"
            ],
            "layout": "IPY_MODEL_3da49739e8b642898c096015b05c981d"
          }
        },
        "9f1cbbdccf7c434aa8548fe70705fba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_935548d7e4c840b6bea8503dfa1af264",
            "placeholder": "​",
            "style": "IPY_MODEL_bfa1154152b84377b5db9ab36a87a3db",
            "value": "tokenizer.json: 100%"
          }
        },
        "fc6574bbb55b4bc0afa750bbd4048803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1812528bae9749c5b059f2de1404aeba",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f8db92ee3554d0e96433d7287525248",
            "value": 466062
          }
        },
        "d6aa17eadd0a4cc3bf47733637234a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee475aec82148fa81a3791f5292d9a7",
            "placeholder": "​",
            "style": "IPY_MODEL_37454c105a9f43d88d243df166c29c99",
            "value": " 466k/466k [00:00&lt;00:00, 20.0MB/s]"
          }
        },
        "3da49739e8b642898c096015b05c981d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "935548d7e4c840b6bea8503dfa1af264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa1154152b84377b5db9ab36a87a3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1812528bae9749c5b059f2de1404aeba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8db92ee3554d0e96433d7287525248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee475aec82148fa81a3791f5292d9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37454c105a9f43d88d243df166c29c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5006c00fa4b2479b9e6bdad160bae7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5b82a8aff184716b4ba663d589f7919",
              "IPY_MODEL_055a5b178c2d4c8b86910f374b2650d1",
              "IPY_MODEL_158823c117154b5ab9c89302fb9da5ba"
            ],
            "layout": "IPY_MODEL_8492ddd14606452e9950bc5ecf416d82"
          }
        },
        "b5b82a8aff184716b4ba663d589f7919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de5f354b5a9a43fdb83ebd755d7cadab",
            "placeholder": "​",
            "style": "IPY_MODEL_964712212eb9469696344f879863ff34",
            "value": "model.safetensors: 100%"
          }
        },
        "055a5b178c2d4c8b86910f374b2650d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c58caf6e3c644986a3b5f0747070da4c",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03533bc094364676bd1dbfeadd6a88ae",
            "value": 440449768
          }
        },
        "158823c117154b5ab9c89302fb9da5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf8f241504a345cd994b96f0629360a1",
            "placeholder": "​",
            "style": "IPY_MODEL_24ff6ab18784458b862382773c605da3",
            "value": " 440M/440M [00:05&lt;00:00, 36.3MB/s]"
          }
        },
        "8492ddd14606452e9950bc5ecf416d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de5f354b5a9a43fdb83ebd755d7cadab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964712212eb9469696344f879863ff34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c58caf6e3c644986a3b5f0747070da4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03533bc094364676bd1dbfeadd6a88ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf8f241504a345cd994b96f0629360a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ff6ab18784458b862382773c605da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}